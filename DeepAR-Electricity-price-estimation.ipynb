{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity price prediciton with SageMaker and DeepAR\n",
    "Projektarbete inom kursen 5TF078, Deep Learning - metoder och till채mpningar, vid Ume책 Universitet\n",
    "\n",
    "DeepAR projektfilen 채r baserad p책: https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/deepar_electricity/DeepAR-Electricity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/site-packages (4.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "!pip install pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "import sys\n",
    "#import zipfile\n",
    "#from dateutil.parser import parse\n",
    "import json\n",
    "import datetime\n",
    "#import os\n",
    "\n",
    "import boto3\n",
    "#import s3fs\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact_manual,interact, interactive, fixed\n",
    "#import ipywidgets as widgets\n",
    "from ipywidgets import IntSlider, FloatSlider, Checkbox\n",
    "\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we can override the default values for the following:\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = \"deepar-electricity-price-prediction\"  # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()  # IAM role to use by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we configure the container image to be used for the region that we are running in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we need to download the original data set of from the UCI data set repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data files locally, let us copy them to S3 where DeepAR can access them. Depending on your connection, this may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith(\"s3://\")\n",
    "    split = s3_path.split(\"/\")\n",
    "    bucket = split[2]\n",
    "    path = \"/\".join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "\n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print(\n",
    "                \"File s3://{}/{} already exists.\\nSet override to upload anyway.\\n\".format(\n",
    "                    s3_bucket, s3_path\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    with open(local_file, \"rb\") as data:\n",
    "        print(\"Uploading file to {}\".format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file\n",
      "Uploading file to s3://sagemaker-eu-north-1-646903401606/deepar-electricity-price-prediction/data/train/train.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://sagemaker-eu-north-1-646903401606/deepar-electricity-price-prediction/data/test/test.json\n",
      "CPU times: user 45.1 ms, sys: 15.2 ms, total: 60.4 ms\n",
      "Wall time: 465 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_to_s3(\"training.jsonl\", s3_data_path + \"/train/train.json\", override=True)\n",
    "copy_to_s3(\"test.jsonl\", s3_data_path + \"/test/test.json\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to what we just wrote to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2021-12-21 00:00:00\", \"target\": [2.4064, 2.1496, 2.0919, 2.0713, 2.2843, 3.2443, 4.1192, ...\n"
     ]
    }
   ],
   "source": [
    "s3_sample = s3.Object(s3_bucket, s3_prefix + \"/data/train/train.json\").get()[\"Body\"].read()\n",
    "StringVariable = s3_sample.decode(\"UTF-8\", \"ignore\")\n",
    "lines = StringVariable.split(\"\\n\")\n",
    "print(lines[0][:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all set with our dataset processing, we can now call DeepAR to train a model and generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "Here we define the estimator that will launch the training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set the hyperparameters for the training job. For example frequency of the time series used, number of data points the model will look at in the past, number of predicted data points. The other hyperparameters concern the model to train (number of layers, number of cells per layer, likelihood function) and the training options (number of epochs, batch size, learning rate...). We use default parameters for every optional parameter in this case (you can always use [Sagemaker Automated Model Tuning](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/) to tune them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 1 hour frequency for the time series\n",
    "freq = \"H\"\n",
    "\n",
    "# we predict for 24 hours\n",
    "prediction_length = 24 * 8\n",
    "\n",
    "# we also use 7 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    base_job_name=s3_prefix,\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-3\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the training job. SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model.\n",
    "\n",
    "If you provide the `test` data channel as we do in this example, DeepAR will also calculate accuracy metrics for the trained model on this test. This is done by predicting the last `prediction_length` points of each time-series in the test set and comparing this to the actual value of the time-series. \n",
    "\n",
    "**Note:** the next cell may take a few minutes to complete, depending on data size, model complexity, training options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ladda tidigare modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-03-08 13:08:10 Starting - Preparing the instances for training\n",
      "2022-03-08 13:08:10 Downloading - Downloading input data\n",
      "2022-03-08 13:08:10 Training - Training image download completed. Training in progress.\n",
      "2022-03-08 13:08:10 Uploading - Uploading generated training model\n",
      "2022-03-08 13:08:10 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator_training_job_name = 'deepar-electricity-price-prediction-2022-03-08-11-53-53-354'\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator.attach(estimator_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-08 13:08:10 Starting - Preparing the instances for training\n",
      "2022-03-08 13:08:10 Downloading - Downloading input data\n",
      "2022-03-08 13:08:10 Training - Training image download completed. Training in progress.\n",
      "2022-03-08 13:08:10 Uploading - Uploading generated training model\n",
      "2022-03-08 13:08:10 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664 integration.py:592] worker started\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '24', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '5E-3', 'mini_batch_size': '64', 'prediction_length': '192', 'time_freq': 'H'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '5E-3', 'likelihood': 'student-t', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '24', 'epochs': '400', 'prediction_length': '192', 'time_freq': 'H'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] random_seed is None\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:13 INFO 140043348993664] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=47 from dataset.\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] Training set statistics:\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] Real time series\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] number of time series: 56\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] number of observations: 12096\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] mean target length: 216.0\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] min/mean/max target: 0.042100001126527786/0.9895553481641901/6.3850998878479\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] mean abs(target): 0.9895553481641901\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] contains missing values: no\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] Small number of time series. Doing 12 passes over dataset with prob 0.9523809523809524 per epoch.\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] Test set statistics:\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] Real time series\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] number of time series: 9\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] number of observations: 1944\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] mean target length: 216.0\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] min/mean/max target: 0.1145000010728836/0.8530394942672165/4.317800045013428\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] mean abs(target): 0.8530394942672165\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] contains missing values: no\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] #memory_usage::<batchbuffer> = 51.66389465332031 mb\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] nvidia-smi took: 0.025269269943237305 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:14 INFO 140043348993664] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740634.1219864, \"EndTime\": 1646740635.0378685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 913.6793613433838, \"count\": 1, \"min\": 913.6793613433838, \"max\": 913.6793613433838}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:15 INFO 140043348993664] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:16 INFO 140043348993664] #memory_usage::<model> = 96 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740635.0380642, \"EndTime\": 1646740636.7696002, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 2647.449016571045, \"count\": 1, \"min\": 2647.449016571045, \"max\": 2647.449016571045}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:19 INFO 140043348993664] Epoch[0] Batch[0] avg_epoch_loss=2.977675\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=2.977675437927246\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:23 INFO 140043348993664] Epoch[0] Batch[5] avg_epoch_loss=1.689700\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=1.6896997292836506\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:23 INFO 140043348993664] Epoch[0] Batch [5]#011Speed: 72.33 samples/sec#011loss=1.689700\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] Epoch[0] Batch[10] avg_epoch_loss=1.489592\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=1.2494621753692627\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] Epoch[0] Batch [10]#011Speed: 83.16 samples/sec#011loss=1.249462\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740636.7698197, \"EndTime\": 1646740647.4462824, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 10676.33581161499, \"count\": 1, \"min\": 10676.33581161499, \"max\": 10676.33581161499}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.91187240544646 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] #progress_metric: host=algo-1, completed 0.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=0, train loss <loss>=1.4895917502316562\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:27 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_3edd94c9-5efc-454a-993e-6189ae0f9d79-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740647.4463735, \"EndTime\": 1646740647.6044188, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 157.49692916870117, \"count\": 1, \"min\": 157.49692916870117, \"max\": 157.49692916870117}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:29 INFO 140043348993664] Epoch[1] Batch[0] avg_epoch_loss=1.203348\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.2033483982086182\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:33 INFO 140043348993664] Epoch[1] Batch[5] avg_epoch_loss=1.137004\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.1370035608609517\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:33 INFO 140043348993664] Epoch[1] Batch [5]#011Speed: 84.64 samples/sec#011loss=1.137004\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] Epoch[1] Batch[10] avg_epoch_loss=1.061061\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=0.9699310064315796\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] Epoch[1] Batch [10]#011Speed: 83.58 samples/sec#011loss=0.969931\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740647.6048608, \"EndTime\": 1646740657.3861444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9781.200885772705, \"count\": 1, \"min\": 9781.200885772705, \"max\": 9781.200885772705}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.90529076862782 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 0.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.0610614906657825\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:37 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_11ce436c-5ac8-4087-a862-49ca8f1bcde4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740657.3864489, \"EndTime\": 1646740657.5045474, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 116.84083938598633, \"count\": 1, \"min\": 116.84083938598633, \"max\": 116.84083938598633}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:39 INFO 140043348993664] Epoch[2] Batch[0] avg_epoch_loss=0.973192\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=0.9731919765472412\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:43 INFO 140043348993664] Epoch[2] Batch[5] avg_epoch_loss=0.907709\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=0.9077092210451762\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:43 INFO 140043348993664] Epoch[2] Batch [5]#011Speed: 87.90 samples/sec#011loss=0.907709\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] Epoch[2] Batch[10] avg_epoch_loss=0.848707\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=0.7779049873352051\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] Epoch[2] Batch [10]#011Speed: 81.69 samples/sec#011loss=0.777905\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740657.5049207, \"EndTime\": 1646740667.253429, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9748.42643737793, \"count\": 1, \"min\": 9748.42643737793, \"max\": 9748.42643737793}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.18938293587667 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] #progress_metric: host=algo-1, completed 0.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=2, train loss <loss>=0.848707296631553\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:47 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_9a53c941-4b3c-43c6-a4e8-5042fc0a262f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740667.2535248, \"EndTime\": 1646740667.3740304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 119.59481239318848, \"count\": 1, \"min\": 119.59481239318848, \"max\": 119.59481239318848}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:49 INFO 140043348993664] Epoch[3] Batch[0] avg_epoch_loss=0.948745\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=0.9487448334693909\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:53 INFO 140043348993664] Epoch[3] Batch[5] avg_epoch_loss=0.808842\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=0.8088420927524567\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:53 INFO 140043348993664] Epoch[3] Batch [5]#011Speed: 89.03 samples/sec#011loss=0.808842\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] Epoch[3] Batch[10] avg_epoch_loss=0.770721\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=0.7249746322631836\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] Epoch[3] Batch [10]#011Speed: 80.60 samples/sec#011loss=0.724975\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740667.3741255, \"EndTime\": 1646740677.0522249, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9678.012371063232, \"count\": 1, \"min\": 9678.012371063232, \"max\": 9678.012371063232}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.84767653677848 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=3, train loss <loss>=0.7707205198027871\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:57 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_b6f6b6b5-28e2-4d7a-99d1-04974d8bfb39-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740677.052378, \"EndTime\": 1646740677.1688287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.59104919433594, \"count\": 1, \"min\": 115.59104919433594, \"max\": 115.59104919433594}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:59 INFO 140043348993664] Epoch[4] Batch[0] avg_epoch_loss=0.719765\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:57:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=0.7197647094726562\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:03 INFO 140043348993664] Epoch[4] Batch[5] avg_epoch_loss=0.632960\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=0.632959634065628\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:03 INFO 140043348993664] Epoch[4] Batch [5]#011Speed: 78.04 samples/sec#011loss=0.632960\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] Epoch[4] Batch[10] avg_epoch_loss=0.596537\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=0.5528294563293457\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] Epoch[4] Batch [10]#011Speed: 81.10 samples/sec#011loss=0.552829\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740677.1689835, \"EndTime\": 1646740687.307756, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10138.676166534424, \"count\": 1, \"min\": 10138.676166534424, \"max\": 10138.676166534424}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.49104271700536 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 1.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=4, train loss <loss>=0.5965368260036815\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:07 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_ec45ea99-deb9-49a0-abd0-645fac636ec4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740687.3078346, \"EndTime\": 1646740687.4427326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 134.4139575958252, \"count\": 1, \"min\": 134.4139575958252, \"max\": 134.4139575958252}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:09 INFO 140043348993664] Epoch[5] Batch[0] avg_epoch_loss=0.508117\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=0.5081169009208679\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:13 INFO 140043348993664] Epoch[5] Batch[5] avg_epoch_loss=0.469737\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=0.469737450281779\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:13 INFO 140043348993664] Epoch[5] Batch [5]#011Speed: 87.69 samples/sec#011loss=0.469737\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] Epoch[5] Batch[10] avg_epoch_loss=0.457681\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=0.44321398735046386\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] Epoch[5] Batch [10]#011Speed: 83.48 samples/sec#011loss=0.443214\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740687.4428031, \"EndTime\": 1646740697.1355608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9692.689418792725, \"count\": 1, \"min\": 9692.689418792725, \"max\": 9692.689418792725}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.88310610786888 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 1.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=5, train loss <loss>=0.45768133076754486\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:17 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_c5df3832-6bc0-471a-b2d1-1f4c5fff9bc6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740697.1359646, \"EndTime\": 1646740697.3012345, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 163.61331939697266, \"count\": 1, \"min\": 163.61331939697266, \"max\": 163.61331939697266}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:19 INFO 140043348993664] Epoch[6] Batch[0] avg_epoch_loss=0.407211\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=0.4072105884552002\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:23 INFO 140043348993664] Epoch[6] Batch[5] avg_epoch_loss=0.368853\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=0.36885278423627216\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:23 INFO 140043348993664] Epoch[6] Batch [5]#011Speed: 86.73 samples/sec#011loss=0.368853\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] Epoch[6] Batch[10] avg_epoch_loss=0.358266\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=0.3455629348754883\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] Epoch[6] Batch [10]#011Speed: 85.85 samples/sec#011loss=0.345563\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740697.3016884, \"EndTime\": 1646740706.7759097, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9474.119663238525, \"count\": 1, \"min\": 9474.119663238525, \"max\": 9474.119663238525}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.8791683910947 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 1.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=6, train loss <loss>=0.3582664890722795\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:26 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_54dc7d28-a0e8-4d95-a050-266f97f8214d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740706.7759852, \"EndTime\": 1646740706.9003685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 123.86488914489746, \"count\": 1, \"min\": 123.86488914489746, \"max\": 123.86488914489746}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:28 INFO 140043348993664] Epoch[7] Batch[0] avg_epoch_loss=0.357105\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=0.3571050763130188\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:32 INFO 140043348993664] Epoch[7] Batch[5] avg_epoch_loss=0.306053\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=0.30605312436819077\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:32 INFO 140043348993664] Epoch[7] Batch [5]#011Speed: 86.81 samples/sec#011loss=0.306053\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] Epoch[7] Batch[10] avg_epoch_loss=0.268001\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=0.22233774065971373\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] Epoch[7] Batch [10]#011Speed: 83.73 samples/sec#011loss=0.222338\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740706.900788, \"EndTime\": 1646740716.4383998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9537.518978118896, \"count\": 1, \"min\": 9537.518978118896, \"max\": 9537.518978118896}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.97980257695578 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=7, train loss <loss>=0.26800067722797394\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:36 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_76ff8ab2-e0f4-463f-ace5-059504cf71be-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740716.4387634, \"EndTime\": 1646740716.5796335, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 139.52350616455078, \"count\": 1, \"min\": 139.52350616455078, \"max\": 139.52350616455078}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:38 INFO 140043348993664] Epoch[8] Batch[0] avg_epoch_loss=0.340477\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=0.3404766023159027\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:42 INFO 140043348993664] Epoch[8] Batch[5] avg_epoch_loss=0.261813\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=0.26181329290072125\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:42 INFO 140043348993664] Epoch[8] Batch [5]#011Speed: 87.51 samples/sec#011loss=0.261813\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] Epoch[8] Batch[10] avg_epoch_loss=0.237156\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=0.2075665384531021\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] Epoch[8] Batch [10]#011Speed: 85.14 samples/sec#011loss=0.207567\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740716.5808537, \"EndTime\": 1646740726.0858164, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9504.889011383057, \"count\": 1, \"min\": 9504.889011383057, \"max\": 9504.889011383057}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.59234787410625 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 2.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=8, train loss <loss>=0.23715567724271255\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:46 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_6d04faf4-e484-4843-b8f2-76742df8f376-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740726.0861504, \"EndTime\": 1646740726.205636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 118.10493469238281, \"count\": 1, \"min\": 118.10493469238281, \"max\": 118.10493469238281}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:48 INFO 140043348993664] Epoch[9] Batch[0] avg_epoch_loss=0.172746\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=0.1727461963891983\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:52 INFO 140043348993664] Epoch[9] Batch[5] avg_epoch_loss=0.203788\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=0.20378805448611578\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:52 INFO 140043348993664] Epoch[9] Batch [5]#011Speed: 87.00 samples/sec#011loss=0.203788\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:55 INFO 140043348993664] Epoch[9] Batch[10] avg_epoch_loss=0.168633\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=0.12644590362906455\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:55 INFO 140043348993664] Epoch[9] Batch [10]#011Speed: 81.76 samples/sec#011loss=0.126446\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:56 INFO 140043348993664] processed a total of 717 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740726.2060459, \"EndTime\": 1646740736.7320073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10525.87080001831, \"count\": 1, \"min\": 10525.87080001831, \"max\": 10525.87080001831}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:56 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.11511481615585 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:56 INFO 140043348993664] #progress_metric: host=algo-1, completed 2.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=9, train loss <loss>=0.14216978071878353\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:56 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:56 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_8d49c42d-3da6-4f86-93ec-f62a4a52d042-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740736.7323906, \"EndTime\": 1646740736.9085608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 174.3297576904297, \"count\": 1, \"min\": 174.3297576904297, \"max\": 174.3297576904297}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:59 INFO 140043348993664] Epoch[10] Batch[0] avg_epoch_loss=0.174140\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:58:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=0.1741403192281723\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:03 INFO 140043348993664] Epoch[10] Batch[5] avg_epoch_loss=0.088914\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=0.08891371699670951\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:03 INFO 140043348993664] Epoch[10] Batch [5]#011Speed: 77.11 samples/sec#011loss=0.088914\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] Epoch[10] Batch[10] avg_epoch_loss=0.079041\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=0.06719472371041775\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] Epoch[10] Batch [10]#011Speed: 82.55 samples/sec#011loss=0.067195\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740736.9089956, \"EndTime\": 1646740747.1010497, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10191.972255706787, \"count\": 1, \"min\": 10191.972255706787, \"max\": 10191.972255706787}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.79756639672999 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 2.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=10, train loss <loss>=0.07904144732112234\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:07 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_189f59f3-3317-4881-a755-9d541056c9c6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740747.101141, \"EndTime\": 1646740747.232555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 130.6915283203125, \"count\": 1, \"min\": 130.6915283203125, \"max\": 130.6915283203125}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:09 INFO 140043348993664] Epoch[11] Batch[0] avg_epoch_loss=0.148339\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=0.14833851158618927\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:13 INFO 140043348993664] Epoch[11] Batch[5] avg_epoch_loss=0.066144\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=0.06614355199659865\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:13 INFO 140043348993664] Epoch[11] Batch [5]#011Speed: 88.57 samples/sec#011loss=0.066144\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] Epoch[11] Batch[10] avg_epoch_loss=0.055010\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=0.041650040494278076\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] Epoch[11] Batch [10]#011Speed: 85.90 samples/sec#011loss=0.041650\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740747.232624, \"EndTime\": 1646740756.8283472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9595.46709060669, \"count\": 1, \"min\": 9595.46709060669, \"max\": 9595.46709060669}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.3023619151738 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=11, train loss <loss>=0.05501013767736202\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:16 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_c90d5248-5dd0-444c-ac58-5329233b4f9d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740756.8284225, \"EndTime\": 1646740756.9417448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 112.73527145385742, \"count\": 1, \"min\": 112.73527145385742, \"max\": 112.73527145385742}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:19 INFO 140043348993664] Epoch[12] Batch[0] avg_epoch_loss=-0.015525\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=-0.015525465831160545\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:22 INFO 140043348993664] Epoch[12] Batch[5] avg_epoch_loss=-0.031003\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=-0.03100284282118082\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:22 INFO 140043348993664] Epoch[12] Batch [5]#011Speed: 86.01 samples/sec#011loss=-0.031003\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] Epoch[12] Batch[10] avg_epoch_loss=-0.040052\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=-0.05091113513335586\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] Epoch[12] Batch [10]#011Speed: 82.69 samples/sec#011loss=-0.050911\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740756.941815, \"EndTime\": 1646740766.7391589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9797.274827957153, \"count\": 1, \"min\": 9797.274827957153, \"max\": 9797.274827957153}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.11881507981657 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 3.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=12, train loss <loss>=-0.0400520665994422\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:26 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_bcc17009-2848-4f5e-b28b-34cd9a0dbcd1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740766.7395, \"EndTime\": 1646740766.856807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.92483520507812, \"count\": 1, \"min\": 115.92483520507812, \"max\": 115.92483520507812}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:29 INFO 140043348993664] Epoch[13] Batch[0] avg_epoch_loss=-0.078669\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=-0.07866871356964111\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:32 INFO 140043348993664] Epoch[13] Batch[5] avg_epoch_loss=-0.069379\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=-0.06937916809692979\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:32 INFO 140043348993664] Epoch[13] Batch [5]#011Speed: 84.99 samples/sec#011loss=-0.069379\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] Epoch[13] Batch[10] avg_epoch_loss=-0.011982\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=0.056894706934690474\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] Epoch[13] Batch [10]#011Speed: 86.00 samples/sec#011loss=0.056895\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740766.8571754, \"EndTime\": 1646740776.4992115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9641.944169998169, \"count\": 1, \"min\": 9641.944169998169, \"max\": 9641.944169998169}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.55171985774436 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 3.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=13, train loss <loss>=-0.011981952173466032\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:36 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:38 INFO 140043348993664] Epoch[14] Batch[0] avg_epoch_loss=0.099196\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=0.09919557720422745\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:42 INFO 140043348993664] Epoch[14] Batch[5] avg_epoch_loss=0.039067\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=0.03906705603003502\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:42 INFO 140043348993664] Epoch[14] Batch [5]#011Speed: 89.08 samples/sec#011loss=0.039067\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] Epoch[14] Batch[10] avg_epoch_loss=0.024833\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=0.0077522918581962585\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] Epoch[14] Batch [10]#011Speed: 86.25 samples/sec#011loss=0.007752\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740776.4995813, \"EndTime\": 1646740785.9378703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9436.588287353516, \"count\": 1, \"min\": 9436.588287353516, \"max\": 9436.588287353516}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.84706202207924 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] #progress_metric: host=algo-1, completed 3.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=14, train loss <loss>=0.024833072315562855\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:45 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:48 INFO 140043348993664] Epoch[15] Batch[0] avg_epoch_loss=-0.105307\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=-0.10530738532543182\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:51 INFO 140043348993664] Epoch[15] Batch[5] avg_epoch_loss=-0.063410\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=-0.06340972892940044\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:51 INFO 140043348993664] Epoch[15] Batch [5]#011Speed: 87.02 samples/sec#011loss=-0.063410\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:54 INFO 140043348993664] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740785.937949, \"EndTime\": 1646740794.6287916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8689.479351043701, \"count\": 1, \"min\": 8689.479351043701, \"max\": 8689.479351043701}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:54 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.46431208326865 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:54 INFO 140043348993664] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=15, train loss <loss>=-0.07050523422658443\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:54 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:54 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_857c30c0-4045-4651-b6a1-fa46fca8589e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740794.628923, \"EndTime\": 1646740794.7434187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 113.64006996154785, \"count\": 1, \"min\": 113.64006996154785, \"max\": 113.64006996154785}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:56 INFO 140043348993664] Epoch[16] Batch[0] avg_epoch_loss=-0.150534\u001b[0m\n",
      "\u001b[34m[03/08/2022 11:59:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=-0.15053430199623108\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:00 INFO 140043348993664] Epoch[16] Batch[5] avg_epoch_loss=-0.135394\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=-0.13539394239584604\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:00 INFO 140043348993664] Epoch[16] Batch [5]#011Speed: 87.38 samples/sec#011loss=-0.135394\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] Epoch[16] Batch[10] avg_epoch_loss=-0.150734\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=-0.16914294362068177\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] Epoch[16] Batch [10]#011Speed: 79.73 samples/sec#011loss=-0.169143\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740794.7435343, \"EndTime\": 1646740804.4880655, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9744.444131851196, \"count\": 1, \"min\": 9744.444131851196, \"max\": 9744.444131851196}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.70611703022391 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 4.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=16, train loss <loss>=-0.1507343974980441\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:04 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_4df745de-ce25-4cdd-8e14-61b474cea4c5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740804.4881434, \"EndTime\": 1646740804.6119783, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 123.34418296813965, \"count\": 1, \"min\": 123.34418296813965, \"max\": 123.34418296813965}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:06 INFO 140043348993664] Epoch[17] Batch[0] avg_epoch_loss=-0.140672\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=-0.14067162573337555\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:10 INFO 140043348993664] Epoch[17] Batch[5] avg_epoch_loss=-0.170575\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=-0.17057487865289053\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:10 INFO 140043348993664] Epoch[17] Batch [5]#011Speed: 81.08 samples/sec#011loss=-0.170575\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] Epoch[17] Batch[10] avg_epoch_loss=-0.180493\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=-0.1923956260085106\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] Epoch[17] Batch [10]#011Speed: 83.31 samples/sec#011loss=-0.192396\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740804.6123219, \"EndTime\": 1646740814.673362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10060.858726501465, \"count\": 1, \"min\": 10060.858726501465, \"max\": 10060.858726501465}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.07826280984924 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 4.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=17, train loss <loss>=-0.18049340017817236\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:14 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_c99ceea0-8d7d-4039-a370-0fcb963da5fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740814.6734493, \"EndTime\": 1646740814.7961946, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 122.24292755126953, \"count\": 1, \"min\": 122.24292755126953, \"max\": 122.24292755126953}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:17 INFO 140043348993664] Epoch[18] Batch[0] avg_epoch_loss=-0.168051\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=-0.16805119812488556\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:20 INFO 140043348993664] Epoch[18] Batch[5] avg_epoch_loss=-0.205337\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=-0.2053365558385849\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:20 INFO 140043348993664] Epoch[18] Batch [5]#011Speed: 85.01 samples/sec#011loss=-0.205337\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] Epoch[18] Batch[10] avg_epoch_loss=-0.238307\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=-0.27787146866321566\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] Epoch[18] Batch [10]#011Speed: 89.52 samples/sec#011loss=-0.277871\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740814.7962637, \"EndTime\": 1646740824.3829181, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9586.569786071777, \"count\": 1, \"min\": 9586.569786071777, \"max\": 9586.569786071777}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.48918002868268 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 4.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=18, train loss <loss>=-0.2383069707588716\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:24 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_71e07039-afa3-4e72-b291-faa3f82a5715-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740824.3830152, \"EndTime\": 1646740824.507772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 124.09281730651855, \"count\": 1, \"min\": 124.09281730651855, \"max\": 124.09281730651855}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:26 INFO 140043348993664] Epoch[19] Batch[0] avg_epoch_loss=-0.256323\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=-0.2563226521015167\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:30 INFO 140043348993664] Epoch[19] Batch[5] avg_epoch_loss=-0.271697\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=-0.2716970890760422\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:30 INFO 140043348993664] Epoch[19] Batch [5]#011Speed: 87.96 samples/sec#011loss=-0.271697\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] Epoch[19] Batch[10] avg_epoch_loss=-0.176134\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=-0.06145731369033456\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] Epoch[19] Batch [10]#011Speed: 87.23 samples/sec#011loss=-0.061457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740824.5078652, \"EndTime\": 1646740833.9480858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9440.151453018188, \"count\": 1, \"min\": 9440.151453018188, \"max\": 9440.151453018188}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.44053300107663 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=19, train loss <loss>=-0.17613355480981144\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:36 INFO 140043348993664] Epoch[20] Batch[0] avg_epoch_loss=-0.152183\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=-0.15218298137187958\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:39 INFO 140043348993664] Epoch[20] Batch[5] avg_epoch_loss=-0.178387\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=-0.17838668823242188\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:39 INFO 140043348993664] Epoch[20] Batch [5]#011Speed: 87.47 samples/sec#011loss=-0.178387\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:42 INFO 140043348993664] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740833.9484596, \"EndTime\": 1646740842.8959823, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8946.08998298645, \"count\": 1, \"min\": 8946.08998298645, \"max\": 8946.08998298645}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:42 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.30318157560382 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:42 INFO 140043348993664] #progress_metric: host=algo-1, completed 5.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=20, train loss <loss>=-0.1872543714940548\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:42 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:44 INFO 140043348993664] Epoch[21] Batch[0] avg_epoch_loss=-0.231937\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=-0.2319371998310089\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:48 INFO 140043348993664] Epoch[21] Batch[5] avg_epoch_loss=-0.243785\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=-0.2437849466999372\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:48 INFO 140043348993664] Epoch[21] Batch [5]#011Speed: 88.19 samples/sec#011loss=-0.243785\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] Epoch[21] Batch[10] avg_epoch_loss=-0.276266\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=-0.31524357199668884\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] Epoch[21] Batch [10]#011Speed: 86.10 samples/sec#011loss=-0.315244\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740842.8960547, \"EndTime\": 1646740852.3071926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9410.66837310791, \"count\": 1, \"min\": 9410.66837310791, \"max\": 9410.66837310791}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=73.63896417143974 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] #progress_metric: host=algo-1, completed 5.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=21, train loss <loss>=-0.27626614001664246\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:52 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_abed741c-3d3d-42e5-827b-fb2bca6bf80b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740852.3072672, \"EndTime\": 1646740852.4241886, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 116.43099784851074, \"count\": 1, \"min\": 116.43099784851074, \"max\": 116.43099784851074}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:54 INFO 140043348993664] Epoch[22] Batch[0] avg_epoch_loss=-0.332463\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=-0.3324628174304962\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:58 INFO 140043348993664] Epoch[22] Batch[5] avg_epoch_loss=-0.261471\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=-0.26147084186474484\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:00:58 INFO 140043348993664] Epoch[22] Batch [5]#011Speed: 87.44 samples/sec#011loss=-0.261471\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] Epoch[22] Batch[10] avg_epoch_loss=-0.256768\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=-0.2511253923177719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] Epoch[22] Batch [10]#011Speed: 80.35 samples/sec#011loss=-0.251125\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740852.4242573, \"EndTime\": 1646740862.085976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9661.650896072388, \"count\": 1, \"min\": 9661.650896072388, \"max\": 9661.650896072388}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.31091812026091 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] #progress_metric: host=algo-1, completed 5.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=22, train loss <loss>=-0.25676836479793896\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:02 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:04 INFO 140043348993664] Epoch[23] Batch[0] avg_epoch_loss=-0.292345\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=-0.2923450767993927\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:07 INFO 140043348993664] Epoch[23] Batch[5] avg_epoch_loss=-0.294367\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=-0.29436688373486203\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:07 INFO 140043348993664] Epoch[23] Batch [5]#011Speed: 84.83 samples/sec#011loss=-0.294367\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] Epoch[23] Batch[10] avg_epoch_loss=-0.201839\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=-0.0908056803047657\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] Epoch[23] Batch [10]#011Speed: 82.39 samples/sec#011loss=-0.090806\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740862.0860767, \"EndTime\": 1646740871.8579295, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9770.226955413818, \"count\": 1, \"min\": 9770.226955413818, \"max\": 9770.226955413818}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.92858248797566 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=23, train loss <loss>=-0.20183906399390913\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:11 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:13 INFO 140043348993664] Epoch[24] Batch[0] avg_epoch_loss=-0.219111\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=-0.2191108614206314\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:17 INFO 140043348993664] Epoch[24] Batch[5] avg_epoch_loss=-0.175278\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=-0.1752778304119905\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:17 INFO 140043348993664] Epoch[24] Batch [5]#011Speed: 86.14 samples/sec#011loss=-0.175278\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] Epoch[24] Batch[10] avg_epoch_loss=-0.221541\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=-0.27705734968185425\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] Epoch[24] Batch [10]#011Speed: 85.56 samples/sec#011loss=-0.277057\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740871.8580134, \"EndTime\": 1646740881.4358425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9576.813459396362, \"count\": 1, \"min\": 9576.813459396362, \"max\": 9576.813459396362}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.43514388274743 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] #progress_metric: host=algo-1, completed 6.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=24, train loss <loss>=-0.22154124826192856\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:21 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:23 INFO 140043348993664] Epoch[25] Batch[0] avg_epoch_loss=-0.241583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=-0.24158312380313873\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:27 INFO 140043348993664] Epoch[25] Batch[5] avg_epoch_loss=-0.242757\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=-0.2427565691371759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:27 INFO 140043348993664] Epoch[25] Batch [5]#011Speed: 88.63 samples/sec#011loss=-0.242757\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] Epoch[25] Batch[10] avg_epoch_loss=-0.261515\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=-0.2840256929397583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] Epoch[25] Batch [10]#011Speed: 86.24 samples/sec#011loss=-0.284026\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740881.4362674, \"EndTime\": 1646740890.8956883, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9457.987070083618, \"count\": 1, \"min\": 9457.987070083618, \"max\": 9457.987070083618}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.41580149717048 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] #progress_metric: host=algo-1, completed 6.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=25, train loss <loss>=-0.26151526177471335\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:30 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:32 INFO 140043348993664] Epoch[26] Batch[0] avg_epoch_loss=-0.309813\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=-0.30981338024139404\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:36 INFO 140043348993664] Epoch[26] Batch[5] avg_epoch_loss=-0.265398\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=-0.26539798080921173\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:36 INFO 140043348993664] Epoch[26] Batch [5]#011Speed: 87.11 samples/sec#011loss=-0.265398\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] Epoch[26] Batch[10] avg_epoch_loss=-0.250375\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=-0.23234781473875046\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] Epoch[26] Batch [10]#011Speed: 83.22 samples/sec#011loss=-0.232348\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740890.8957672, \"EndTime\": 1646740900.4617634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9565.332412719727, \"count\": 1, \"min\": 9565.332412719727, \"max\": 9565.332412719727}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.71560696465455 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] #progress_metric: host=algo-1, completed 6.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=26, train loss <loss>=-0.25037517804991116\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:40 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:42 INFO 140043348993664] Epoch[27] Batch[0] avg_epoch_loss=-0.315666\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=-0.31566575169563293\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:46 INFO 140043348993664] Epoch[27] Batch[5] avg_epoch_loss=-0.270417\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=-0.2704165255029996\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:46 INFO 140043348993664] Epoch[27] Batch [5]#011Speed: 88.38 samples/sec#011loss=-0.270417\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] Epoch[27] Batch[10] avg_epoch_loss=-0.290518\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=-0.3146407544612885\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] Epoch[27] Batch [10]#011Speed: 89.42 samples/sec#011loss=-0.314641\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740900.461917, \"EndTime\": 1646740909.7817912, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9319.064855575562, \"count\": 1, \"min\": 9319.064855575562, \"max\": 9319.064855575562}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.390449591556 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=27, train loss <loss>=-0.2905184477567673\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:49 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_04ff5c75-2f06-4102-98e0-35eaf271bc86-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740909.7821267, \"EndTime\": 1646740909.8983846, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 114.88008499145508, \"count\": 1, \"min\": 114.88008499145508, \"max\": 114.88008499145508}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:52 INFO 140043348993664] Epoch[28] Batch[0] avg_epoch_loss=-0.336658\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=-0.3366583287715912\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:55 INFO 140043348993664] Epoch[28] Batch[5] avg_epoch_loss=-0.338084\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=-0.3380841612815857\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:55 INFO 140043348993664] Epoch[28] Batch [5]#011Speed: 87.47 samples/sec#011loss=-0.338084\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] Epoch[28] Batch[10] avg_epoch_loss=-0.375216\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=-0.4197742104530334\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] Epoch[28] Batch [10]#011Speed: 86.97 samples/sec#011loss=-0.419774\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740909.8987703, \"EndTime\": 1646740919.3708, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9471.926212310791, \"count\": 1, \"min\": 9471.926212310791, \"max\": 9471.926212310791}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.98775394144242 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] #progress_metric: host=algo-1, completed 7.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=28, train loss <loss>=-0.37521600181406195\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:01:59 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_53ffe7eb-a335-417b-a44e-49a2d2a4da94-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740919.3711257, \"EndTime\": 1646740919.4895375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 117.01512336730957, \"count\": 1, \"min\": 117.01512336730957, \"max\": 117.01512336730957}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:01 INFO 140043348993664] Epoch[29] Batch[0] avg_epoch_loss=-0.306486\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=-0.30648595094680786\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:05 INFO 140043348993664] Epoch[29] Batch[5] avg_epoch_loss=-0.289457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=-0.2894569933414459\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:05 INFO 140043348993664] Epoch[29] Batch [5]#011Speed: 85.12 samples/sec#011loss=-0.289457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:09 INFO 140043348993664] Epoch[29] Batch[10] avg_epoch_loss=-0.309841\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=-0.3343013107776642\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:09 INFO 140043348993664] Epoch[29] Batch [10]#011Speed: 79.34 samples/sec#011loss=-0.334301\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:10 INFO 140043348993664] processed a total of 710 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740919.4896376, \"EndTime\": 1646740930.1802018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10690.4878616333, \"count\": 1, \"min\": 10690.4878616333, \"max\": 10690.4878616333}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:10 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.41116291417218 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:10 INFO 140043348993664] #progress_metric: host=algo-1, completed 7.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=29, train loss <loss>=-0.3252566655476888\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:10 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:12 INFO 140043348993664] Epoch[30] Batch[0] avg_epoch_loss=-0.204831\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=-0.20483137667179108\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:15 INFO 140043348993664] Epoch[30] Batch[5] avg_epoch_loss=-0.238946\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=-0.23894619196653366\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:15 INFO 140043348993664] Epoch[30] Batch [5]#011Speed: 86.92 samples/sec#011loss=-0.238946\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:19 INFO 140043348993664] Epoch[30] Batch[10] avg_epoch_loss=-0.273833\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=-0.31569730043411254\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:19 INFO 140043348993664] Epoch[30] Batch [10]#011Speed: 82.36 samples/sec#011loss=-0.315697\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:20 INFO 140043348993664] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740930.1806262, \"EndTime\": 1646740940.582766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10400.630235671997, \"count\": 1, \"min\": 10400.630235671997, \"max\": 10400.630235671997}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.97344312425979 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 7.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=30, train loss <loss>=-0.2561614780376355\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:22 INFO 140043348993664] Epoch[31] Batch[0] avg_epoch_loss=-0.309334\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=-0.30933427810668945\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:26 INFO 140043348993664] Epoch[31] Batch[5] avg_epoch_loss=-0.293933\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=-0.2939330115914345\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:26 INFO 140043348993664] Epoch[31] Batch [5]#011Speed: 84.34 samples/sec#011loss=-0.293933\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] Epoch[31] Batch[10] avg_epoch_loss=-0.278457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=-0.25988677740097044\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] Epoch[31] Batch [10]#011Speed: 87.38 samples/sec#011loss=-0.259887\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740940.5832145, \"EndTime\": 1646740950.2580206, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9673.334836959839, \"count\": 1, \"min\": 9673.334836959839, \"max\": 9673.334836959839}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.84608263270518 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=31, train loss <loss>=-0.27845745059576904\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:30 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:32 INFO 140043348993664] Epoch[32] Batch[0] avg_epoch_loss=-0.430731\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=-0.4307308495044708\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:35 INFO 140043348993664] Epoch[32] Batch[5] avg_epoch_loss=-0.374152\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=-0.3741524616877238\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:35 INFO 140043348993664] Epoch[32] Batch [5]#011Speed: 87.58 samples/sec#011loss=-0.374152\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:39 INFO 140043348993664] Epoch[32] Batch[10] avg_epoch_loss=-0.397999\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=-0.4266156077384949\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:39 INFO 140043348993664] Epoch[32] Batch [10]#011Speed: 83.15 samples/sec#011loss=-0.426616\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:40 INFO 140043348993664] processed a total of 713 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740950.258377, \"EndTime\": 1646740960.5702446, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10310.00804901123, \"count\": 1, \"min\": 10310.00804901123, \"max\": 10310.00804901123}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:40 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.15271327288717 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:40 INFO 140043348993664] #progress_metric: host=algo-1, completed 8.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=32, train loss <loss>=-0.41052214801311493\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:40 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:40 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_e027a419-889e-4c0a-9db1-d10fc89a5596-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740960.5707028, \"EndTime\": 1646740960.7082448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 135.97464561462402, \"count\": 1, \"min\": 135.97464561462402, \"max\": 135.97464561462402}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:42 INFO 140043348993664] Epoch[33] Batch[0] avg_epoch_loss=-0.413791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=-0.41379112005233765\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:46 INFO 140043348993664] Epoch[33] Batch[5] avg_epoch_loss=-0.395134\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=-0.3951336046059926\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:46 INFO 140043348993664] Epoch[33] Batch [5]#011Speed: 84.16 samples/sec#011loss=-0.395134\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:49 INFO 140043348993664] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740960.7086756, \"EndTime\": 1646740969.611815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8903.04183959961, \"count\": 1, \"min\": 8903.04183959961, \"max\": 8903.04183959961}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:49 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.5041611794035 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:49 INFO 140043348993664] #progress_metric: host=algo-1, completed 8.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=33, train loss <loss>=-0.43147937655448915\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:49 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:49 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_9af9e943-57bb-418c-a69c-a78d3f339a30-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740969.611891, \"EndTime\": 1646740969.7270162, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 114.61281776428223, \"count\": 1, \"min\": 114.61281776428223, \"max\": 114.61281776428223}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:51 INFO 140043348993664] Epoch[34] Batch[0] avg_epoch_loss=-0.393278\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=-0.3932778239250183\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:55 INFO 140043348993664] Epoch[34] Batch[5] avg_epoch_loss=-0.380259\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=-0.3802589227755864\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:55 INFO 140043348993664] Epoch[34] Batch [5]#011Speed: 88.44 samples/sec#011loss=-0.380259\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] Epoch[34] Batch[10] avg_epoch_loss=-0.389791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=-0.40122872591018677\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] Epoch[34] Batch [10]#011Speed: 84.26 samples/sec#011loss=-0.401229\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740969.727088, \"EndTime\": 1646740979.2255528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9498.397588729858, \"count\": 1, \"min\": 9498.397588729858, \"max\": 9498.397588729858}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.69546346736017 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] #progress_metric: host=algo-1, completed 8.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=34, train loss <loss>=-0.389790651473132\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:02:59 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:01 INFO 140043348993664] Epoch[35] Batch[0] avg_epoch_loss=-0.503218\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=-0.5032177567481995\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:05 INFO 140043348993664] Epoch[35] Batch[5] avg_epoch_loss=-0.411053\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=-0.41105333467324573\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:05 INFO 140043348993664] Epoch[35] Batch [5]#011Speed: 83.47 samples/sec#011loss=-0.411053\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] Epoch[35] Batch[10] avg_epoch_loss=-0.405840\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=-0.399583238363266\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] Epoch[35] Batch [10]#011Speed: 78.90 samples/sec#011loss=-0.399583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740979.225628, \"EndTime\": 1646740989.231275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10005.176305770874, \"count\": 1, \"min\": 10005.176305770874, \"max\": 10005.176305770874}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.46112181435313 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=35, train loss <loss>=-0.4058396545323459\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:09 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:11 INFO 140043348993664] Epoch[36] Batch[0] avg_epoch_loss=-0.487967\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=-0.48796674609184265\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:15 INFO 140043348993664] Epoch[36] Batch[5] avg_epoch_loss=-0.440551\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=-0.4405512313048045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:15 INFO 140043348993664] Epoch[36] Batch [5]#011Speed: 85.81 samples/sec#011loss=-0.440551\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] Epoch[36] Batch[10] avg_epoch_loss=-0.427061\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=-0.4108727514743805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] Epoch[36] Batch [10]#011Speed: 78.40 samples/sec#011loss=-0.410873\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740989.2316399, \"EndTime\": 1646740999.1598334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9925.378322601318, \"count\": 1, \"min\": 9925.378322601318, \"max\": 9925.378322601318}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.91907734825634 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] #progress_metric: host=algo-1, completed 9.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=36, train loss <loss>=-0.4270610132000663\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:19 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:21 INFO 140043348993664] Epoch[37] Batch[0] avg_epoch_loss=-0.415964\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=-0.4159640371799469\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:24 INFO 140043348993664] Epoch[37] Batch[5] avg_epoch_loss=-0.451962\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=-0.451961745818456\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:24 INFO 140043348993664] Epoch[37] Batch [5]#011Speed: 89.07 samples/sec#011loss=-0.451962\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] Epoch[37] Batch[10] avg_epoch_loss=-0.409486\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=-0.35851527452468873\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] Epoch[37] Batch [10]#011Speed: 82.03 samples/sec#011loss=-0.358515\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646740999.1601746, \"EndTime\": 1646741008.8525252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9690.975904464722, \"count\": 1, \"min\": 9690.975904464722, \"max\": 9690.975904464722}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.17498482254152 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 9.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=37, train loss <loss>=-0.40948607704856177\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:31 INFO 140043348993664] Epoch[38] Batch[0] avg_epoch_loss=-0.413094\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=-0.413093626499176\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:34 INFO 140043348993664] Epoch[38] Batch[5] avg_epoch_loss=-0.429048\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=-0.4290477732817332\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:34 INFO 140043348993664] Epoch[38] Batch [5]#011Speed: 88.35 samples/sec#011loss=-0.429048\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:37 INFO 140043348993664] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741008.8526173, \"EndTime\": 1646741017.6644351, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8811.251401901245, \"count\": 1, \"min\": 8811.251401901245, \"max\": 8811.251401901245}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=72.40503589384626 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 9.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=38, train loss <loss>=-0.41626292169094087\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:39 INFO 140043348993664] Epoch[39] Batch[0] avg_epoch_loss=-0.383248\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=-0.3832480013370514\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:43 INFO 140043348993664] Epoch[39] Batch[5] avg_epoch_loss=-0.434987\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=-0.4349868545929591\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:43 INFO 140043348993664] Epoch[39] Batch [5]#011Speed: 90.46 samples/sec#011loss=-0.434987\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] Epoch[39] Batch[10] avg_epoch_loss=-0.426891\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=-0.4171769082546234\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] Epoch[39] Batch [10]#011Speed: 88.49 samples/sec#011loss=-0.417177\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741017.6646852, \"EndTime\": 1646741027.0022342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9336.166620254517, \"count\": 1, \"min\": 9336.166620254517, \"max\": 9336.166620254517}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.7964702720114 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=39, train loss <loss>=-0.42689142443917016\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:47 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:49 INFO 140043348993664] Epoch[40] Batch[0] avg_epoch_loss=-0.500167\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=-0.5001671314239502\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:52 INFO 140043348993664] Epoch[40] Batch[5] avg_epoch_loss=-0.504948\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=-0.5049475034077963\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:52 INFO 140043348993664] Epoch[40] Batch [5]#011Speed: 87.10 samples/sec#011loss=-0.504948\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] Epoch[40] Batch[10] avg_epoch_loss=-0.491216\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=-0.4747376382350922\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] Epoch[40] Batch [10]#011Speed: 85.92 samples/sec#011loss=-0.474738\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741027.002642, \"EndTime\": 1646741036.5236979, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9519.613981246948, \"count\": 1, \"min\": 9519.613981246948, \"max\": 9519.613981246948}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.64861422526106 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] #progress_metric: host=algo-1, completed 10.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=40, train loss <loss>=-0.49121574651111255\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:56 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_eda022fd-5d22-48ac-a22e-5b1a369eb93d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741036.5238035, \"EndTime\": 1646741036.6438243, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 119.34518814086914, \"count\": 1, \"min\": 119.34518814086914, \"max\": 119.34518814086914}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:58 INFO 140043348993664] Epoch[41] Batch[0] avg_epoch_loss=-0.495888\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:03:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=-0.4958876967430115\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:02 INFO 140043348993664] Epoch[41] Batch[5] avg_epoch_loss=-0.414871\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=-0.4148707588513692\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:02 INFO 140043348993664] Epoch[41] Batch [5]#011Speed: 83.17 samples/sec#011loss=-0.414871\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] Epoch[41] Batch[10] avg_epoch_loss=-0.384860\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=-0.3488469272851944\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] Epoch[41] Batch [10]#011Speed: 84.54 samples/sec#011loss=-0.348847\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741036.6441958, \"EndTime\": 1646741046.3768222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9732.535362243652, \"count\": 1, \"min\": 9732.535362243652, \"max\": 9732.535362243652}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.04557258366536 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] #progress_metric: host=algo-1, completed 10.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=41, train loss <loss>=-0.38485992632128974\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:06 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:08 INFO 140043348993664] Epoch[42] Batch[0] avg_epoch_loss=-0.401625\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=-0.4016246199607849\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:12 INFO 140043348993664] Epoch[42] Batch[5] avg_epoch_loss=-0.412522\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=-0.41252201795578003\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:12 INFO 140043348993664] Epoch[42] Batch [5]#011Speed: 85.87 samples/sec#011loss=-0.412522\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] Epoch[42] Batch[10] avg_epoch_loss=-0.414248\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=-0.4163195490837097\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] Epoch[42] Batch [10]#011Speed: 82.92 samples/sec#011loss=-0.416320\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741046.3769526, \"EndTime\": 1646741056.3099172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9932.197332382202, \"count\": 1, \"min\": 9932.197332382202, \"max\": 9932.197332382202}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.4752872497535 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] #progress_metric: host=algo-1, completed 10.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=42, train loss <loss>=-0.41424816846847534\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:16 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:18 INFO 140043348993664] Epoch[43] Batch[0] avg_epoch_loss=-0.458197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=-0.4581967890262604\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:22 INFO 140043348993664] Epoch[43] Batch[5] avg_epoch_loss=-0.430289\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=-0.4302886525789897\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:22 INFO 140043348993664] Epoch[43] Batch [5]#011Speed: 85.28 samples/sec#011loss=-0.430289\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] Epoch[43] Batch[10] avg_epoch_loss=-0.395773\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=-0.3543545871973038\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] Epoch[43] Batch [10]#011Speed: 82.39 samples/sec#011loss=-0.354355\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741056.3102322, \"EndTime\": 1646741066.1759207, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9864.0775680542, \"count\": 1, \"min\": 9864.0775680542, \"max\": 9864.0775680542}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.60321643580968 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=43, train loss <loss>=-0.395773168314587\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:26 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:28 INFO 140043348993664] Epoch[44] Batch[0] avg_epoch_loss=-0.325262\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=-0.32526183128356934\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:32 INFO 140043348993664] Epoch[44] Batch[5] avg_epoch_loss=-0.285346\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=-0.2853463714321454\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:32 INFO 140043348993664] Epoch[44] Batch [5]#011Speed: 86.77 samples/sec#011loss=-0.285346\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] Epoch[44] Batch[10] avg_epoch_loss=-0.327306\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=-0.3776570200920105\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] Epoch[44] Batch [10]#011Speed: 85.51 samples/sec#011loss=-0.377657\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741066.1760068, \"EndTime\": 1646741075.8011913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9623.720407485962, \"count\": 1, \"min\": 9623.720407485962, \"max\": 9623.720407485962}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=72.11046586206214 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 11.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=44, train loss <loss>=-0.3273057571866296\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:37 INFO 140043348993664] Epoch[45] Batch[0] avg_epoch_loss=-0.436763\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=-0.4367629289627075\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:41 INFO 140043348993664] Epoch[45] Batch[5] avg_epoch_loss=-0.431759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=-0.4317592034737269\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:41 INFO 140043348993664] Epoch[45] Batch [5]#011Speed: 87.33 samples/sec#011loss=-0.431759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] Epoch[45] Batch[10] avg_epoch_loss=-0.472196\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=-0.5207194983959198\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] Epoch[45] Batch [10]#011Speed: 84.19 samples/sec#011loss=-0.520719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741075.8015523, \"EndTime\": 1646741085.3840284, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9580.302000045776, \"count\": 1, \"min\": 9580.302000045776, \"max\": 9580.302000045776}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.81116782066228 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] #progress_metric: host=algo-1, completed 11.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=45, train loss <loss>=-0.47219570116563275\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:45 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:47 INFO 140043348993664] Epoch[46] Batch[0] avg_epoch_loss=-0.497568\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=-0.4975675642490387\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:51 INFO 140043348993664] Epoch[46] Batch[5] avg_epoch_loss=-0.437959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=-0.43795904020468396\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:51 INFO 140043348993664] Epoch[46] Batch [5]#011Speed: 87.20 samples/sec#011loss=-0.437959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] Epoch[46] Batch[10] avg_epoch_loss=-0.446146\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=-0.4559714138507843\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] Epoch[46] Batch [10]#011Speed: 84.48 samples/sec#011loss=-0.455971\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741085.3843699, \"EndTime\": 1646741095.0127954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9627.120018005371, \"count\": 1, \"min\": 9627.120018005371, \"max\": 9627.120018005371}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.52902870852192 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 11.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=46, train loss <loss>=-0.4461464827710932\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:57 INFO 140043348993664] Epoch[47] Batch[0] avg_epoch_loss=-0.446964\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:04:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=-0.4469638168811798\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:00 INFO 140043348993664] Epoch[47] Batch[5] avg_epoch_loss=-0.469667\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=-0.46966738998889923\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:00 INFO 140043348993664] Epoch[47] Batch [5]#011Speed: 87.31 samples/sec#011loss=-0.469667\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:04 INFO 140043348993664] Epoch[47] Batch[10] avg_epoch_loss=-0.471351\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=-0.4733717739582062\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:04 INFO 140043348993664] Epoch[47] Batch [10]#011Speed: 80.25 samples/sec#011loss=-0.473372\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:05 INFO 140043348993664] processed a total of 713 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741095.0128767, \"EndTime\": 1646741105.543505, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10530.121803283691, \"count\": 1, \"min\": 10530.121803283691, \"max\": 10530.121803283691}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:05 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.7096777056577 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:05 INFO 140043348993664] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=47, train loss <loss>=-0.471909262239933\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:05 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:07 INFO 140043348993664] Epoch[48] Batch[0] avg_epoch_loss=-0.450159\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=-0.4501585364341736\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:11 INFO 140043348993664] Epoch[48] Batch[5] avg_epoch_loss=-0.420059\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=-0.4200591544310252\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:11 INFO 140043348993664] Epoch[48] Batch [5]#011Speed: 84.98 samples/sec#011loss=-0.420059\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] Epoch[48] Batch[10] avg_epoch_loss=-0.427095\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=-0.43553770184516905\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] Epoch[48] Batch [10]#011Speed: 84.78 samples/sec#011loss=-0.435538\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741105.5435894, \"EndTime\": 1646741115.3684404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9819.041967391968, \"count\": 1, \"min\": 9819.041967391968, \"max\": 9819.041967391968}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.06548063407769 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] #progress_metric: host=algo-1, completed 12.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=48, train loss <loss>=-0.4270948578010906\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:15 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:17 INFO 140043348993664] Epoch[49] Batch[0] avg_epoch_loss=-0.473299\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=-0.4732987880706787\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:21 INFO 140043348993664] Epoch[49] Batch[5] avg_epoch_loss=-0.497796\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=-0.49779626727104187\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:21 INFO 140043348993664] Epoch[49] Batch [5]#011Speed: 85.59 samples/sec#011loss=-0.497796\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] Epoch[49] Batch[10] avg_epoch_loss=-0.525975\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=-0.5597886919975281\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] Epoch[49] Batch [10]#011Speed: 82.23 samples/sec#011loss=-0.559789\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741115.368732, \"EndTime\": 1646741125.2670848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9897.074222564697, \"count\": 1, \"min\": 9897.074222564697, \"max\": 9897.074222564697}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.9763374298983 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=49, train loss <loss>=-0.5259746421467174\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:25 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_359e1e7c-e92e-4cfb-b113-010a56c90c96-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741125.2674565, \"EndTime\": 1646741125.3943899, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 125.32496452331543, \"count\": 1, \"min\": 125.32496452331543, \"max\": 125.32496452331543}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:27 INFO 140043348993664] Epoch[50] Batch[0] avg_epoch_loss=-0.527662\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=-0.527662456035614\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:31 INFO 140043348993664] Epoch[50] Batch[5] avg_epoch_loss=-0.412686\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=-0.4126858462889989\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:31 INFO 140043348993664] Epoch[50] Batch [5]#011Speed: 89.62 samples/sec#011loss=-0.412686\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] Epoch[50] Batch[10] avg_epoch_loss=-0.421002\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=-0.4309816837310791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] Epoch[50] Batch [10]#011Speed: 85.56 samples/sec#011loss=-0.430982\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741125.394836, \"EndTime\": 1646741134.8286963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9433.779954910278, \"count\": 1, \"min\": 9433.779954910278, \"max\": 9433.779954910278}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.70186538288667 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] #progress_metric: host=algo-1, completed 12.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=50, train loss <loss>=-0.421002136035399\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:34 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:36 INFO 140043348993664] Epoch[51] Batch[0] avg_epoch_loss=-0.341189\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=-0.3411886990070343\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:40 INFO 140043348993664] Epoch[51] Batch[5] avg_epoch_loss=-0.459317\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=-0.4593170831600825\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:40 INFO 140043348993664] Epoch[51] Batch [5]#011Speed: 87.44 samples/sec#011loss=-0.459317\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] Epoch[51] Batch[10] avg_epoch_loss=-0.484233\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=-0.5141325950622558\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] Epoch[51] Batch [10]#011Speed: 85.15 samples/sec#011loss=-0.514133\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741134.8288548, \"EndTime\": 1646741144.3316538, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9501.67965888977, \"count\": 1, \"min\": 9501.67965888977, \"max\": 9501.67965888977}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.98419441008576 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=51, train loss <loss>=-0.48423322493379767\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:46 INFO 140043348993664] Epoch[52] Batch[0] avg_epoch_loss=-0.527368\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=-0.5273684859275818\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:50 INFO 140043348993664] Epoch[52] Batch[5] avg_epoch_loss=-0.484862\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=-0.4848615725835164\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:50 INFO 140043348993664] Epoch[52] Batch [5]#011Speed: 85.68 samples/sec#011loss=-0.484862\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] Epoch[52] Batch[10] avg_epoch_loss=-0.478548\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=-0.47097140550613403\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] Epoch[52] Batch [10]#011Speed: 84.99 samples/sec#011loss=-0.470971\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741144.3320258, \"EndTime\": 1646741154.002073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9668.580532073975, \"count\": 1, \"min\": 9668.580532073975, \"max\": 9668.580532073975}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.01856599730023 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] #progress_metric: host=algo-1, completed 13.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=52, train loss <loss>=-0.47854786027561536\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:54 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:56 INFO 140043348993664] Epoch[53] Batch[0] avg_epoch_loss=-0.495390\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=-0.49538999795913696\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:59 INFO 140043348993664] Epoch[53] Batch[5] avg_epoch_loss=-0.344133\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=-0.3441334751745065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:05:59 INFO 140043348993664] Epoch[53] Batch [5]#011Speed: 86.85 samples/sec#011loss=-0.344133\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] Epoch[53] Batch[10] avg_epoch_loss=-0.363085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=-0.3858260869979858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] Epoch[53] Batch [10]#011Speed: 81.49 samples/sec#011loss=-0.385826\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741154.0024097, \"EndTime\": 1646741163.8436775, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9839.949131011963, \"count\": 1, \"min\": 9839.949131011963, \"max\": 9839.949131011963}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.27479168439417 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] #progress_metric: host=algo-1, completed 13.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=53, train loss <loss>=-0.3630846623669971\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:03 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:06 INFO 140043348993664] Epoch[54] Batch[0] avg_epoch_loss=-0.309235\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=-0.309234619140625\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:09 INFO 140043348993664] Epoch[54] Batch[5] avg_epoch_loss=-0.464309\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=-0.46430932482083637\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:09 INFO 140043348993664] Epoch[54] Batch [5]#011Speed: 81.37 samples/sec#011loss=-0.464309\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] Epoch[54] Batch[10] avg_epoch_loss=-0.483650\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=-0.5068584978580475\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] Epoch[54] Batch [10]#011Speed: 85.18 samples/sec#011loss=-0.506858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741163.8437665, \"EndTime\": 1646741173.7203767, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9875.531196594238, \"count\": 1, \"min\": 9875.531196594238, \"max\": 9875.531196594238}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.94258410815257 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 13.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=54, train loss <loss>=-0.4836498580195687\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:16 INFO 140043348993664] Epoch[55] Batch[0] avg_epoch_loss=-0.319047\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=-0.3190467059612274\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:19 INFO 140043348993664] Epoch[55] Batch[5] avg_epoch_loss=-0.397625\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=-0.39762525757153827\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:19 INFO 140043348993664] Epoch[55] Batch [5]#011Speed: 86.93 samples/sec#011loss=-0.397625\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:22 INFO 140043348993664] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741173.7207837, \"EndTime\": 1646741182.6239657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8901.75747871399, \"count\": 1, \"min\": 8901.75747871399, \"max\": 8901.75747871399}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.75806549151201 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=55, train loss <loss>=-0.41624694168567655\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:24 INFO 140043348993664] Epoch[56] Batch[0] avg_epoch_loss=-0.510276\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=-0.5102760195732117\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:28 INFO 140043348993664] Epoch[56] Batch[5] avg_epoch_loss=-0.528103\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=-0.5281034161647161\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:28 INFO 140043348993664] Epoch[56] Batch [5]#011Speed: 86.82 samples/sec#011loss=-0.528103\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] Epoch[56] Batch[10] avg_epoch_loss=-0.533188\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=-0.539289915561676\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] Epoch[56] Batch [10]#011Speed: 86.93 samples/sec#011loss=-0.539290\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741182.6243567, \"EndTime\": 1646741192.1352823, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9509.456157684326, \"count\": 1, \"min\": 9509.456157684326, \"max\": 9509.456157684326}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.24454692463327 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] #progress_metric: host=algo-1, completed 14.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=56, train loss <loss>=-0.5331881886178796\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:32 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_109fe391-d2ac-44f2-b999-34e9553dba06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741192.1354067, \"EndTime\": 1646741192.253686, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 117.4776554107666, \"count\": 1, \"min\": 117.4776554107666, \"max\": 117.4776554107666}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:34 INFO 140043348993664] Epoch[57] Batch[0] avg_epoch_loss=-0.512267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=-0.5122665166854858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:38 INFO 140043348993664] Epoch[57] Batch[5] avg_epoch_loss=-0.513423\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=-0.5134228219588598\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:38 INFO 140043348993664] Epoch[57] Batch [5]#011Speed: 87.63 samples/sec#011loss=-0.513423\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] Epoch[57] Batch[10] avg_epoch_loss=-0.519198\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=-0.5261292099952698\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] Epoch[57] Batch [10]#011Speed: 84.81 samples/sec#011loss=-0.526129\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741192.2538197, \"EndTime\": 1646741201.777819, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9523.90432357788, \"count\": 1, \"min\": 9523.90432357788, \"max\": 9523.90432357788}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.76619891239334 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 14.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=57, train loss <loss>=-0.5191984528845007\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:41 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:43 INFO 140043348993664] Epoch[58] Batch[0] avg_epoch_loss=-0.491300\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=-0.49129998683929443\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:47 INFO 140043348993664] Epoch[58] Batch[5] avg_epoch_loss=-0.440967\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=-0.4409674157698949\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:47 INFO 140043348993664] Epoch[58] Batch [5]#011Speed: 86.96 samples/sec#011loss=-0.440967\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] Epoch[58] Batch[10] avg_epoch_loss=-0.466771\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=-0.49773573875427246\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] Epoch[58] Batch [10]#011Speed: 83.48 samples/sec#011loss=-0.497736\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741201.7781909, \"EndTime\": 1646741211.430791, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9651.133298873901, \"count\": 1, \"min\": 9651.133298873901, \"max\": 9651.133298873901}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.56022160533982 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] #progress_metric: host=algo-1, completed 14.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=58, train loss <loss>=-0.466771198944612\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:51 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:53 INFO 140043348993664] Epoch[59] Batch[0] avg_epoch_loss=-0.395142\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=-0.39514151215553284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:57 INFO 140043348993664] Epoch[59] Batch[5] avg_epoch_loss=-0.475247\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=-0.47524667779604596\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:06:57 INFO 140043348993664] Epoch[59] Batch [5]#011Speed: 86.90 samples/sec#011loss=-0.475247\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:00 INFO 140043348993664] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741211.4308832, \"EndTime\": 1646741220.3684587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8936.701536178589, \"count\": 1, \"min\": 8936.701536178589, \"max\": 8936.701536178589}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:00 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.59974162648433 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:00 INFO 140043348993664] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=59, train loss <loss>=-0.48552100658416747\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:00 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:02 INFO 140043348993664] Epoch[60] Batch[0] avg_epoch_loss=-0.470700\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=-0.4706999361515045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:06 INFO 140043348993664] Epoch[60] Batch[5] avg_epoch_loss=-0.528133\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=-0.5281333277622858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:06 INFO 140043348993664] Epoch[60] Batch [5]#011Speed: 84.91 samples/sec#011loss=-0.528133\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] Epoch[60] Batch[10] avg_epoch_loss=-0.552531\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=-0.5818087458610535\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] Epoch[60] Batch [10]#011Speed: 78.97 samples/sec#011loss=-0.581809\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741220.3685353, \"EndTime\": 1646741230.468418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10099.37834739685, \"count\": 1, \"min\": 10099.37834739685, \"max\": 10099.37834739685}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.348708805948 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] #progress_metric: host=algo-1, completed 15.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=60, train loss <loss>=-0.5525312450799075\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:10 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_b99f4891-0faa-44c4-84b1-bec43b5f99f4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741230.4685073, \"EndTime\": 1646741230.5944462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 124.47929382324219, \"count\": 1, \"min\": 124.47929382324219, \"max\": 124.47929382324219}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:12 INFO 140043348993664] Epoch[61] Batch[0] avg_epoch_loss=-0.582582\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=-0.5825822353363037\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:16 INFO 140043348993664] Epoch[61] Batch[5] avg_epoch_loss=-0.499793\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=-0.49979256093502045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:16 INFO 140043348993664] Epoch[61] Batch [5]#011Speed: 86.36 samples/sec#011loss=-0.499793\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:19 INFO 140043348993664] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741230.5948155, \"EndTime\": 1646741239.5541332, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8959.209203720093, \"count\": 1, \"min\": 8959.209203720093, \"max\": 8959.209203720093}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:19 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.65249678863105 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:19 INFO 140043348993664] #progress_metric: host=algo-1, completed 15.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=61, train loss <loss>=-0.49144303798675537\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:19 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:21 INFO 140043348993664] Epoch[62] Batch[0] avg_epoch_loss=-0.557398\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=-0.5573977828025818\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:25 INFO 140043348993664] Epoch[62] Batch[5] avg_epoch_loss=-0.541332\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=-0.5413320809602737\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:25 INFO 140043348993664] Epoch[62] Batch [5]#011Speed: 86.31 samples/sec#011loss=-0.541332\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] Epoch[62] Batch[10] avg_epoch_loss=-0.553521\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=-0.5681477308273315\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] Epoch[62] Batch [10]#011Speed: 85.15 samples/sec#011loss=-0.568148\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741239.554214, \"EndTime\": 1646741249.274173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9719.280242919922, \"count\": 1, \"min\": 9719.280242919922, \"max\": 9719.280242919922}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.59450904481977 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] #progress_metric: host=algo-1, completed 15.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=62, train loss <loss>=-0.5535210127180273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:29 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_af33b561-80b2-4996-acef-1e6e904a1efb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741249.274559, \"EndTime\": 1646741249.391281, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.28801918029785, \"count\": 1, \"min\": 115.28801918029785, \"max\": 115.28801918029785}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:31 INFO 140043348993664] Epoch[63] Batch[0] avg_epoch_loss=-0.367341\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=-0.36734074354171753\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:35 INFO 140043348993664] Epoch[63] Batch[5] avg_epoch_loss=-0.490454\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=-0.4904543509085973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:35 INFO 140043348993664] Epoch[63] Batch [5]#011Speed: 85.62 samples/sec#011loss=-0.490454\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] Epoch[63] Batch[10] avg_epoch_loss=-0.489552\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=-0.48846831917762756\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] Epoch[63] Batch [10]#011Speed: 84.16 samples/sec#011loss=-0.488468\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741249.3917081, \"EndTime\": 1646741259.035014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9643.210887908936, \"count\": 1, \"min\": 9643.210887908936, \"max\": 9643.210887908936}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.54469810080374 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=63, train loss <loss>=-0.48955160921270197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:41 INFO 140043348993664] Epoch[64] Batch[0] avg_epoch_loss=-0.467340\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=-0.4673396348953247\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:44 INFO 140043348993664] Epoch[64] Batch[5] avg_epoch_loss=-0.507487\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=-0.5074867208798727\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:44 INFO 140043348993664] Epoch[64] Batch [5]#011Speed: 87.70 samples/sec#011loss=-0.507487\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] Epoch[64] Batch[10] avg_epoch_loss=-0.530099\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=-0.5572335898876191\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] Epoch[64] Batch [10]#011Speed: 84.98 samples/sec#011loss=-0.557234\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741259.0351021, \"EndTime\": 1646741268.6354814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9599.026203155518, \"count\": 1, \"min\": 9599.026203155518, \"max\": 9599.026203155518}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.92069042759503 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 16.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=64, train loss <loss>=-0.5300989340652119\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:50 INFO 140043348993664] Epoch[65] Batch[0] avg_epoch_loss=-0.455150\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=-0.4551504850387573\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:54 INFO 140043348993664] Epoch[65] Batch[5] avg_epoch_loss=-0.447199\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=-0.44719897707303363\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:54 INFO 140043348993664] Epoch[65] Batch [5]#011Speed: 85.33 samples/sec#011loss=-0.447199\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] Epoch[65] Batch[10] avg_epoch_loss=-0.480622\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=-0.5207294523715973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] Epoch[65] Batch [10]#011Speed: 85.14 samples/sec#011loss=-0.520729\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741268.6358254, \"EndTime\": 1646741278.3391826, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9702.035427093506, \"count\": 1, \"min\": 9702.035427093506, \"max\": 9702.035427093506}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.43825988251352 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] #progress_metric: host=algo-1, completed 16.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=65, train loss <loss>=-0.48062192039056256\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:07:58 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:00 INFO 140043348993664] Epoch[66] Batch[0] avg_epoch_loss=-0.570316\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=-0.5703155398368835\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:04 INFO 140043348993664] Epoch[66] Batch[5] avg_epoch_loss=-0.575149\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=-0.5751489202181498\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:04 INFO 140043348993664] Epoch[66] Batch [5]#011Speed: 81.84 samples/sec#011loss=-0.575149\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:07 INFO 140043348993664] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741278.339284, \"EndTime\": 1646741287.6279857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9288.069248199463, \"count\": 1, \"min\": 9288.069248199463, \"max\": 9288.069248199463}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.93565055699102 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 16.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=66, train loss <loss>=-0.576518428325653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:07 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:07 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_c27939ce-edca-4c38-8a77-e865fd6f8506-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741287.628076, \"EndTime\": 1646741287.742445, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 113.7700080871582, \"count\": 1, \"min\": 113.7700080871582, \"max\": 113.7700080871582}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:09 INFO 140043348993664] Epoch[67] Batch[0] avg_epoch_loss=-0.606576\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=-0.6065759658813477\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:13 INFO 140043348993664] Epoch[67] Batch[5] avg_epoch_loss=-0.607775\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=-0.6077747444311777\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:13 INFO 140043348993664] Epoch[67] Batch [5]#011Speed: 89.08 samples/sec#011loss=-0.607775\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] Epoch[67] Batch[10] avg_epoch_loss=-0.620250\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=-0.6352208614349365\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] Epoch[67] Batch [10]#011Speed: 83.30 samples/sec#011loss=-0.635221\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741287.7425144, \"EndTime\": 1646741297.340577, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9597.99575805664, \"count\": 1, \"min\": 9597.99575805664, \"max\": 9597.99575805664}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.68079513963427 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=67, train loss <loss>=-0.620250252160159\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:17 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_a225b094-ddd3-4b7f-9525-003d639af6be-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741297.3406537, \"EndTime\": 1646741297.46099, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 119.83394622802734, \"count\": 1, \"min\": 119.83394622802734, \"max\": 119.83394622802734}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:19 INFO 140043348993664] Epoch[68] Batch[0] avg_epoch_loss=-0.629083\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=-0.6290827393531799\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:23 INFO 140043348993664] Epoch[68] Batch[5] avg_epoch_loss=-0.614163\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=-0.6141627828280131\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:23 INFO 140043348993664] Epoch[68] Batch [5]#011Speed: 87.26 samples/sec#011loss=-0.614163\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] Epoch[68] Batch[10] avg_epoch_loss=-0.611459\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=-0.6082141399383545\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] Epoch[68] Batch [10]#011Speed: 83.52 samples/sec#011loss=-0.608214\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741297.4611015, \"EndTime\": 1646741307.1026585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9641.48497581482, \"count\": 1, \"min\": 9641.48497581482, \"max\": 9641.48497581482}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.96996871934266 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] #progress_metric: host=algo-1, completed 17.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=68, train loss <loss>=-0.6114588542418047\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:27 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:29 INFO 140043348993664] Epoch[69] Batch[0] avg_epoch_loss=-0.513675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=-0.5136749744415283\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:33 INFO 140043348993664] Epoch[69] Batch[5] avg_epoch_loss=-0.548759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=-0.5487587799628576\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:33 INFO 140043348993664] Epoch[69] Batch [5]#011Speed: 85.00 samples/sec#011loss=-0.548759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:36 INFO 140043348993664] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741307.1030111, \"EndTime\": 1646741316.0355425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8931.205987930298, \"count\": 1, \"min\": 8931.205987930298, \"max\": 8931.205987930298}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.09784023652449 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 17.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=69, train loss <loss>=-0.538219827413559\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:36 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:38 INFO 140043348993664] Epoch[70] Batch[0] avg_epoch_loss=-0.669455\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=-0.6694547533988953\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:41 INFO 140043348993664] Epoch[70] Batch[5] avg_epoch_loss=-0.548673\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=-0.548672616481781\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:41 INFO 140043348993664] Epoch[70] Batch [5]#011Speed: 87.20 samples/sec#011loss=-0.548673\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] Epoch[70] Batch[10] avg_epoch_loss=-0.549726\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=-0.5509903132915497\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] Epoch[70] Batch [10]#011Speed: 87.16 samples/sec#011loss=-0.550990\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741316.035653, \"EndTime\": 1646741325.5625029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9526.116371154785, \"count\": 1, \"min\": 9526.116371154785, \"max\": 9526.116371154785}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.38531016074045 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] #progress_metric: host=algo-1, completed 17.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=70, train loss <loss>=-0.5497261150316759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:45 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:47 INFO 140043348993664] Epoch[71] Batch[0] avg_epoch_loss=-0.557637\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=-0.5576373338699341\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:51 INFO 140043348993664] Epoch[71] Batch[5] avg_epoch_loss=-0.555137\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=-0.5551371475060781\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:51 INFO 140043348993664] Epoch[71] Batch [5]#011Speed: 87.96 samples/sec#011loss=-0.555137\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] Epoch[71] Batch[10] avg_epoch_loss=-0.553262\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=-0.5510108888149261\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] Epoch[71] Batch [10]#011Speed: 84.33 samples/sec#011loss=-0.551011\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741325.562841, \"EndTime\": 1646741335.1183157, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9554.157257080078, \"count\": 1, \"min\": 9554.157257080078, \"max\": 9554.157257080078}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=72.00753133278833 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=71, train loss <loss>=-0.5532615753737363\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:57 INFO 140043348993664] Epoch[72] Batch[0] avg_epoch_loss=-0.448675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:08:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=-0.4486752152442932\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:00 INFO 140043348993664] Epoch[72] Batch[5] avg_epoch_loss=-0.525578\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=-0.5255775650342306\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:00 INFO 140043348993664] Epoch[72] Batch [5]#011Speed: 86.64 samples/sec#011loss=-0.525578\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] Epoch[72] Batch[10] avg_epoch_loss=-0.565873\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=-0.614228117465973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] Epoch[72] Batch [10]#011Speed: 76.51 samples/sec#011loss=-0.614228\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741335.1186652, \"EndTime\": 1646741345.1335032, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10013.516426086426, \"count\": 1, \"min\": 10013.516426086426, \"max\": 10013.516426086426}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.90606848307637 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] #progress_metric: host=algo-1, completed 18.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=72, train loss <loss>=-0.5658732706850226\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:05 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:07 INFO 140043348993664] Epoch[73] Batch[0] avg_epoch_loss=-0.651256\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=-0.6512560844421387\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:11 INFO 140043348993664] Epoch[73] Batch[5] avg_epoch_loss=-0.617283\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=-0.6172834038734436\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:11 INFO 140043348993664] Epoch[73] Batch [5]#011Speed: 79.05 samples/sec#011loss=-0.617283\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] Epoch[73] Batch[10] avg_epoch_loss=-0.622516\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=-0.6287952423095703\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] Epoch[73] Batch [10]#011Speed: 80.41 samples/sec#011loss=-0.628795\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741345.1335802, \"EndTime\": 1646741355.4150224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10280.989170074463, \"count\": 1, \"min\": 10280.989170074463, \"max\": 10280.989170074463}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.52964986515293 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] #progress_metric: host=algo-1, completed 18.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=73, train loss <loss>=-0.6225160577080466\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:15 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_3d9d6ba4-9bc1-4ece-9c39-ce80ac33566c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741355.4151263, \"EndTime\": 1646741355.5455182, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 129.24695014953613, \"count\": 1, \"min\": 129.24695014953613, \"max\": 129.24695014953613}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:17 INFO 140043348993664] Epoch[74] Batch[0] avg_epoch_loss=-0.652211\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=-0.65221107006073\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:21 INFO 140043348993664] Epoch[74] Batch[5] avg_epoch_loss=-0.650842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=-0.6508417725563049\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:21 INFO 140043348993664] Epoch[74] Batch [5]#011Speed: 82.55 samples/sec#011loss=-0.650842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:25 INFO 140043348993664] Epoch[74] Batch[10] avg_epoch_loss=-0.639886\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=-0.6267385005950927\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:25 INFO 140043348993664] Epoch[74] Batch [10]#011Speed: 79.02 samples/sec#011loss=-0.626739\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:26 INFO 140043348993664] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741355.545626, \"EndTime\": 1646741366.562875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11016.910552978516, \"count\": 1, \"min\": 11016.910552978516, \"max\": 11016.910552978516}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.26148341532952 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 18.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=74, train loss <loss>=-0.6309624711672465\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:26 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:26 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_db02bd84-8a29-4d39-a9ec-70b34fd4a8f8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741366.563319, \"EndTime\": 1646741366.6839275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 118.9720630645752, \"count\": 1, \"min\": 118.9720630645752, \"max\": 118.9720630645752}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:28 INFO 140043348993664] Epoch[75] Batch[0] avg_epoch_loss=-0.665012\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=-0.6650118231773376\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:32 INFO 140043348993664] Epoch[75] Batch[5] avg_epoch_loss=-0.640745\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=-0.6407451033592224\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:32 INFO 140043348993664] Epoch[75] Batch [5]#011Speed: 81.50 samples/sec#011loss=-0.640745\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] Epoch[75] Batch[10] avg_epoch_loss=-0.653923\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=-0.6697366118431092\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] Epoch[75] Batch [10]#011Speed: 72.51 samples/sec#011loss=-0.669737\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741366.6842291, \"EndTime\": 1646741377.1561697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10471.8496799469, \"count\": 1, \"min\": 10471.8496799469, \"max\": 10471.8496799469}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.215398932298015 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=75, train loss <loss>=-0.6539230617609891\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:37 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_5cd25122-7821-40e5-bb88-c0a971f136eb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741377.1562526, \"EndTime\": 1646741377.274738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 117.03968048095703, \"count\": 1, \"min\": 117.03968048095703, \"max\": 117.03968048095703}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:39 INFO 140043348993664] Epoch[76] Batch[0] avg_epoch_loss=-0.655680\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=-0.6556801795959473\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:43 INFO 140043348993664] Epoch[76] Batch[5] avg_epoch_loss=-0.578922\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=-0.5789219538370768\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:43 INFO 140043348993664] Epoch[76] Batch [5]#011Speed: 82.81 samples/sec#011loss=-0.578922\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] Epoch[76] Batch[10] avg_epoch_loss=-0.609817\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=-0.646890377998352\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] Epoch[76] Batch [10]#011Speed: 78.01 samples/sec#011loss=-0.646890\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741377.2748318, \"EndTime\": 1646741387.4740853, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10199.00131225586, \"count\": 1, \"min\": 10199.00131225586, \"max\": 10199.00131225586}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.33706279301664 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] #progress_metric: host=algo-1, completed 19.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=76, train loss <loss>=-0.6098166920922019\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:47 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:49 INFO 140043348993664] Epoch[77] Batch[0] avg_epoch_loss=-0.633121\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=-0.633120596408844\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:53 INFO 140043348993664] Epoch[77] Batch[5] avg_epoch_loss=-0.647005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=-0.6470051805178324\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:53 INFO 140043348993664] Epoch[77] Batch [5]#011Speed: 85.25 samples/sec#011loss=-0.647005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] Epoch[77] Batch[10] avg_epoch_loss=-0.637851\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=-0.6268659949302673\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] Epoch[77] Batch [10]#011Speed: 80.28 samples/sec#011loss=-0.626866\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741387.4744883, \"EndTime\": 1646741397.356997, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9881.115913391113, \"count\": 1, \"min\": 9881.115913391113, \"max\": 9881.115913391113}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.13262832330126 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 19.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=77, train loss <loss>=-0.6378510052507574\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:59 INFO 140043348993664] Epoch[78] Batch[0] avg_epoch_loss=-0.642485\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:09:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=-0.6424847841262817\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:03 INFO 140043348993664] Epoch[78] Batch[5] avg_epoch_loss=-0.637793\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=-0.6377930541833242\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:03 INFO 140043348993664] Epoch[78] Batch [5]#011Speed: 78.88 samples/sec#011loss=-0.637793\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] Epoch[78] Batch[10] avg_epoch_loss=-0.660429\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=-0.6875916957855225\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] Epoch[78] Batch [10]#011Speed: 76.70 samples/sec#011loss=-0.687592\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741397.3570929, \"EndTime\": 1646741407.7946875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10436.939001083374, \"count\": 1, \"min\": 10436.939001083374, \"max\": 10436.939001083374}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.52366717416487 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 19.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=78, train loss <loss>=-0.6604288003661416\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:07 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_6a052b8a-9dd7-45f7-bc38-28307424260c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741407.7947662, \"EndTime\": 1646741407.951417, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 156.13985061645508, \"count\": 1, \"min\": 156.13985061645508, \"max\": 156.13985061645508}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:10 INFO 140043348993664] Epoch[79] Batch[0] avg_epoch_loss=-0.685711\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=-0.6857113242149353\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:14 INFO 140043348993664] Epoch[79] Batch[5] avg_epoch_loss=-0.669587\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=-0.6695869366327921\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:14 INFO 140043348993664] Epoch[79] Batch [5]#011Speed: 83.00 samples/sec#011loss=-0.669587\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] Epoch[79] Batch[10] avg_epoch_loss=-0.663968\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=-0.6572256684303284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] Epoch[79] Batch [10]#011Speed: 82.47 samples/sec#011loss=-0.657226\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741407.9514894, \"EndTime\": 1646741417.931441, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9979.875564575195, \"count\": 1, \"min\": 9979.875564575195, \"max\": 9979.875564575195}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.33078426188645 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=79, train loss <loss>=-0.663968178358945\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:17 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:18 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_464cd53d-87c3-4204-b9a2-8d6246e5e895-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741417.931804, \"EndTime\": 1646741418.0521138, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 118.89338493347168, \"count\": 1, \"min\": 118.89338493347168, \"max\": 118.89338493347168}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:20 INFO 140043348993664] Epoch[80] Batch[0] avg_epoch_loss=-0.613632\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=-0.613632082939148\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:24 INFO 140043348993664] Epoch[80] Batch[5] avg_epoch_loss=-0.566927\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=-0.566927413145701\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:24 INFO 140043348993664] Epoch[80] Batch [5]#011Speed: 82.90 samples/sec#011loss=-0.566927\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] Epoch[80] Batch[10] avg_epoch_loss=-0.585805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=-0.6084590673446655\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] Epoch[80] Batch [10]#011Speed: 83.75 samples/sec#011loss=-0.608459\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741418.0524924, \"EndTime\": 1646741428.006104, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9953.510761260986, \"count\": 1, \"min\": 9953.510761260986, \"max\": 9953.510761260986}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.80769131091343 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 20.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=80, train loss <loss>=-0.585805437781594\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:30 INFO 140043348993664] Epoch[81] Batch[0] avg_epoch_loss=-0.661487\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=-0.6614866256713867\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:33 INFO 140043348993664] Epoch[81] Batch[5] avg_epoch_loss=-0.575003\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=-0.5750028441349665\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:33 INFO 140043348993664] Epoch[81] Batch [5]#011Speed: 86.41 samples/sec#011loss=-0.575003\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] Epoch[81] Batch[10] avg_epoch_loss=-0.580748\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=-0.5876425385475159\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] Epoch[81] Batch [10]#011Speed: 84.52 samples/sec#011loss=-0.587643\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741428.0064914, \"EndTime\": 1646741437.6892748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9681.498289108276, \"count\": 1, \"min\": 9681.498289108276, \"max\": 9681.498289108276}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.72396217623238 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 20.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=81, train loss <loss>=-0.5807481597770344\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:39 INFO 140043348993664] Epoch[82] Batch[0] avg_epoch_loss=-0.565928\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=-0.5659278631210327\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:43 INFO 140043348993664] Epoch[82] Batch[5] avg_epoch_loss=-0.600765\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=-0.6007654865582784\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:43 INFO 140043348993664] Epoch[82] Batch [5]#011Speed: 86.18 samples/sec#011loss=-0.600765\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] Epoch[82] Batch[10] avg_epoch_loss=-0.628139\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=-0.6609875082969665\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] Epoch[82] Batch [10]#011Speed: 81.02 samples/sec#011loss=-0.660988\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741437.6894145, \"EndTime\": 1646741447.4561543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9766.042947769165, \"count\": 1, \"min\": 9766.042947769165, \"max\": 9766.042947769165}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.16352448146816 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] #progress_metric: host=algo-1, completed 20.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=82, train loss <loss>=-0.6281391328031366\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:47 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:49 INFO 140043348993664] Epoch[83] Batch[0] avg_epoch_loss=-0.625618\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=-0.6256183385848999\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:53 INFO 140043348993664] Epoch[83] Batch[5] avg_epoch_loss=-0.602292\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=-0.602292130390803\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:53 INFO 140043348993664] Epoch[83] Batch [5]#011Speed: 86.44 samples/sec#011loss=-0.602292\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] Epoch[83] Batch[10] avg_epoch_loss=-0.643766\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=-0.6935349762439728\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] Epoch[83] Batch [10]#011Speed: 84.58 samples/sec#011loss=-0.693535\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741447.4563096, \"EndTime\": 1646741457.154196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9696.74015045166, \"count\": 1, \"min\": 9696.74015045166, \"max\": 9696.74015045166}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.10195773057627 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=83, train loss <loss>=-0.643766151233153\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:59 INFO 140043348993664] Epoch[84] Batch[0] avg_epoch_loss=-0.586283\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:10:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=-0.586283266544342\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:03 INFO 140043348993664] Epoch[84] Batch[5] avg_epoch_loss=-0.565650\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=-0.5656504432360331\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:03 INFO 140043348993664] Epoch[84] Batch [5]#011Speed: 78.29 samples/sec#011loss=-0.565650\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] Epoch[84] Batch[10] avg_epoch_loss=-0.594719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=-0.6296021640300751\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] Epoch[84] Batch [10]#011Speed: 82.41 samples/sec#011loss=-0.629602\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741457.1545537, \"EndTime\": 1646741467.20521, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10049.247980117798, \"count\": 1, \"min\": 10049.247980117798, \"max\": 10049.247980117798}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.96751299361398 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 21.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=84, train loss <loss>=-0.594719407233325\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:07 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:09 INFO 140043348993664] Epoch[85] Batch[0] avg_epoch_loss=-0.595785\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=-0.5957849621772766\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:13 INFO 140043348993664] Epoch[85] Batch[5] avg_epoch_loss=-0.627675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=-0.6276750266551971\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:13 INFO 140043348993664] Epoch[85] Batch [5]#011Speed: 83.40 samples/sec#011loss=-0.627675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] Epoch[85] Batch[10] avg_epoch_loss=-0.632254\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=-0.6377484679222107\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] Epoch[85] Batch [10]#011Speed: 83.37 samples/sec#011loss=-0.637748\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741467.2055697, \"EndTime\": 1646741477.2442985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10037.301778793335, \"count\": 1, \"min\": 10037.301778793335, \"max\": 10037.301778793335}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.35075974579456 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 21.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=85, train loss <loss>=-0.6322538635947488\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:17 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:19 INFO 140043348993664] Epoch[86] Batch[0] avg_epoch_loss=-0.662435\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=-0.6624354720115662\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:23 INFO 140043348993664] Epoch[86] Batch[5] avg_epoch_loss=-0.663871\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=-0.6638711293538412\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:23 INFO 140043348993664] Epoch[86] Batch [5]#011Speed: 83.80 samples/sec#011loss=-0.663871\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] Epoch[86] Batch[10] avg_epoch_loss=-0.615935\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=-0.5584111213684082\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] Epoch[86] Batch [10]#011Speed: 78.64 samples/sec#011loss=-0.558411\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741477.2443852, \"EndTime\": 1646741487.32274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10077.1963596344, \"count\": 1, \"min\": 10077.1963596344, \"max\": 10077.1963596344}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.67624576738868 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] #progress_metric: host=algo-1, completed 21.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=86, train loss <loss>=-0.6159347620877352\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:27 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:29 INFO 140043348993664] Epoch[87] Batch[0] avg_epoch_loss=-0.629389\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=-0.629388689994812\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:33 INFO 140043348993664] Epoch[87] Batch[5] avg_epoch_loss=-0.540860\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=-0.5408595005671183\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:33 INFO 140043348993664] Epoch[87] Batch [5]#011Speed: 86.32 samples/sec#011loss=-0.540860\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] Epoch[87] Batch[10] avg_epoch_loss=-0.555577\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=-0.5732385814189911\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] Epoch[87] Batch [10]#011Speed: 83.15 samples/sec#011loss=-0.573239\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741487.3228767, \"EndTime\": 1646741497.0033062, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9679.683923721313, \"count\": 1, \"min\": 9679.683923721313, \"max\": 9679.683923721313}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.87330460379296 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=87, train loss <loss>=-0.5555772645906969\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:39 INFO 140043348993664] Epoch[88] Batch[0] avg_epoch_loss=-0.598206\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=-0.5982063412666321\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:42 INFO 140043348993664] Epoch[88] Batch[5] avg_epoch_loss=-0.620035\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=-0.6200346251328787\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:42 INFO 140043348993664] Epoch[88] Batch [5]#011Speed: 85.23 samples/sec#011loss=-0.620035\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] Epoch[88] Batch[10] avg_epoch_loss=-0.635704\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=-0.6545066475868225\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] Epoch[88] Batch [10]#011Speed: 84.07 samples/sec#011loss=-0.654507\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741497.0033863, \"EndTime\": 1646741506.7680178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9764.181137084961, \"count\": 1, \"min\": 9764.181137084961, \"max\": 9764.181137084961}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.26000027493222 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 22.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=88, train loss <loss>=-0.6357037262483076\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:48 INFO 140043348993664] Epoch[89] Batch[0] avg_epoch_loss=-0.669903\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=-0.669903039932251\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:52 INFO 140043348993664] Epoch[89] Batch[5] avg_epoch_loss=-0.651683\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=-0.6516828735669454\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:52 INFO 140043348993664] Epoch[89] Batch [5]#011Speed: 86.00 samples/sec#011loss=-0.651683\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] Epoch[89] Batch[10] avg_epoch_loss=-0.661931\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=-0.6742293000221252\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] Epoch[89] Batch [10]#011Speed: 86.79 samples/sec#011loss=-0.674229\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741506.7683594, \"EndTime\": 1646741516.35651, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9586.778402328491, \"count\": 1, \"min\": 9586.778402328491, \"max\": 9586.778402328491}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.05042853911736 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] #progress_metric: host=algo-1, completed 22.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=89, train loss <loss>=-0.6619312492283908\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:56 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:58 INFO 140043348993664] Epoch[90] Batch[0] avg_epoch_loss=-0.677527\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:11:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=-0.6775270104408264\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:02 INFO 140043348993664] Epoch[90] Batch[5] avg_epoch_loss=-0.694781\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=-0.6947806477546692\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:02 INFO 140043348993664] Epoch[90] Batch [5]#011Speed: 81.85 samples/sec#011loss=-0.694781\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] Epoch[90] Batch[10] avg_epoch_loss=-0.666825\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=-0.6332776188850403\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] Epoch[90] Batch [10]#011Speed: 81.68 samples/sec#011loss=-0.633278\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741516.3568683, \"EndTime\": 1646741526.3355055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9977.26559638977, \"count\": 1, \"min\": 9977.26559638977, \"max\": 9977.26559638977}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.55483705577774 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] #progress_metric: host=algo-1, completed 22.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=90, train loss <loss>=-0.6668247255412015\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:06 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_fd453d18-7514-44fd-9c36-363eb0f67f0d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741526.335611, \"EndTime\": 1646741526.4508908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 114.3960952758789, \"count\": 1, \"min\": 114.3960952758789, \"max\": 114.3960952758789}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:08 INFO 140043348993664] Epoch[91] Batch[0] avg_epoch_loss=-0.619043\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=-0.6190431118011475\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:12 INFO 140043348993664] Epoch[91] Batch[5] avg_epoch_loss=-0.706858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=-0.7068579693635305\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:12 INFO 140043348993664] Epoch[91] Batch [5]#011Speed: 85.20 samples/sec#011loss=-0.706858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] Epoch[91] Batch[10] avg_epoch_loss=-0.693456\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=-0.6773738861083984\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] Epoch[91] Batch [10]#011Speed: 82.93 samples/sec#011loss=-0.677374\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741526.451014, \"EndTime\": 1646741536.4805498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10029.446125030518, \"count\": 1, \"min\": 10029.446125030518, \"max\": 10029.446125030518}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.9912363141098 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=91, train loss <loss>=-0.6934561133384705\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:16 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_502a0ab6-2f15-4e7c-9e28-71f92c29a720-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741536.480891, \"EndTime\": 1646741536.602881, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 120.6204891204834, \"count\": 1, \"min\": 120.6204891204834, \"max\": 120.6204891204834}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:18 INFO 140043348993664] Epoch[92] Batch[0] avg_epoch_loss=-0.721847\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=-0.7218465209007263\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:22 INFO 140043348993664] Epoch[92] Batch[5] avg_epoch_loss=-0.730142\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=-0.7301419079303741\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:22 INFO 140043348993664] Epoch[92] Batch [5]#011Speed: 84.66 samples/sec#011loss=-0.730142\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:25 INFO 140043348993664] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741536.6029713, \"EndTime\": 1646741545.5509038, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8947.83329963684, \"count\": 1, \"min\": 8947.83329963684, \"max\": 8947.83329963684}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:25 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.40366617553414 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:25 INFO 140043348993664] #progress_metric: host=algo-1, completed 23.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=92, train loss <loss>=-0.7291900515556335\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:25 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:25 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_cdf6e458-6960-4bd8-94d3-e2cb779c89cd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741545.5511754, \"EndTime\": 1646741545.6709545, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 118.33715438842773, \"count\": 1, \"min\": 118.33715438842773, \"max\": 118.33715438842773}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:27 INFO 140043348993664] Epoch[93] Batch[0] avg_epoch_loss=-0.714002\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=-0.7140017747879028\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:31 INFO 140043348993664] Epoch[93] Batch[5] avg_epoch_loss=-0.722015\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=-0.7220153907934824\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:31 INFO 140043348993664] Epoch[93] Batch [5]#011Speed: 87.49 samples/sec#011loss=-0.722015\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] Epoch[93] Batch[10] avg_epoch_loss=-0.735526\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=-0.7517387270927429\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] Epoch[93] Batch [10]#011Speed: 82.42 samples/sec#011loss=-0.751739\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741545.6713312, \"EndTime\": 1646741555.3413274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9669.734954833984, \"count\": 1, \"min\": 9669.734954833984, \"max\": 9669.734954833984}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.11358045633253 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 23.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=93, train loss <loss>=-0.7355259982022372\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:35 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_54ad539b-4e38-4ca1-913a-ff9cf7c19faf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741555.3415778, \"EndTime\": 1646741555.4608982, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 117.9494857788086, \"count\": 1, \"min\": 117.9494857788086, \"max\": 117.9494857788086}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:37 INFO 140043348993664] Epoch[94] Batch[0] avg_epoch_loss=-0.706250\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=-0.7062495350837708\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:41 INFO 140043348993664] Epoch[94] Batch[5] avg_epoch_loss=-0.577006\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=-0.5770062853892645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:41 INFO 140043348993664] Epoch[94] Batch [5]#011Speed: 86.28 samples/sec#011loss=-0.577006\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:44 INFO 140043348993664] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741555.4612823, \"EndTime\": 1646741564.369306, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8907.767534255981, \"count\": 1, \"min\": 8907.767534255981, \"max\": 8907.767534255981}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.17023547084749 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 23.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=94, train loss <loss>=-0.5991660684347153\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:46 INFO 140043348993664] Epoch[95] Batch[0] avg_epoch_loss=-0.586866\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=-0.5868659019470215\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:50 INFO 140043348993664] Epoch[95] Batch[5] avg_epoch_loss=-0.630813\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=-0.6308125257492065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:50 INFO 140043348993664] Epoch[95] Batch [5]#011Speed: 87.68 samples/sec#011loss=-0.630813\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] Epoch[95] Batch[10] avg_epoch_loss=-0.640575\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=-0.6522890210151673\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] Epoch[95] Batch [10]#011Speed: 85.44 samples/sec#011loss=-0.652289\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741564.3696938, \"EndTime\": 1646741573.8161907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9445.038795471191, \"count\": 1, \"min\": 9445.038795471191, \"max\": 9445.038795471191}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.46499216364066 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=95, train loss <loss>=-0.6405745690519159\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:53 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:55 INFO 140043348993664] Epoch[96] Batch[0] avg_epoch_loss=0.043945\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=0.043944887816905975\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:59 INFO 140043348993664] Epoch[96] Batch[5] avg_epoch_loss=-0.192557\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=-0.1925572194159031\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:12:59 INFO 140043348993664] Epoch[96] Batch [5]#011Speed: 86.62 samples/sec#011loss=-0.192557\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] Epoch[96] Batch[10] avg_epoch_loss=-0.298671\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=-0.42600716948509215\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] Epoch[96] Batch [10]#011Speed: 80.53 samples/sec#011loss=-0.426007\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741573.816298, \"EndTime\": 1646741583.612669, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9795.264720916748, \"count\": 1, \"min\": 9795.264720916748, \"max\": 9795.264720916748}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.46151374930811 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] #progress_metric: host=algo-1, completed 24.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=96, train loss <loss>=-0.2986708330837163\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:03 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:05 INFO 140043348993664] Epoch[97] Batch[0] avg_epoch_loss=-0.528470\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=-0.5284703969955444\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:09 INFO 140043348993664] Epoch[97] Batch[5] avg_epoch_loss=-0.544103\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=-0.5441026290257772\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:09 INFO 140043348993664] Epoch[97] Batch [5]#011Speed: 79.95 samples/sec#011loss=-0.544103\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] Epoch[97] Batch[10] avg_epoch_loss=-0.574637\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=-0.6112789988517762\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] Epoch[97] Batch [10]#011Speed: 83.21 samples/sec#011loss=-0.611279\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741583.6128223, \"EndTime\": 1646741593.7054536, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10091.417789459229, \"count\": 1, \"min\": 10091.417789459229, \"max\": 10091.417789459229}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.27506957151412 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 24.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=97, train loss <loss>=-0.5746373425830494\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:15 INFO 140043348993664] Epoch[98] Batch[0] avg_epoch_loss=-0.643354\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=-0.6433542370796204\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:19 INFO 140043348993664] Epoch[98] Batch[5] avg_epoch_loss=-0.674459\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=-0.6744594673315684\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:19 INFO 140043348993664] Epoch[98] Batch [5]#011Speed: 83.68 samples/sec#011loss=-0.674459\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] Epoch[98] Batch[10] avg_epoch_loss=-0.686469\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=-0.7008802056312561\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] Epoch[98] Batch [10]#011Speed: 81.84 samples/sec#011loss=-0.700880\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741593.7055314, \"EndTime\": 1646741603.6588702, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9952.752590179443, \"count\": 1, \"min\": 9952.752590179443, \"max\": 9952.752590179443}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.01088495635638 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] #progress_metric: host=algo-1, completed 24.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=98, train loss <loss>=-0.6864688938314264\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:23 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:25 INFO 140043348993664] Epoch[99] Batch[0] avg_epoch_loss=-0.671889\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=-0.6718886494636536\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:29 INFO 140043348993664] Epoch[99] Batch[5] avg_epoch_loss=-0.661931\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=-0.6619314849376678\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:29 INFO 140043348993664] Epoch[99] Batch [5]#011Speed: 85.66 samples/sec#011loss=-0.661931\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] Epoch[99] Batch[10] avg_epoch_loss=-0.694091\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=-0.7326814532279968\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] Epoch[99] Batch [10]#011Speed: 81.67 samples/sec#011loss=-0.732681\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741603.6589613, \"EndTime\": 1646741613.5626016, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9902.36783027649, \"count\": 1, \"min\": 9902.36783027649, \"max\": 9902.36783027649}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.63827421385258 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=99, train loss <loss>=-0.694090561433272\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:35 INFO 140043348993664] Epoch[100] Batch[0] avg_epoch_loss=-0.635315\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=-0.6353152394294739\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:39 INFO 140043348993664] Epoch[100] Batch[5] avg_epoch_loss=-0.697539\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=-0.6975389719009399\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:39 INFO 140043348993664] Epoch[100] Batch [5]#011Speed: 85.98 samples/sec#011loss=-0.697539\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] Epoch[100] Batch[10] avg_epoch_loss=-0.707587\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=-0.7196450352668762\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] Epoch[100] Batch [10]#011Speed: 82.98 samples/sec#011loss=-0.719645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741613.5629513, \"EndTime\": 1646741623.2768745, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9712.517499923706, \"count\": 1, \"min\": 9712.517499923706, \"max\": 9712.517499923706}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.35040134793995 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] #progress_metric: host=algo-1, completed 25.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=100, train loss <loss>=-0.7075871825218201\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:43 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:45 INFO 140043348993664] Epoch[101] Batch[0] avg_epoch_loss=-0.642598\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=-0.6425977349281311\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:49 INFO 140043348993664] Epoch[101] Batch[5] avg_epoch_loss=-0.665976\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=-0.6659762561321259\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:49 INFO 140043348993664] Epoch[101] Batch [5]#011Speed: 84.86 samples/sec#011loss=-0.665976\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] Epoch[101] Batch[10] avg_epoch_loss=-0.685191\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=-0.708248746395111\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] Epoch[101] Batch [10]#011Speed: 82.91 samples/sec#011loss=-0.708249\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741623.2769485, \"EndTime\": 1646741633.793017, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10515.613794326782, \"count\": 1, \"min\": 10515.613794326782, \"max\": 10515.613794326782}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.32534732302501 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] #progress_metric: host=algo-1, completed 25.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=101, train loss <loss>=-0.7022307366132736\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:53 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:55 INFO 140043348993664] Epoch[102] Batch[0] avg_epoch_loss=-0.009087\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=-0.009087068028748035\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:59 INFO 140043348993664] Epoch[102] Batch[5] avg_epoch_loss=-0.468827\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=-0.4688270459882915\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:13:59 INFO 140043348993664] Epoch[102] Batch [5]#011Speed: 85.31 samples/sec#011loss=-0.468827\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:02 INFO 140043348993664] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741633.7934542, \"EndTime\": 1646741642.9081984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9113.18850517273, \"count\": 1, \"min\": 9113.18850517273, \"max\": 9113.18850517273}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:02 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.90980823174131 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:02 INFO 140043348993664] #progress_metric: host=algo-1, completed 25.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=102, train loss <loss>=-0.5095403832383454\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:02 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:05 INFO 140043348993664] Epoch[103] Batch[0] avg_epoch_loss=-0.662579\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=-0.662579357624054\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:08 INFO 140043348993664] Epoch[103] Batch[5] avg_epoch_loss=-0.682085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=-0.6820853253205618\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:08 INFO 140043348993664] Epoch[103] Batch [5]#011Speed: 87.78 samples/sec#011loss=-0.682085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] Epoch[103] Batch[10] avg_epoch_loss=-0.641937\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=-0.5937580704689026\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] Epoch[103] Batch [10]#011Speed: 79.43 samples/sec#011loss=-0.593758\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741642.9083302, \"EndTime\": 1646741652.8170204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9907.86623954773, \"count\": 1, \"min\": 9907.86623954773, \"max\": 9907.86623954773}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.7232427992297 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=103, train loss <loss>=-0.6419365731152621\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:12 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:15 INFO 140043348993664] Epoch[104] Batch[0] avg_epoch_loss=-0.613672\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=-0.6136721968650818\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:18 INFO 140043348993664] Epoch[104] Batch[5] avg_epoch_loss=-0.641835\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=-0.6418353219827017\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:18 INFO 140043348993664] Epoch[104] Batch [5]#011Speed: 82.81 samples/sec#011loss=-0.641835\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] Epoch[104] Batch[10] avg_epoch_loss=-0.683188\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=-0.7328102111816406\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] Epoch[104] Batch [10]#011Speed: 79.93 samples/sec#011loss=-0.732810\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741652.817092, \"EndTime\": 1646741662.918072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10100.542545318604, \"count\": 1, \"min\": 10100.542545318604, \"max\": 10100.542545318604}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.91500040256258 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 26.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=104, train loss <loss>=-0.6831875443458557\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:25 INFO 140043348993664] Epoch[105] Batch[0] avg_epoch_loss=-0.689005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=-0.6890049576759338\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:28 INFO 140043348993664] Epoch[105] Batch[5] avg_epoch_loss=-0.733329\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=-0.7333291868368784\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:28 INFO 140043348993664] Epoch[105] Batch [5]#011Speed: 85.38 samples/sec#011loss=-0.733329\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] Epoch[105] Batch[10] avg_epoch_loss=-0.736040\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=-0.7392928123474121\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] Epoch[105] Batch [10]#011Speed: 82.04 samples/sec#011loss=-0.739293\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741662.9182663, \"EndTime\": 1646741672.7276864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9808.339357376099, \"count\": 1, \"min\": 9808.339357376099, \"max\": 9808.339357376099}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.56870778608298 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] #progress_metric: host=algo-1, completed 26.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=105, train loss <loss>=-0.7360399257053029\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:32 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_a0563ebe-c870-4472-ad2c-05d161951ae2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741672.7280447, \"EndTime\": 1646741672.8617282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 132.33113288879395, \"count\": 1, \"min\": 132.33113288879395, \"max\": 132.33113288879395}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:35 INFO 140043348993664] Epoch[106] Batch[0] avg_epoch_loss=-0.758252\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=-0.7582523226737976\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:38 INFO 140043348993664] Epoch[106] Batch[5] avg_epoch_loss=-0.757573\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=-0.7575733462969462\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:38 INFO 140043348993664] Epoch[106] Batch [5]#011Speed: 84.50 samples/sec#011loss=-0.757573\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:41 INFO 140043348993664] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741672.8621254, \"EndTime\": 1646741681.9362202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9074.000358581543, \"count\": 1, \"min\": 9074.000358581543, \"max\": 9074.000358581543}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.41954073755434 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 26.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=106, train loss <loss>=-0.769255930185318\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:41 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:42 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_8e2893d1-e482-4df6-9534-6a1f2d6b337b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741681.9363656, \"EndTime\": 1646741682.0548751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 117.79570579528809, \"count\": 1, \"min\": 117.79570579528809, \"max\": 117.79570579528809}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:44 INFO 140043348993664] Epoch[107] Batch[0] avg_epoch_loss=-0.828658\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=-0.828657865524292\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:48 INFO 140043348993664] Epoch[107] Batch[5] avg_epoch_loss=-0.733362\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=-0.7333624760309855\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:48 INFO 140043348993664] Epoch[107] Batch [5]#011Speed: 84.50 samples/sec#011loss=-0.733362\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] Epoch[107] Batch[10] avg_epoch_loss=-0.717624\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=-0.6987389087677002\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] Epoch[107] Batch [10]#011Speed: 83.54 samples/sec#011loss=-0.698739\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741682.0549781, \"EndTime\": 1646741691.9066348, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9851.585149765015, \"count\": 1, \"min\": 9851.585149765015, \"max\": 9851.585149765015}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.38247327863725 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=107, train loss <loss>=-0.7176244909113104\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:51 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:54 INFO 140043348993664] Epoch[108] Batch[0] avg_epoch_loss=-0.664680\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=-0.6646803021430969\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:58 INFO 140043348993664] Epoch[108] Batch[5] avg_epoch_loss=-0.749347\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=-0.7493473390738169\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:14:58 INFO 140043348993664] Epoch[108] Batch [5]#011Speed: 81.21 samples/sec#011loss=-0.749347\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] Epoch[108] Batch[10] avg_epoch_loss=-0.732296\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=-0.7118347644805908\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] Epoch[108] Batch [10]#011Speed: 79.17 samples/sec#011loss=-0.711835\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741691.9070055, \"EndTime\": 1646741702.1168222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10208.479404449463, \"count\": 1, \"min\": 10208.479404449463, \"max\": 10208.479404449463}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.16051308435638 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] #progress_metric: host=algo-1, completed 27.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=108, train loss <loss>=-0.7322961688041687\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:02 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:04 INFO 140043348993664] Epoch[109] Batch[0] avg_epoch_loss=-0.675360\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=-0.6753599643707275\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:08 INFO 140043348993664] Epoch[109] Batch[5] avg_epoch_loss=-0.742324\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=-0.7423236767450968\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:08 INFO 140043348993664] Epoch[109] Batch [5]#011Speed: 78.84 samples/sec#011loss=-0.742324\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] Epoch[109] Batch[10] avg_epoch_loss=-0.735898\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=-0.7281878232955933\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] Epoch[109] Batch [10]#011Speed: 85.74 samples/sec#011loss=-0.728188\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741702.1169605, \"EndTime\": 1646741712.173603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10055.563926696777, \"count\": 1, \"min\": 10055.563926696777, \"max\": 10055.563926696777}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.54022892086336 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] #progress_metric: host=algo-1, completed 27.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=109, train loss <loss>=-0.7358982888135043\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:12 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:14 INFO 140043348993664] Epoch[110] Batch[0] avg_epoch_loss=-0.554744\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=-0.554744303226471\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:18 INFO 140043348993664] Epoch[110] Batch[5] avg_epoch_loss=-0.618343\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=-0.6183425486087799\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:18 INFO 140043348993664] Epoch[110] Batch [5]#011Speed: 82.86 samples/sec#011loss=-0.618343\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] Epoch[110] Batch[10] avg_epoch_loss=-0.650465\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=-0.6890117406845093\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] Epoch[110] Batch [10]#011Speed: 78.95 samples/sec#011loss=-0.689012\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741712.1737418, \"EndTime\": 1646741722.222631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10047.999858856201, \"count\": 1, \"min\": 10047.999858856201, \"max\": 10047.999858856201}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.5747784631223 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 27.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=110, train loss <loss>=-0.6504649086432024\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:24 INFO 140043348993664] Epoch[111] Batch[0] avg_epoch_loss=-0.680214\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=-0.6802141666412354\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:28 INFO 140043348993664] Epoch[111] Batch[5] avg_epoch_loss=-0.668645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=-0.6686448852221171\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:28 INFO 140043348993664] Epoch[111] Batch [5]#011Speed: 84.59 samples/sec#011loss=-0.668645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:31 INFO 140043348993664] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741722.2227194, \"EndTime\": 1646741731.0707774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8847.097873687744, \"count\": 1, \"min\": 8847.097873687744, \"max\": 8847.097873687744}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:31 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.75442493675004 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:31 INFO 140043348993664] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=111, train loss <loss>=-0.658089330792427\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:31 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:33 INFO 140043348993664] Epoch[112] Batch[0] avg_epoch_loss=-0.631468\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=-0.6314675807952881\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:36 INFO 140043348993664] Epoch[112] Batch[5] avg_epoch_loss=-0.674399\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=-0.6743985017140707\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:36 INFO 140043348993664] Epoch[112] Batch [5]#011Speed: 86.93 samples/sec#011loss=-0.674399\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:39 INFO 140043348993664] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741731.0711312, \"EndTime\": 1646741739.975738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8903.199911117554, \"count\": 1, \"min\": 8903.199911117554, \"max\": 8903.199911117554}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.64549282983185 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 28.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=112, train loss <loss>=-0.6816690266132355\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:42 INFO 140043348993664] Epoch[113] Batch[0] avg_epoch_loss=-0.586139\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=-0.5861387252807617\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:46 INFO 140043348993664] Epoch[113] Batch[5] avg_epoch_loss=-0.705920\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=-0.7059204479058584\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:46 INFO 140043348993664] Epoch[113] Batch [5]#011Speed: 83.88 samples/sec#011loss=-0.705920\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:48 INFO 140043348993664] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741739.9759274, \"EndTime\": 1646741748.9994726, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9021.996259689331, \"count\": 1, \"min\": 9021.996259689331, \"max\": 9021.996259689331}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.16093610053578 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 28.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=113, train loss <loss>=-0.7327224850654602\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:51 INFO 140043348993664] Epoch[114] Batch[0] avg_epoch_loss=-0.710495\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=-0.7104946970939636\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:54 INFO 140043348993664] Epoch[114] Batch[5] avg_epoch_loss=-0.742101\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=-0.7421007653077444\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:54 INFO 140043348993664] Epoch[114] Batch [5]#011Speed: 86.54 samples/sec#011loss=-0.742101\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] Epoch[114] Batch[10] avg_epoch_loss=-0.738281\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=-0.7336971402168274\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] Epoch[114] Batch [10]#011Speed: 83.70 samples/sec#011loss=-0.733697\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741748.9995518, \"EndTime\": 1646741758.6170304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9616.97506904602, \"count\": 1, \"min\": 9616.97506904602, \"max\": 9616.97506904602}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.74531137470693 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] #progress_metric: host=algo-1, completed 28.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=114, train loss <loss>=-0.7382809357209639\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:15:58 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:00 INFO 140043348993664] Epoch[115] Batch[0] avg_epoch_loss=-0.680553\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=-0.6805530786514282\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:04 INFO 140043348993664] Epoch[115] Batch[5] avg_epoch_loss=-0.600227\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=-0.6002272715171179\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:04 INFO 140043348993664] Epoch[115] Batch [5]#011Speed: 80.78 samples/sec#011loss=-0.600227\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] Epoch[115] Batch[10] avg_epoch_loss=-0.637943\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=-0.6832027077674866\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] Epoch[115] Batch [10]#011Speed: 78.39 samples/sec#011loss=-0.683203\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741758.6173677, \"EndTime\": 1646741768.8478842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10229.168891906738, \"count\": 1, \"min\": 10229.168891906738, \"max\": 10229.168891906738}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.32510794844579 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=115, train loss <loss>=-0.637943378903649\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:08 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:11 INFO 140043348993664] Epoch[116] Batch[0] avg_epoch_loss=-0.532892\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=-0.5328924655914307\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:14 INFO 140043348993664] Epoch[116] Batch[5] avg_epoch_loss=-0.555483\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=-0.5554828494787216\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:14 INFO 140043348993664] Epoch[116] Batch [5]#011Speed: 86.13 samples/sec#011loss=-0.555483\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] Epoch[116] Batch[10] avg_epoch_loss=-0.593607\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=-0.63935546875\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] Epoch[116] Batch [10]#011Speed: 83.52 samples/sec#011loss=-0.639355\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741768.8479629, \"EndTime\": 1646741778.6205711, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9772.150039672852, \"count\": 1, \"min\": 9772.150039672852, \"max\": 9772.150039672852}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.66144854442396 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] #progress_metric: host=algo-1, completed 29.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=116, train loss <loss>=-0.5936067673293027\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:18 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:20 INFO 140043348993664] Epoch[117] Batch[0] avg_epoch_loss=-0.666350\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=-0.6663495302200317\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:24 INFO 140043348993664] Epoch[117] Batch[5] avg_epoch_loss=-0.722005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=-0.7220054169495901\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:24 INFO 140043348993664] Epoch[117] Batch [5]#011Speed: 83.19 samples/sec#011loss=-0.722005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] Epoch[117] Batch[10] avg_epoch_loss=-0.743365\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=-0.7689962983131409\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] Epoch[117] Batch [10]#011Speed: 82.48 samples/sec#011loss=-0.768996\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741778.6209462, \"EndTime\": 1646741788.593304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9970.90196609497, \"count\": 1, \"min\": 9970.90196609497, \"max\": 9970.90196609497}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.09133425383023 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 29.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=117, train loss <loss>=-0.7433649084784768\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:30 INFO 140043348993664] Epoch[118] Batch[0] avg_epoch_loss=-0.738124\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=-0.7381235361099243\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:34 INFO 140043348993664] Epoch[118] Batch[5] avg_epoch_loss=-0.652654\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=-0.6526544292767843\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:34 INFO 140043348993664] Epoch[118] Batch [5]#011Speed: 83.82 samples/sec#011loss=-0.652654\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:37 INFO 140043348993664] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741788.593403, \"EndTime\": 1646741797.651619, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9057.645320892334, \"count\": 1, \"min\": 9057.645320892334, \"max\": 9057.645320892334}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.7717257596499 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 29.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=118, train loss <loss>=-0.6656476259231567\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:39 INFO 140043348993664] Epoch[119] Batch[0] avg_epoch_loss=-0.667976\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=-0.6679757237434387\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:43 INFO 140043348993664] Epoch[119] Batch[5] avg_epoch_loss=-0.734214\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=-0.7342136998971304\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:43 INFO 140043348993664] Epoch[119] Batch [5]#011Speed: 85.98 samples/sec#011loss=-0.734214\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:47 INFO 140043348993664] Epoch[119] Batch[10] avg_epoch_loss=-0.713606\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=-0.6888777613639832\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:47 INFO 140043348993664] Epoch[119] Batch [10]#011Speed: 79.72 samples/sec#011loss=-0.688878\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:48 INFO 140043348993664] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741797.6520424, \"EndTime\": 1646741808.2429857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10589.423179626465, \"count\": 1, \"min\": 10589.423179626465, \"max\": 10589.423179626465}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.2336481400795 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=119, train loss <loss>=-0.709206705292066\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:50 INFO 140043348993664] Epoch[120] Batch[0] avg_epoch_loss=-0.769753\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=-0.7697533369064331\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:54 INFO 140043348993664] Epoch[120] Batch[5] avg_epoch_loss=-0.711116\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=-0.7111159761746725\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:54 INFO 140043348993664] Epoch[120] Batch [5]#011Speed: 86.95 samples/sec#011loss=-0.711116\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] Epoch[120] Batch[10] avg_epoch_loss=-0.723883\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=-0.7392037868499756\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] Epoch[120] Batch [10]#011Speed: 82.10 samples/sec#011loss=-0.739204\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741808.243435, \"EndTime\": 1646741817.996099, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9751.187324523926, \"count\": 1, \"min\": 9751.187324523926, \"max\": 9751.187324523926}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.06796689724982 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 30.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=120, train loss <loss>=-0.7238831628452648\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:16:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:00 INFO 140043348993664] Epoch[121] Batch[0] avg_epoch_loss=-0.752251\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=-0.7522512674331665\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:04 INFO 140043348993664] Epoch[121] Batch[5] avg_epoch_loss=-0.702479\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=-0.702479084332784\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:04 INFO 140043348993664] Epoch[121] Batch [5]#011Speed: 81.76 samples/sec#011loss=-0.702479\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] Epoch[121] Batch[10] avg_epoch_loss=-0.690316\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=-0.6757194995880127\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] Epoch[121] Batch [10]#011Speed: 80.27 samples/sec#011loss=-0.675719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741817.9961772, \"EndTime\": 1646741828.0252864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10028.62524986267, \"count\": 1, \"min\": 10028.62524986267, \"max\": 10028.62524986267}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.00743548307533 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] #progress_metric: host=algo-1, completed 30.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=121, train loss <loss>=-0.6903156367215243\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:08 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:10 INFO 140043348993664] Epoch[122] Batch[0] avg_epoch_loss=-0.705404\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=-0.7054038643836975\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:13 INFO 140043348993664] Epoch[122] Batch[5] avg_epoch_loss=-0.745500\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=-0.7455003360907236\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:13 INFO 140043348993664] Epoch[122] Batch [5]#011Speed: 85.47 samples/sec#011loss=-0.745500\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] Epoch[122] Batch[10] avg_epoch_loss=-0.750468\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=-0.7564290523529053\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] Epoch[122] Batch [10]#011Speed: 67.27 samples/sec#011loss=-0.756429\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741828.0253625, \"EndTime\": 1646741838.6949432, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10669.104814529419, \"count\": 1, \"min\": 10669.104814529419, \"max\": 10669.104814529419}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.23414854317465 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] #progress_metric: host=algo-1, completed 30.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=122, train loss <loss>=-0.7504679343917153\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:18 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:20 INFO 140043348993664] Epoch[123] Batch[0] avg_epoch_loss=-0.828600\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=-0.8285995721817017\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:24 INFO 140043348993664] Epoch[123] Batch[5] avg_epoch_loss=-0.791994\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=-0.7919944922129313\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:24 INFO 140043348993664] Epoch[123] Batch [5]#011Speed: 84.95 samples/sec#011loss=-0.791994\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] Epoch[123] Batch[10] avg_epoch_loss=-0.773251\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=-0.7507578253746032\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] Epoch[123] Batch [10]#011Speed: 81.64 samples/sec#011loss=-0.750758\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741838.6950405, \"EndTime\": 1646741848.6343002, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9938.800573348999, \"count\": 1, \"min\": 9938.800573348999, \"max\": 9938.800573348999}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.90258786128958 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=123, train loss <loss>=-0.773250552740964\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:28 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_50713f7d-840e-4bb3-a1c0-24c77ffda165-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741848.6343756, \"EndTime\": 1646741848.752811, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 117.89774894714355, \"count\": 1, \"min\": 117.89774894714355, \"max\": 117.89774894714355}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:30 INFO 140043348993664] Epoch[124] Batch[0] avg_epoch_loss=-0.799502\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=-0.7995022535324097\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:34 INFO 140043348993664] Epoch[124] Batch[5] avg_epoch_loss=-0.748897\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=-0.7488971948623657\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:34 INFO 140043348993664] Epoch[124] Batch [5]#011Speed: 85.58 samples/sec#011loss=-0.748897\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] Epoch[124] Batch[10] avg_epoch_loss=-0.736721\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=-0.7221103191375733\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] Epoch[124] Batch [10]#011Speed: 83.41 samples/sec#011loss=-0.722110\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741848.7528841, \"EndTime\": 1646741858.5241983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9771.242141723633, \"count\": 1, \"min\": 9771.242141723633, \"max\": 9771.242141723633}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.05352635869546 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] #progress_metric: host=algo-1, completed 31.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=124, train loss <loss>=-0.7367213422601874\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:38 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:40 INFO 140043348993664] Epoch[125] Batch[0] avg_epoch_loss=-0.523003\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=-0.5230029225349426\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:44 INFO 140043348993664] Epoch[125] Batch[5] avg_epoch_loss=-0.580315\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=-0.5803146560986837\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:44 INFO 140043348993664] Epoch[125] Batch [5]#011Speed: 86.77 samples/sec#011loss=-0.580315\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] Epoch[125] Batch[10] avg_epoch_loss=-0.611639\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=-0.6492277920246124\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] Epoch[125] Batch [10]#011Speed: 83.28 samples/sec#011loss=-0.649228\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741858.524635, \"EndTime\": 1646741868.254666, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9728.638648986816, \"count\": 1, \"min\": 9728.638648986816, \"max\": 9728.638648986816}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.60632176915254 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 31.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=125, train loss <loss>=-0.6116388087922876\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:50 INFO 140043348993664] Epoch[126] Batch[0] avg_epoch_loss=-0.692844\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=-0.6928439140319824\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:54 INFO 140043348993664] Epoch[126] Batch[5] avg_epoch_loss=-0.717870\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=-0.7178697685400645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:54 INFO 140043348993664] Epoch[126] Batch [5]#011Speed: 86.91 samples/sec#011loss=-0.717870\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] Epoch[126] Batch[10] avg_epoch_loss=-0.725231\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=-0.7340647220611572\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] Epoch[126] Batch [10]#011Speed: 80.86 samples/sec#011loss=-0.734065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741868.254766, \"EndTime\": 1646741878.0952768, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9839.778900146484, \"count\": 1, \"min\": 9839.778900146484, \"max\": 9839.778900146484}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.51278353575904 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] #progress_metric: host=algo-1, completed 31.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=126, train loss <loss>=-0.7252311110496521\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:17:58 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:00 INFO 140043348993664] Epoch[127] Batch[0] avg_epoch_loss=-0.629297\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=-0.6292965412139893\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:04 INFO 140043348993664] Epoch[127] Batch[5] avg_epoch_loss=-0.658065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=-0.6580647031466166\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:04 INFO 140043348993664] Epoch[127] Batch [5]#011Speed: 81.97 samples/sec#011loss=-0.658065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] Epoch[127] Batch[10] avg_epoch_loss=-0.625607\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=-0.5866580188274384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] Epoch[127] Batch [10]#011Speed: 77.74 samples/sec#011loss=-0.586658\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741878.0953767, \"EndTime\": 1646741888.288095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10192.06976890564, \"count\": 1, \"min\": 10192.06976890564, \"max\": 10192.06976890564}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.91356117163814 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=127, train loss <loss>=-0.625607119365172\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:08 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:10 INFO 140043348993664] Epoch[128] Batch[0] avg_epoch_loss=-0.722896\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=-0.7228962779045105\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:14 INFO 140043348993664] Epoch[128] Batch[5] avg_epoch_loss=-0.700667\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=-0.7006670037905375\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:14 INFO 140043348993664] Epoch[128] Batch [5]#011Speed: 85.30 samples/sec#011loss=-0.700667\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] Epoch[128] Batch[10] avg_epoch_loss=-0.705028\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=-0.7102618336677551\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] Epoch[128] Batch [10]#011Speed: 81.67 samples/sec#011loss=-0.710262\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741888.2882316, \"EndTime\": 1646741898.2081451, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9919.098854064941, \"count\": 1, \"min\": 9919.098854064941, \"max\": 9919.098854064941}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.75545429974069 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] #progress_metric: host=algo-1, completed 32.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=128, train loss <loss>=-0.7050282900983637\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:18 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:20 INFO 140043348993664] Epoch[129] Batch[0] avg_epoch_loss=-0.788156\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=-0.7881557941436768\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:24 INFO 140043348993664] Epoch[129] Batch[5] avg_epoch_loss=-0.782791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=-0.7827905019124349\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:24 INFO 140043348993664] Epoch[129] Batch [5]#011Speed: 85.38 samples/sec#011loss=-0.782791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:27 INFO 140043348993664] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741898.2082222, \"EndTime\": 1646741907.2913506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9082.66830444336, \"count\": 1, \"min\": 9082.66830444336, \"max\": 9082.66830444336}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:27 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.02256180962348 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:27 INFO 140043348993664] #progress_metric: host=algo-1, completed 32.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=129, train loss <loss>=-0.7969011723995209\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:27 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:27 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_4b82a61e-b3c9-4883-9760-d0b055ef71f3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741907.29143, \"EndTime\": 1646741907.407898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.76724052429199, \"count\": 1, \"min\": 115.76724052429199, \"max\": 115.76724052429199}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:29 INFO 140043348993664] Epoch[130] Batch[0] avg_epoch_loss=-0.756426\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=-0.7564260959625244\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:33 INFO 140043348993664] Epoch[130] Batch[5] avg_epoch_loss=-0.812669\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=-0.8126687109470367\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:33 INFO 140043348993664] Epoch[130] Batch [5]#011Speed: 85.73 samples/sec#011loss=-0.812669\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] Epoch[130] Batch[10] avg_epoch_loss=-0.773036\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=-0.7254770040512085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] Epoch[130] Batch [10]#011Speed: 84.85 samples/sec#011loss=-0.725477\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741907.4079888, \"EndTime\": 1646741917.0719624, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9663.905382156372, \"count\": 1, \"min\": 9663.905382156372, \"max\": 9663.905382156372}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.77713370726265 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 32.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=130, train loss <loss>=-0.7730361169034784\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:39 INFO 140043348993664] Epoch[131] Batch[0] avg_epoch_loss=-0.619310\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=-0.6193098425865173\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:43 INFO 140043348993664] Epoch[131] Batch[5] avg_epoch_loss=-0.621226\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=-0.621226042509079\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:43 INFO 140043348993664] Epoch[131] Batch [5]#011Speed: 83.03 samples/sec#011loss=-0.621226\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:46 INFO 140043348993664] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741917.0720491, \"EndTime\": 1646741926.2424605, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9169.90852355957, \"count\": 1, \"min\": 9169.90852355957, \"max\": 9169.90852355957}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.46478136171343 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=131, train loss <loss>=-0.6668779671192169\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:48 INFO 140043348993664] Epoch[132] Batch[0] avg_epoch_loss=-0.768149\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=-0.7681490182876587\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:52 INFO 140043348993664] Epoch[132] Batch[5] avg_epoch_loss=-0.752405\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=-0.7524051566918691\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:52 INFO 140043348993664] Epoch[132] Batch [5]#011Speed: 84.04 samples/sec#011loss=-0.752405\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] Epoch[132] Batch[10] avg_epoch_loss=-0.783061\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=-0.8198480725288391\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] Epoch[132] Batch [10]#011Speed: 82.29 samples/sec#011loss=-0.819848\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741926.2426085, \"EndTime\": 1646741936.060994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9817.594051361084, \"count\": 1, \"min\": 9817.594051361084, \"max\": 9817.594051361084}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.05667787848256 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] #progress_metric: host=algo-1, completed 33.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=132, train loss <loss>=-0.7830610275268555\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:56 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:58 INFO 140043348993664] Epoch[133] Batch[0] avg_epoch_loss=-0.880485\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:18:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=-0.8804847002029419\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:02 INFO 140043348993664] Epoch[133] Batch[5] avg_epoch_loss=-0.819204\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=-0.8192043403784434\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:02 INFO 140043348993664] Epoch[133] Batch [5]#011Speed: 82.38 samples/sec#011loss=-0.819204\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] Epoch[133] Batch[10] avg_epoch_loss=-0.789035\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=-0.7528314113616943\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] Epoch[133] Batch [10]#011Speed: 77.12 samples/sec#011loss=-0.752831\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741936.0613563, \"EndTime\": 1646741946.279948, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10217.0991897583, \"count\": 1, \"min\": 10217.0991897583, \"max\": 10217.0991897583}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.16283258505432 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] #progress_metric: host=algo-1, completed 33.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=133, train loss <loss>=-0.789034827189012\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:06 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:08 INFO 140043348993664] Epoch[134] Batch[0] avg_epoch_loss=-0.778404\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=-0.7784040570259094\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:12 INFO 140043348993664] Epoch[134] Batch[5] avg_epoch_loss=-0.784750\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=-0.7847502926985422\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:12 INFO 140043348993664] Epoch[134] Batch [5]#011Speed: 85.09 samples/sec#011loss=-0.784750\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] Epoch[134] Batch[10] avg_epoch_loss=-0.802699\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=-0.8242367744445801\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] Epoch[134] Batch [10]#011Speed: 81.84 samples/sec#011loss=-0.824237\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741946.280027, \"EndTime\": 1646741956.1113513, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9830.870866775513, \"count\": 1, \"min\": 9830.870866775513, \"max\": 9830.870866775513}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.21825431576114 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] #progress_metric: host=algo-1, completed 33.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=134, train loss <loss>=-0.8026986934921958\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:16 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_be9a217a-9a5b-489e-906d-78c2da7aae38-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741956.1114397, \"EndTime\": 1646741956.2287214, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 116.11557006835938, \"count\": 1, \"min\": 116.11557006835938, \"max\": 116.11557006835938}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:18 INFO 140043348993664] Epoch[135] Batch[0] avg_epoch_loss=-0.612169\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=-0.6121688485145569\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:22 INFO 140043348993664] Epoch[135] Batch[5] avg_epoch_loss=-0.481443\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=-0.481443186601003\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:22 INFO 140043348993664] Epoch[135] Batch [5]#011Speed: 84.93 samples/sec#011loss=-0.481443\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] Epoch[135] Batch[10] avg_epoch_loss=-0.529349\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=-0.5868361294269562\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] Epoch[135] Batch [10]#011Speed: 84.41 samples/sec#011loss=-0.586836\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741956.2288325, \"EndTime\": 1646741965.9171627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9688.08913230896, \"count\": 1, \"min\": 9688.08913230896, \"max\": 9688.08913230896}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.91654656359532 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=135, train loss <loss>=-0.529349069703709\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:25 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:28 INFO 140043348993664] Epoch[136] Batch[0] avg_epoch_loss=-0.594015\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=-0.5940151810646057\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:31 INFO 140043348993664] Epoch[136] Batch[5] avg_epoch_loss=-0.679359\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=-0.6793593267599741\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:31 INFO 140043348993664] Epoch[136] Batch [5]#011Speed: 83.44 samples/sec#011loss=-0.679359\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] Epoch[136] Batch[10] avg_epoch_loss=-0.642923\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=-0.599198579788208\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] Epoch[136] Batch [10]#011Speed: 79.71 samples/sec#011loss=-0.599199\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741965.9172537, \"EndTime\": 1646741975.9230013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10004.475116729736, \"count\": 1, \"min\": 10004.475116729736, \"max\": 10004.475116729736}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.16726753834524 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 34.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=136, train loss <loss>=-0.6429226235909895\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:38 INFO 140043348993664] Epoch[137] Batch[0] avg_epoch_loss=-0.745945\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=-0.7459452748298645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:41 INFO 140043348993664] Epoch[137] Batch[5] avg_epoch_loss=-0.742085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=-0.742085337638855\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:41 INFO 140043348993664] Epoch[137] Batch [5]#011Speed: 82.87 samples/sec#011loss=-0.742085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] Epoch[137] Batch[10] avg_epoch_loss=-0.749005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=-0.7573086142539978\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] Epoch[137] Batch [10]#011Speed: 82.68 samples/sec#011loss=-0.757309\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741975.9233413, \"EndTime\": 1646741985.7620723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9837.353944778442, \"count\": 1, \"min\": 9837.353944778442, \"max\": 9837.353944778442}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.5443348891144 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] #progress_metric: host=algo-1, completed 34.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=137, train loss <loss>=-0.7490050088275563\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:45 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:47 INFO 140043348993664] Epoch[138] Batch[0] avg_epoch_loss=-0.813882\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=-0.813881516456604\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:51 INFO 140043348993664] Epoch[138] Batch[5] avg_epoch_loss=-0.814036\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=-0.8140362799167633\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:51 INFO 140043348993664] Epoch[138] Batch [5]#011Speed: 85.39 samples/sec#011loss=-0.814036\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:55 INFO 140043348993664] Epoch[138] Batch[10] avg_epoch_loss=-0.814692\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=-0.815479850769043\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:55 INFO 140043348993664] Epoch[138] Batch [10]#011Speed: 83.56 samples/sec#011loss=-0.815480\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:56 INFO 140043348993664] processed a total of 714 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741985.7624447, \"EndTime\": 1646741996.1769288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10413.050889968872, \"count\": 1, \"min\": 10413.050889968872, \"max\": 10413.050889968872}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:56 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.56470196594469 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:56 INFO 140043348993664] #progress_metric: host=algo-1, completed 34.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=138, train loss <loss>=-0.8153388748566309\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:56 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:56 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_35e3962a-087c-45bf-869e-8382bb810008-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741996.1773305, \"EndTime\": 1646741996.3026884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 123.84152412414551, \"count\": 1, \"min\": 123.84152412414551, \"max\": 123.84152412414551}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:58 INFO 140043348993664] Epoch[139] Batch[0] avg_epoch_loss=-0.733297\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:19:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=-0.7332972884178162\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:02 INFO 140043348993664] Epoch[139] Batch[5] avg_epoch_loss=-0.791787\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=-0.7917866309483846\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:02 INFO 140043348993664] Epoch[139] Batch [5]#011Speed: 82.78 samples/sec#011loss=-0.791787\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] Epoch[139] Batch[10] avg_epoch_loss=-0.814626\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=-0.8420325756072998\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] Epoch[139] Batch [10]#011Speed: 78.15 samples/sec#011loss=-0.842033\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646741996.3030932, \"EndTime\": 1646742006.4432573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10140.007257461548, \"count\": 1, \"min\": 10140.007257461548, \"max\": 10140.007257461548}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.90454945795818 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=139, train loss <loss>=-0.814625696702437\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:06 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:08 INFO 140043348993664] Epoch[140] Batch[0] avg_epoch_loss=-0.760476\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=-0.7604759931564331\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:12 INFO 140043348993664] Epoch[140] Batch[5] avg_epoch_loss=-0.804496\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=-0.8044964869817098\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:12 INFO 140043348993664] Epoch[140] Batch [5]#011Speed: 81.59 samples/sec#011loss=-0.804496\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:15 INFO 140043348993664] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742006.4433336, \"EndTime\": 1646742015.795101, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9351.183891296387, \"count\": 1, \"min\": 9351.183891296387, \"max\": 9351.183891296387}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:15 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.00941993024871 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:15 INFO 140043348993664] #progress_metric: host=algo-1, completed 35.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=140, train loss <loss>=-0.8082022845745087\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:15 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:17 INFO 140043348993664] Epoch[141] Batch[0] avg_epoch_loss=-0.881150\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=-0.8811495304107666\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:21 INFO 140043348993664] Epoch[141] Batch[5] avg_epoch_loss=-0.854146\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=-0.854146013657252\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:21 INFO 140043348993664] Epoch[141] Batch [5]#011Speed: 85.59 samples/sec#011loss=-0.854146\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:25 INFO 140043348993664] Epoch[141] Batch[10] avg_epoch_loss=-0.846449\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=-0.8372122168540954\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:25 INFO 140043348993664] Epoch[141] Batch [10]#011Speed: 82.12 samples/sec#011loss=-0.837212\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:26 INFO 140043348993664] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742015.7955184, \"EndTime\": 1646742026.3269348, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10530.019760131836, \"count\": 1, \"min\": 10530.019760131836, \"max\": 10530.019760131836}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.9484702793403 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 35.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=141, train loss <loss>=-0.8517128129800161\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:26 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:26 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_343befdd-cecd-4852-9853-143e257e0e07-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742026.3273296, \"EndTime\": 1646742026.4483278, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 119.43864822387695, \"count\": 1, \"min\": 119.43864822387695, \"max\": 119.43864822387695}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:28 INFO 140043348993664] Epoch[142] Batch[0] avg_epoch_loss=-0.880219\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=-0.8802185654640198\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:32 INFO 140043348993664] Epoch[142] Batch[5] avg_epoch_loss=-0.809397\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=-0.8093966742356619\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:32 INFO 140043348993664] Epoch[142] Batch [5]#011Speed: 86.34 samples/sec#011loss=-0.809397\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] Epoch[142] Batch[10] avg_epoch_loss=-0.815665\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=-0.8231863021850586\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] Epoch[142] Batch [10]#011Speed: 83.87 samples/sec#011loss=-0.823186\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742026.448747, \"EndTime\": 1646742036.1258848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9677.032470703125, \"count\": 1, \"min\": 9677.032470703125, \"max\": 9677.032470703125}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.50823056141283 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 35.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=142, train loss <loss>=-0.8156646869399331\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:36 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:38 INFO 140043348993664] Epoch[143] Batch[0] avg_epoch_loss=-0.723491\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=-0.7234908938407898\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:42 INFO 140043348993664] Epoch[143] Batch[5] avg_epoch_loss=-0.819491\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=-0.8194905718167623\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:42 INFO 140043348993664] Epoch[143] Batch [5]#011Speed: 84.12 samples/sec#011loss=-0.819491\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:45 INFO 140043348993664] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742036.1259484, \"EndTime\": 1646742045.1844132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9057.66224861145, \"count\": 1, \"min\": 9057.66224861145, \"max\": 9057.66224861145}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:45 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=69.11183721111058 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:45 INFO 140043348993664] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=143, train loss <loss>=-0.7892285346984863\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:45 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:47 INFO 140043348993664] Epoch[144] Batch[0] avg_epoch_loss=-0.705550\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=-0.7055502533912659\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:51 INFO 140043348993664] Epoch[144] Batch[5] avg_epoch_loss=-0.775369\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=-0.7753691176573435\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:51 INFO 140043348993664] Epoch[144] Batch [5]#011Speed: 85.29 samples/sec#011loss=-0.775369\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:54 INFO 140043348993664] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742045.1844943, \"EndTime\": 1646742054.169126, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8984.007120132446, \"count\": 1, \"min\": 8984.007120132446, \"max\": 8984.007120132446}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:54 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.2349130437171 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:54 INFO 140043348993664] #progress_metric: host=algo-1, completed 36.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=144, train loss <loss>=-0.7947247385978699\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:54 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:56 INFO 140043348993664] Epoch[145] Batch[0] avg_epoch_loss=-0.809300\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:20:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=-0.8093004822731018\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:00 INFO 140043348993664] Epoch[145] Batch[5] avg_epoch_loss=-0.860949\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=-0.8609491586685181\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:00 INFO 140043348993664] Epoch[145] Batch [5]#011Speed: 84.21 samples/sec#011loss=-0.860949\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] Epoch[145] Batch[10] avg_epoch_loss=-0.867249\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=-0.8748096108436585\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] Epoch[145] Batch [10]#011Speed: 78.57 samples/sec#011loss=-0.874810\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742054.1694288, \"EndTime\": 1646742064.2735028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10102.649450302124, \"count\": 1, \"min\": 10102.649450302124, \"max\": 10102.649450302124}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.14056684743443 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 36.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=145, train loss <loss>=-0.8672493642026727\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:04 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_55faffce-fdc0-4422-8502-fae48a11a0de-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742064.2736003, \"EndTime\": 1646742064.3928964, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 118.56269836425781, \"count\": 1, \"min\": 118.56269836425781, \"max\": 118.56269836425781}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:06 INFO 140043348993664] Epoch[146] Batch[0] avg_epoch_loss=-0.506830\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=-0.5068297386169434\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:10 INFO 140043348993664] Epoch[146] Batch[5] avg_epoch_loss=-0.613690\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=-0.6136895616849264\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:10 INFO 140043348993664] Epoch[146] Batch [5]#011Speed: 85.37 samples/sec#011loss=-0.613690\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] Epoch[146] Batch[10] avg_epoch_loss=-0.630946\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=-0.6516538023948669\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] Epoch[146] Batch [10]#011Speed: 81.18 samples/sec#011loss=-0.651654\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742064.3932662, \"EndTime\": 1646742074.454963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10061.601161956787, \"count\": 1, \"min\": 10061.601161956787, \"max\": 10061.601161956787}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.3945349368775 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 36.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=146, train loss <loss>=-0.6309460347348993\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:14 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:16 INFO 140043348993664] Epoch[147] Batch[0] avg_epoch_loss=-0.697616\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=-0.6976161599159241\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:20 INFO 140043348993664] Epoch[147] Batch[5] avg_epoch_loss=-0.690997\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=-0.6909973720709482\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:20 INFO 140043348993664] Epoch[147] Batch [5]#011Speed: 82.53 samples/sec#011loss=-0.690997\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] Epoch[147] Batch[10] avg_epoch_loss=-0.721402\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=-0.7578881621360779\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] Epoch[147] Batch [10]#011Speed: 81.20 samples/sec#011loss=-0.757888\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742074.4553084, \"EndTime\": 1646742084.4875078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10030.818223953247, \"count\": 1, \"min\": 10030.818223953247, \"max\": 10030.818223953247}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.08945422517803 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=147, train loss <loss>=-0.7214022766460072\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:26 INFO 140043348993664] Epoch[148] Batch[0] avg_epoch_loss=-0.495335\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=-0.49533528089523315\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:30 INFO 140043348993664] Epoch[148] Batch[5] avg_epoch_loss=-0.629457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=-0.6294565697511038\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:30 INFO 140043348993664] Epoch[148] Batch [5]#011Speed: 87.40 samples/sec#011loss=-0.629457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] Epoch[148] Batch[10] avg_epoch_loss=-0.677242\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=-0.7345839500427246\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] Epoch[148] Batch [10]#011Speed: 78.51 samples/sec#011loss=-0.734584\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] processed a total of 714 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742084.4875731, \"EndTime\": 1646742094.9477184, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10459.557294845581, \"count\": 1, \"min\": 10459.557294845581, \"max\": 10459.557294845581}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.26147253964294 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] #progress_metric: host=algo-1, completed 37.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=148, train loss <loss>=-0.6591702202955881\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:34 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:37 INFO 140043348993664] Epoch[149] Batch[0] avg_epoch_loss=-0.750638\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=-0.7506380081176758\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:40 INFO 140043348993664] Epoch[149] Batch[5] avg_epoch_loss=-0.689267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=-0.6892668604850769\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:40 INFO 140043348993664] Epoch[149] Batch [5]#011Speed: 86.82 samples/sec#011loss=-0.689267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:43 INFO 140043348993664] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742094.9478807, \"EndTime\": 1646742103.8223486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8872.852325439453, \"count\": 1, \"min\": 8872.852325439453, \"max\": 8872.852325439453}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:43 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=71.78861433069424 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:43 INFO 140043348993664] #progress_metric: host=algo-1, completed 37.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=149, train loss <loss>=-0.6879562437534332\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:43 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:45 INFO 140043348993664] Epoch[150] Batch[0] avg_epoch_loss=-0.714826\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=-0.7148256301879883\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:49 INFO 140043348993664] Epoch[150] Batch[5] avg_epoch_loss=-0.741223\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=-0.7412230173746744\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:49 INFO 140043348993664] Epoch[150] Batch [5]#011Speed: 86.05 samples/sec#011loss=-0.741223\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:52 INFO 140043348993664] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742103.8227267, \"EndTime\": 1646742112.7341206, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8910.011053085327, \"count\": 1, \"min\": 8910.011053085327, \"max\": 8910.011053085327}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:52 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=70.03268927146404 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:52 INFO 140043348993664] #progress_metric: host=algo-1, completed 37.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=150, train loss <loss>=-0.7414325714111328\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:52 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:54 INFO 140043348993664] Epoch[151] Batch[0] avg_epoch_loss=-0.659811\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=-0.6598113775253296\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:58 INFO 140043348993664] Epoch[151] Batch[5] avg_epoch_loss=-0.750640\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=-0.7506403028964996\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:21:58 INFO 140043348993664] Epoch[151] Batch [5]#011Speed: 83.30 samples/sec#011loss=-0.750640\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] Epoch[151] Batch[10] avg_epoch_loss=-0.773671\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=-0.8013072371482849\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] Epoch[151] Batch [10]#011Speed: 75.85 samples/sec#011loss=-0.801307\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742112.7341962, \"EndTime\": 1646742122.8632553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10128.51333618164, \"count\": 1, \"min\": 10128.51333618164, \"max\": 10128.51333618164}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=68.91357182922333 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=151, train loss <loss>=-0.773670727556402\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:02 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:04 INFO 140043348993664] Epoch[152] Batch[0] avg_epoch_loss=-0.705547\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=-0.7055469751358032\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:09 INFO 140043348993664] Epoch[152] Batch[5] avg_epoch_loss=-0.788577\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=-0.7885766923427582\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:09 INFO 140043348993664] Epoch[152] Batch [5]#011Speed: 77.94 samples/sec#011loss=-0.788577\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] Epoch[152] Batch[10] avg_epoch_loss=-0.804076\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=-0.8226753354072571\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] Epoch[152] Batch [10]#011Speed: 78.80 samples/sec#011loss=-0.822675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742122.863334, \"EndTime\": 1646742133.1635413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10299.724817276001, \"count\": 1, \"min\": 10299.724817276001, \"max\": 10299.724817276001}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.63031323581956 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 38.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=152, train loss <loss>=-0.804076075553894\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:15 INFO 140043348993664] Epoch[153] Batch[0] avg_epoch_loss=-0.866365\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=-0.8663646578788757\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:19 INFO 140043348993664] Epoch[153] Batch[5] avg_epoch_loss=-0.799492\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=-0.7994915445645651\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:19 INFO 140043348993664] Epoch[153] Batch [5]#011Speed: 81.90 samples/sec#011loss=-0.799492\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] Epoch[153] Batch[10] avg_epoch_loss=-0.789107\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=-0.776646363735199\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] Epoch[153] Batch [10]#011Speed: 79.04 samples/sec#011loss=-0.776646\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742133.1638792, \"EndTime\": 1646742143.3352184, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10170.04680633545, \"count\": 1, \"min\": 10170.04680633545, \"max\": 10170.04680633545}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.61572027669606 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] #progress_metric: host=algo-1, completed 38.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=153, train loss <loss>=-0.7891073714603077\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:23 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:25 INFO 140043348993664] Epoch[154] Batch[0] avg_epoch_loss=-0.830714\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=-0.83071368932724\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:29 INFO 140043348993664] Epoch[154] Batch[5] avg_epoch_loss=-0.746196\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=-0.7461962898572286\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:29 INFO 140043348993664] Epoch[154] Batch [5]#011Speed: 79.18 samples/sec#011loss=-0.746196\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] Epoch[154] Batch[10] avg_epoch_loss=-0.785704\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=-0.8331140637397766\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] Epoch[154] Batch [10]#011Speed: 76.63 samples/sec#011loss=-0.833114\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742143.33557, \"EndTime\": 1646742153.6685388, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10331.568479537964, \"count\": 1, \"min\": 10331.568479537964, \"max\": 10331.568479537964}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.20183689134932 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 38.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=154, train loss <loss>=-0.7857043688947504\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:35 INFO 140043348993664] Epoch[155] Batch[0] avg_epoch_loss=-0.884983\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=-0.8849833607673645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:39 INFO 140043348993664] Epoch[155] Batch[5] avg_epoch_loss=-0.837111\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=-0.8371110359827677\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:39 INFO 140043348993664] Epoch[155] Batch [5]#011Speed: 80.94 samples/sec#011loss=-0.837111\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:43 INFO 140043348993664] Epoch[155] Batch[10] avg_epoch_loss=-0.830407\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=-0.8223623991012573\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:43 INFO 140043348993664] Epoch[155] Batch [10]#011Speed: 78.41 samples/sec#011loss=-0.822362\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:44 INFO 140043348993664] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742153.6689675, \"EndTime\": 1646742164.807656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11137.25757598877, \"count\": 1, \"min\": 11137.25757598877, \"max\": 11137.25757598877}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.83898076501194 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=155, train loss <loss>=-0.8461837371190389\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:47 INFO 140043348993664] Epoch[156] Batch[0] avg_epoch_loss=-0.761978\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=-0.761978030204773\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:51 INFO 140043348993664] Epoch[156] Batch[5] avg_epoch_loss=-0.694583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=-0.6945829490820566\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:51 INFO 140043348993664] Epoch[156] Batch [5]#011Speed: 79.23 samples/sec#011loss=-0.694583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] Epoch[156] Batch[10] avg_epoch_loss=-0.726375\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=-0.7645263910293579\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] Epoch[156] Batch [10]#011Speed: 78.53 samples/sec#011loss=-0.764526\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742164.8077552, \"EndTime\": 1646742175.232361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10424.066543579102, \"count\": 1, \"min\": 10424.066543579102, \"max\": 10424.066543579102}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.16129745538165 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 39.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=156, train loss <loss>=-0.7263754226944663\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:57 INFO 140043348993664] Epoch[157] Batch[0] avg_epoch_loss=-0.734061\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:22:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=-0.7340607047080994\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:01 INFO 140043348993664] Epoch[157] Batch[5] avg_epoch_loss=-0.747081\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=-0.7470809618631998\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:01 INFO 140043348993664] Epoch[157] Batch [5]#011Speed: 82.72 samples/sec#011loss=-0.747081\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] Epoch[157] Batch[10] avg_epoch_loss=-0.770494\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=-0.7985904097557068\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] Epoch[157] Batch [10]#011Speed: 74.29 samples/sec#011loss=-0.798590\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742175.232716, \"EndTime\": 1646742185.7219458, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10487.907886505127, \"count\": 1, \"min\": 10487.907886505127, \"max\": 10487.907886505127}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.49857951994517 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] #progress_metric: host=algo-1, completed 39.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=157, train loss <loss>=-0.7704943472688849\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:05 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:07 INFO 140043348993664] Epoch[158] Batch[0] avg_epoch_loss=-0.522474\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=-0.5224743485450745\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:11 INFO 140043348993664] Epoch[158] Batch[5] avg_epoch_loss=-0.665021\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=-0.6650210420290629\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:11 INFO 140043348993664] Epoch[158] Batch [5]#011Speed: 79.79 samples/sec#011loss=-0.665021\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] Epoch[158] Batch[10] avg_epoch_loss=-0.720532\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=-0.7871448397636414\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] Epoch[158] Batch [10]#011Speed: 73.80 samples/sec#011loss=-0.787145\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742185.7220466, \"EndTime\": 1646742196.2560394, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10531.574964523315, \"count\": 1, \"min\": 10531.574964523315, \"max\": 10531.574964523315}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.433360377569194 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] #progress_metric: host=algo-1, completed 39.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=158, train loss <loss>=-0.720531859181144\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:16 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:18 INFO 140043348993664] Epoch[159] Batch[0] avg_epoch_loss=-0.222012\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=-0.2220117598772049\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:22 INFO 140043348993664] Epoch[159] Batch[5] avg_epoch_loss=-0.413676\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=-0.4136756733059883\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:22 INFO 140043348993664] Epoch[159] Batch [5]#011Speed: 78.81 samples/sec#011loss=-0.413676\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] Epoch[159] Batch[10] avg_epoch_loss=-0.497137\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=-0.59729163646698\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] Epoch[159] Batch [10]#011Speed: 75.54 samples/sec#011loss=-0.597292\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742196.2561603, \"EndTime\": 1646742206.7698731, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10513.105630874634, \"count\": 1, \"min\": 10513.105630874634, \"max\": 10513.105630874634}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.7735670821808 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=159, train loss <loss>=-0.49713747474280273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:26 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:28 INFO 140043348993664] Epoch[160] Batch[0] avg_epoch_loss=-0.774888\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=-0.7748876214027405\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:32 INFO 140043348993664] Epoch[160] Batch[5] avg_epoch_loss=-0.680020\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=-0.6800198157628378\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:32 INFO 140043348993664] Epoch[160] Batch [5]#011Speed: 79.83 samples/sec#011loss=-0.680020\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] Epoch[160] Batch[10] avg_epoch_loss=-0.714333\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=-0.7555090427398682\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] Epoch[160] Batch [10]#011Speed: 78.87 samples/sec#011loss=-0.755509\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742206.7702744, \"EndTime\": 1646742216.9732146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10201.586246490479, \"count\": 1, \"min\": 10201.586246490479, \"max\": 10201.586246490479}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.4575207010054 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 40.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=160, train loss <loss>=-0.714333100752397\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:36 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:39 INFO 140043348993664] Epoch[161] Batch[0] avg_epoch_loss=-0.737663\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=-0.7376633882522583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:43 INFO 140043348993664] Epoch[161] Batch[5] avg_epoch_loss=-0.633444\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=-0.6334437926610311\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:43 INFO 140043348993664] Epoch[161] Batch [5]#011Speed: 78.75 samples/sec#011loss=-0.633444\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] Epoch[161] Batch[10] avg_epoch_loss=-0.658877\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=-0.6893974184989929\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] Epoch[161] Batch [10]#011Speed: 76.97 samples/sec#011loss=-0.689397\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742216.9735708, \"EndTime\": 1646742227.474224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10499.228954315186, \"count\": 1, \"min\": 10499.228954315186, \"max\": 10499.228954315186}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.04971353737298 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] #progress_metric: host=algo-1, completed 40.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=161, train loss <loss>=-0.6588772589510138\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:47 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:49 INFO 140043348993664] Epoch[162] Batch[0] avg_epoch_loss=-0.734840\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=-0.7348402738571167\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:53 INFO 140043348993664] Epoch[162] Batch[5] avg_epoch_loss=-0.755418\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=-0.7554176251093546\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:53 INFO 140043348993664] Epoch[162] Batch [5]#011Speed: 80.28 samples/sec#011loss=-0.755418\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] Epoch[162] Batch[10] avg_epoch_loss=-0.769368\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=-0.7861078023910523\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] Epoch[162] Batch [10]#011Speed: 75.79 samples/sec#011loss=-0.786108\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742227.474581, \"EndTime\": 1646742237.890983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10415.037870407104, \"count\": 1, \"min\": 10415.037870407104, \"max\": 10415.037870407104}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.43971240405448 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 40.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=162, train loss <loss>=-0.7693677056919445\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:23:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:00 INFO 140043348993664] Epoch[163] Batch[0] avg_epoch_loss=-0.766489\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=-0.7664891481399536\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:04 INFO 140043348993664] Epoch[163] Batch[5] avg_epoch_loss=-0.797999\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=-0.7979992926120758\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:04 INFO 140043348993664] Epoch[163] Batch [5]#011Speed: 73.21 samples/sec#011loss=-0.797999\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:07 INFO 140043348993664] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742237.8913393, \"EndTime\": 1646742247.9646592, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10071.922302246094, \"count\": 1, \"min\": 10071.922302246094, \"max\": 10071.922302246094}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.554772872443735 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=163, train loss <loss>=-0.7987346470355987\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:07 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:10 INFO 140043348993664] Epoch[164] Batch[0] avg_epoch_loss=-0.852803\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=-0.8528033494949341\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:14 INFO 140043348993664] Epoch[164] Batch[5] avg_epoch_loss=-0.808507\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=-0.808506965637207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:14 INFO 140043348993664] Epoch[164] Batch [5]#011Speed: 79.80 samples/sec#011loss=-0.808507\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] Epoch[164] Batch[10] avg_epoch_loss=-0.776375\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=-0.7378164052963256\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] Epoch[164] Batch [10]#011Speed: 77.82 samples/sec#011loss=-0.737816\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742247.9649744, \"EndTime\": 1646742258.4193485, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10453.09853553772, \"count\": 1, \"min\": 10453.09853553772, \"max\": 10453.09853553772}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.75393098221117 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] #progress_metric: host=algo-1, completed 41.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=164, train loss <loss>=-0.7763748927549883\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:18 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:20 INFO 140043348993664] Epoch[165] Batch[0] avg_epoch_loss=-0.664173\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=-0.6641726493835449\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:24 INFO 140043348993664] Epoch[165] Batch[5] avg_epoch_loss=-0.761272\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=-0.7612723012765249\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:24 INFO 140043348993664] Epoch[165] Batch [5]#011Speed: 79.99 samples/sec#011loss=-0.761272\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] Epoch[165] Batch[10] avg_epoch_loss=-0.774866\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=-0.7911778807640075\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] Epoch[165] Batch [10]#011Speed: 78.63 samples/sec#011loss=-0.791178\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742258.419718, \"EndTime\": 1646742268.6712568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10250.179052352905, \"count\": 1, \"min\": 10250.179052352905, \"max\": 10250.179052352905}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.94933728853428 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 41.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=165, train loss <loss>=-0.7748657464981079\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:30 INFO 140043348993664] Epoch[166] Batch[0] avg_epoch_loss=-0.824094\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=-0.8240935206413269\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:34 INFO 140043348993664] Epoch[166] Batch[5] avg_epoch_loss=-0.858392\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=-0.8583916624387106\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:34 INFO 140043348993664] Epoch[166] Batch [5]#011Speed: 78.41 samples/sec#011loss=-0.858392\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] Epoch[166] Batch[10] avg_epoch_loss=-0.835959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=-0.809040880203247\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] Epoch[166] Batch [10]#011Speed: 76.02 samples/sec#011loss=-0.809041\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742268.6713345, \"EndTime\": 1646742279.1616492, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10489.857196807861, \"count\": 1, \"min\": 10489.857196807861, \"max\": 10489.857196807861}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.06122445918236 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 41.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=166, train loss <loss>=-0.835959488695318\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:41 INFO 140043348993664] Epoch[167] Batch[0] avg_epoch_loss=-0.838814\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=-0.8388137817382812\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:45 INFO 140043348993664] Epoch[167] Batch[5] avg_epoch_loss=-0.807933\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=-0.8079329331715902\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:45 INFO 140043348993664] Epoch[167] Batch [5]#011Speed: 80.25 samples/sec#011loss=-0.807933\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] Epoch[167] Batch[10] avg_epoch_loss=-0.823870\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=-0.8429946184158326\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] Epoch[167] Batch [10]#011Speed: 75.60 samples/sec#011loss=-0.842995\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742279.1617231, \"EndTime\": 1646742289.501412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10339.245080947876, \"count\": 1, \"min\": 10339.245080947876, \"max\": 10339.245080947876}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.47795118489397 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=167, train loss <loss>=-0.823870062828064\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:49 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:51 INFO 140043348993664] Epoch[168] Batch[0] avg_epoch_loss=-0.926261\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=-0.926261305809021\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:55 INFO 140043348993664] Epoch[168] Batch[5] avg_epoch_loss=-0.736958\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=-0.736958235502243\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:55 INFO 140043348993664] Epoch[168] Batch [5]#011Speed: 79.18 samples/sec#011loss=-0.736958\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] Epoch[168] Batch[10] avg_epoch_loss=-0.750036\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=-0.7657291173934937\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] Epoch[168] Batch [10]#011Speed: 75.58 samples/sec#011loss=-0.765729\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742289.5014892, \"EndTime\": 1646742299.9283817, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10426.435947418213, \"count\": 1, \"min\": 10426.435947418213, \"max\": 10426.435947418213}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.45080831611564 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] #progress_metric: host=algo-1, completed 42.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=168, train loss <loss>=-0.7500359090891752\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:24:59 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:02 INFO 140043348993664] Epoch[169] Batch[0] avg_epoch_loss=-0.849220\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=-0.8492204546928406\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:06 INFO 140043348993664] Epoch[169] Batch[5] avg_epoch_loss=-0.792072\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=-0.7920719683170319\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:06 INFO 140043348993664] Epoch[169] Batch [5]#011Speed: 73.79 samples/sec#011loss=-0.792072\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] Epoch[169] Batch[10] avg_epoch_loss=-0.828107\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=-0.8713499784469605\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] Epoch[169] Batch [10]#011Speed: 74.97 samples/sec#011loss=-0.871350\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742299.9284668, \"EndTime\": 1646742310.900105, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10970.957040786743, \"count\": 1, \"min\": 10970.957040786743, \"max\": 10970.957040786743}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.069585830974084 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] #progress_metric: host=algo-1, completed 42.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=169, train loss <loss>=-0.8281074274669994\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:10 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:13 INFO 140043348993664] Epoch[170] Batch[0] avg_epoch_loss=-0.801797\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=-0.8017969727516174\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:17 INFO 140043348993664] Epoch[170] Batch[5] avg_epoch_loss=-0.840193\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=-0.8401930729548136\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:17 INFO 140043348993664] Epoch[170] Batch [5]#011Speed: 78.78 samples/sec#011loss=-0.840193\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:20 INFO 140043348993664] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742310.9002, \"EndTime\": 1646742320.4132845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9510.94365119934, \"count\": 1, \"min\": 9510.94365119934, \"max\": 9510.94365119934}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.39479042428454 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 42.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=170, train loss <loss>=-0.8411584436893463\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:22 INFO 140043348993664] Epoch[171] Batch[0] avg_epoch_loss=-0.860888\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=-0.8608884811401367\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:26 INFO 140043348993664] Epoch[171] Batch[5] avg_epoch_loss=-0.839867\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=-0.8398670355478922\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:26 INFO 140043348993664] Epoch[171] Batch [5]#011Speed: 77.89 samples/sec#011loss=-0.839867\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:30 INFO 140043348993664] Epoch[171] Batch[10] avg_epoch_loss=-0.868227\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=-0.902259624004364\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:30 INFO 140043348993664] Epoch[171] Batch [10]#011Speed: 73.97 samples/sec#011loss=-0.902260\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:31 INFO 140043348993664] processed a total of 722 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742320.4133852, \"EndTime\": 1646742331.889057, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11474.312543869019, \"count\": 1, \"min\": 11474.312543869019, \"max\": 11474.312543869019}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:31 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.92224836669101 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:31 INFO 140043348993664] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=171, train loss <loss>=-0.8701573610305786\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:31 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:32 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_bb361bdb-bd6b-4861-8689-c9bf8de23d31-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742331.8891637, \"EndTime\": 1646742332.0220797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 132.03954696655273, \"count\": 1, \"min\": 132.03954696655273, \"max\": 132.03954696655273}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:34 INFO 140043348993664] Epoch[172] Batch[0] avg_epoch_loss=-0.538513\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=-0.53851318359375\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:38 INFO 140043348993664] Epoch[172] Batch[5] avg_epoch_loss=-0.591823\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=-0.591823140780131\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:38 INFO 140043348993664] Epoch[172] Batch [5]#011Speed: 77.05 samples/sec#011loss=-0.591823\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] Epoch[172] Batch[10] avg_epoch_loss=-0.660531\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=-0.7429814338684082\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] Epoch[172] Batch [10]#011Speed: 78.24 samples/sec#011loss=-0.742981\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742332.0221992, \"EndTime\": 1646742342.453126, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10430.776119232178, \"count\": 1, \"min\": 10430.776119232178, \"max\": 10430.776119232178}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=67.29785785882792 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] #progress_metric: host=algo-1, completed 43.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=172, train loss <loss>=-0.660531455820257\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:42 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:44 INFO 140043348993664] Epoch[173] Batch[0] avg_epoch_loss=-0.803353\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=-0.8033530116081238\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:48 INFO 140043348993664] Epoch[173] Batch[5] avg_epoch_loss=-0.797625\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=-0.79762535293897\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:48 INFO 140043348993664] Epoch[173] Batch [5]#011Speed: 79.71 samples/sec#011loss=-0.797625\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] Epoch[173] Batch[10] avg_epoch_loss=-0.840684\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=-0.8923537254333496\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] Epoch[173] Batch [10]#011Speed: 74.74 samples/sec#011loss=-0.892354\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742342.4534707, \"EndTime\": 1646742352.9560616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10501.290082931519, \"count\": 1, \"min\": 10501.290082931519, \"max\": 10501.290082931519}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.37073458761252 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] #progress_metric: host=algo-1, completed 43.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=173, train loss <loss>=-0.8406837040727789\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:52 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:55 INFO 140043348993664] Epoch[174] Batch[0] avg_epoch_loss=-0.832554\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=-0.8325542211532593\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:59 INFO 140043348993664] Epoch[174] Batch[5] avg_epoch_loss=-0.888896\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=-0.8888960182666779\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:25:59 INFO 140043348993664] Epoch[174] Batch [5]#011Speed: 79.44 samples/sec#011loss=-0.888896\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] Epoch[174] Batch[10] avg_epoch_loss=-0.896280\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=-0.9051409006118775\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] Epoch[174] Batch [10]#011Speed: 73.40 samples/sec#011loss=-0.905141\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] processed a total of 703 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742352.9563391, \"EndTime\": 1646742363.4833589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10526.31139755249, \"count\": 1, \"min\": 10526.31139755249, \"max\": 10526.31139755249}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=66.78411876510309 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] #progress_metric: host=algo-1, completed 43.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=174, train loss <loss>=-0.8962800556963141\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:03 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_0ecd0b15-eb58-4583-bb18-f29542c23e81-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742363.4834645, \"EndTime\": 1646742363.6342275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 150.09665489196777, \"count\": 1, \"min\": 150.09665489196777, \"max\": 150.09665489196777}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:05 INFO 140043348993664] Epoch[175] Batch[0] avg_epoch_loss=-0.849494\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=-0.8494939804077148\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:10 INFO 140043348993664] Epoch[175] Batch[5] avg_epoch_loss=-0.886664\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=-0.8866635461648306\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:10 INFO 140043348993664] Epoch[175] Batch [5]#011Speed: 75.18 samples/sec#011loss=-0.886664\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] Epoch[175] Batch[10] avg_epoch_loss=-0.869065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=-0.8479457139968872\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] Epoch[175] Batch [10]#011Speed: 76.38 samples/sec#011loss=-0.847946\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742363.6343222, \"EndTime\": 1646742374.3601692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10725.7399559021, \"count\": 1, \"min\": 10725.7399559021, \"max\": 10725.7399559021}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.30408804740664 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=175, train loss <loss>=-0.8690645315430381\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:14 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:16 INFO 140043348993664] Epoch[176] Batch[0] avg_epoch_loss=-0.818588\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=-0.8185882568359375\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:20 INFO 140043348993664] Epoch[176] Batch[5] avg_epoch_loss=-0.791384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=-0.7913842697938284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:20 INFO 140043348993664] Epoch[176] Batch [5]#011Speed: 78.99 samples/sec#011loss=-0.791384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] Epoch[176] Batch[10] avg_epoch_loss=-0.805163\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=-0.821697449684143\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] Epoch[176] Batch [10]#011Speed: 76.54 samples/sec#011loss=-0.821697\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742374.3603919, \"EndTime\": 1646742384.7730508, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10411.635875701904, \"count\": 1, \"min\": 10411.635875701904, \"max\": 10411.635875701904}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.59858217592195 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 44.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=176, train loss <loss>=-0.8051629879257896\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:27 INFO 140043348993664] Epoch[177] Batch[0] avg_epoch_loss=-0.934144\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=-0.934144139289856\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:31 INFO 140043348993664] Epoch[177] Batch[5] avg_epoch_loss=-0.792868\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=-0.7928678294022878\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:31 INFO 140043348993664] Epoch[177] Batch [5]#011Speed: 78.07 samples/sec#011loss=-0.792868\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] Epoch[177] Batch[10] avg_epoch_loss=-0.809885\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=-0.8303055882453918\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] Epoch[177] Batch [10]#011Speed: 76.46 samples/sec#011loss=-0.830306\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742384.7731612, \"EndTime\": 1646742395.3349543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10561.075925827026, \"count\": 1, \"min\": 10561.075925827026, \"max\": 10561.075925827026}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.64048247359825 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 44.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=177, train loss <loss>=-0.8098849925127897\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:37 INFO 140043348993664] Epoch[178] Batch[0] avg_epoch_loss=-0.709784\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=-0.7097837328910828\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:41 INFO 140043348993664] Epoch[178] Batch[5] avg_epoch_loss=-0.841187\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=-0.8411867717901865\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:41 INFO 140043348993664] Epoch[178] Batch [5]#011Speed: 79.19 samples/sec#011loss=-0.841187\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] Epoch[178] Batch[10] avg_epoch_loss=-0.863930\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=-0.8912221193313599\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] Epoch[178] Batch [10]#011Speed: 75.35 samples/sec#011loss=-0.891222\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742395.335082, \"EndTime\": 1646742405.8490021, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10513.195276260376, \"count\": 1, \"min\": 10513.195276260376, \"max\": 10513.195276260376}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.49202686611024 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] #progress_metric: host=algo-1, completed 44.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=178, train loss <loss>=-0.863930111581629\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:45 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:48 INFO 140043348993664] Epoch[179] Batch[0] avg_epoch_loss=-0.802966\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=-0.8029657602310181\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:52 INFO 140043348993664] Epoch[179] Batch[5] avg_epoch_loss=-0.863994\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=-0.8639938135941824\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:52 INFO 140043348993664] Epoch[179] Batch [5]#011Speed: 77.51 samples/sec#011loss=-0.863994\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] Epoch[179] Batch[10] avg_epoch_loss=-0.867452\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=-0.8716020107269287\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] Epoch[179] Batch [10]#011Speed: 76.25 samples/sec#011loss=-0.871602\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742405.8491113, \"EndTime\": 1646742416.4625757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10612.268209457397, \"count\": 1, \"min\": 10612.268209457397, \"max\": 10612.268209457397}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.4741876492309 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=179, train loss <loss>=-0.867452085018158\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:56 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:58 INFO 140043348993664] Epoch[180] Batch[0] avg_epoch_loss=-0.862477\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:26:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=-0.8624773621559143\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:03 INFO 140043348993664] Epoch[180] Batch[5] avg_epoch_loss=-0.825197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=-0.825197180112203\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:03 INFO 140043348993664] Epoch[180] Batch [5]#011Speed: 75.86 samples/sec#011loss=-0.825197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] Epoch[180] Batch[10] avg_epoch_loss=-0.823807\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=-0.8221393585205078\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] Epoch[180] Batch [10]#011Speed: 73.77 samples/sec#011loss=-0.822139\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742416.4626524, \"EndTime\": 1646742427.360049, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10896.791934967041, \"count\": 1, \"min\": 10896.791934967041, \"max\": 10896.791934967041}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.0294438804022 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 45.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=180, train loss <loss>=-0.823807261206887\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:07 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:09 INFO 140043348993664] Epoch[181] Batch[0] avg_epoch_loss=-0.841002\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=-0.841001570224762\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:13 INFO 140043348993664] Epoch[181] Batch[5] avg_epoch_loss=-0.870957\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=-0.870956540107727\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:13 INFO 140043348993664] Epoch[181] Batch [5]#011Speed: 78.38 samples/sec#011loss=-0.870957\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] Epoch[181] Batch[10] avg_epoch_loss=-0.896253\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=-0.9266098260879516\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] Epoch[181] Batch [10]#011Speed: 74.53 samples/sec#011loss=-0.926610\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742427.3612676, \"EndTime\": 1646742438.158667, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10784.940958023071, \"count\": 1, \"min\": 10784.940958023071, \"max\": 10784.940958023071}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.08137545418995 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] #progress_metric: host=algo-1, completed 45.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=181, train loss <loss>=-0.8962534882805564\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:18 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:20 INFO 140043348993664] Epoch[182] Batch[0] avg_epoch_loss=0.001843\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=0.0018426133319735527\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:24 INFO 140043348993664] Epoch[182] Batch[5] avg_epoch_loss=-0.463799\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=-0.46379852869237465\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:24 INFO 140043348993664] Epoch[182] Batch [5]#011Speed: 75.03 samples/sec#011loss=-0.463799\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] Epoch[182] Batch[10] avg_epoch_loss=-0.533577\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=-0.6173120617866517\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] Epoch[182] Batch [10]#011Speed: 71.76 samples/sec#011loss=-0.617312\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742438.1590314, \"EndTime\": 1646742449.9608376, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11800.301313400269, \"count\": 1, \"min\": 11800.301313400269, \"max\": 11800.301313400269}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.33618426299032 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] #progress_metric: host=algo-1, completed 45.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=182, train loss <loss>=-0.5575286029682806\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:29 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:32 INFO 140043348993664] Epoch[183] Batch[0] avg_epoch_loss=-0.569346\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=-0.5693464279174805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:36 INFO 140043348993664] Epoch[183] Batch[5] avg_epoch_loss=-0.701691\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=-0.7016913791497549\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:36 INFO 140043348993664] Epoch[183] Batch [5]#011Speed: 76.50 samples/sec#011loss=-0.701691\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] Epoch[183] Batch[10] avg_epoch_loss=-0.748778\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=-0.8052819252014161\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] Epoch[183] Batch [10]#011Speed: 72.65 samples/sec#011loss=-0.805282\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742449.96097, \"EndTime\": 1646742460.838625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10876.010656356812, \"count\": 1, \"min\": 10876.010656356812, \"max\": 10876.010656356812}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.865683635363816 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=183, train loss <loss>=-0.7487779909914191\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:40 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:43 INFO 140043348993664] Epoch[184] Batch[0] avg_epoch_loss=-0.800862\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=-0.8008615374565125\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:47 INFO 140043348993664] Epoch[184] Batch[5] avg_epoch_loss=-0.807165\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=-0.8071654736995697\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:47 INFO 140043348993664] Epoch[184] Batch [5]#011Speed: 74.31 samples/sec#011loss=-0.807165\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:51 INFO 140043348993664] Epoch[184] Batch[10] avg_epoch_loss=-0.833919\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=-0.8660239815711975\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:51 INFO 140043348993664] Epoch[184] Batch [10]#011Speed: 69.72 samples/sec#011loss=-0.866024\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:53 INFO 140043348993664] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742460.83896, \"EndTime\": 1646742473.1715088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12331.12645149231, \"count\": 1, \"min\": 12331.12645149231, \"max\": 12331.12645149231}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:53 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.73831889970959 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:53 INFO 140043348993664] #progress_metric: host=algo-1, completed 46.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=184, train loss <loss>=-0.8524087369441986\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:53 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:55 INFO 140043348993664] Epoch[185] Batch[0] avg_epoch_loss=-0.807268\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=-0.8072683215141296\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:59 INFO 140043348993664] Epoch[185] Batch[5] avg_epoch_loss=-0.751764\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=-0.7517640391985575\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:27:59 INFO 140043348993664] Epoch[185] Batch [5]#011Speed: 74.73 samples/sec#011loss=-0.751764\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] Epoch[185] Batch[10] avg_epoch_loss=-0.745260\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=-0.7374562442302703\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] Epoch[185] Batch [10]#011Speed: 69.41 samples/sec#011loss=-0.737456\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742473.1716151, \"EndTime\": 1646742484.2972493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11124.308109283447, \"count\": 1, \"min\": 11124.308109283447, \"max\": 11124.308109283447}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.58596668582999 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 46.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=185, train loss <loss>=-0.7452604960311543\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:04 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:06 INFO 140043348993664] Epoch[186] Batch[0] avg_epoch_loss=-0.756914\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=-0.7569141983985901\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:11 INFO 140043348993664] Epoch[186] Batch[5] avg_epoch_loss=-0.737911\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=-0.7379109362761179\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:11 INFO 140043348993664] Epoch[186] Batch [5]#011Speed: 73.15 samples/sec#011loss=-0.737911\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:14 INFO 140043348993664] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742484.2975872, \"EndTime\": 1646742494.7326994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10433.897256851196, \"count\": 1, \"min\": 10433.897256851196, \"max\": 10433.897256851196}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.33777521034033 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 46.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=186, train loss <loss>=-0.7680632293224334\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:14 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:16 INFO 140043348993664] Epoch[187] Batch[0] avg_epoch_loss=-0.874912\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=-0.8749118447303772\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:21 INFO 140043348993664] Epoch[187] Batch[5] avg_epoch_loss=-0.851786\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=-0.8517856299877167\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:21 INFO 140043348993664] Epoch[187] Batch [5]#011Speed: 73.60 samples/sec#011loss=-0.851786\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] Epoch[187] Batch[10] avg_epoch_loss=-0.859070\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=-0.8678104400634765\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] Epoch[187] Batch [10]#011Speed: 72.32 samples/sec#011loss=-0.867810\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742494.7327933, \"EndTime\": 1646742505.7226036, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10989.302635192871, \"count\": 1, \"min\": 10989.302635192871, \"max\": 10989.302635192871}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.329413657032994 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=187, train loss <loss>=-0.8590696345676075\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:25 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:27 INFO 140043348993664] Epoch[188] Batch[0] avg_epoch_loss=-0.792409\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=-0.7924086451530457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:32 INFO 140043348993664] Epoch[188] Batch[5] avg_epoch_loss=-0.852576\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=-0.852576345205307\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:32 INFO 140043348993664] Epoch[188] Batch [5]#011Speed: 73.69 samples/sec#011loss=-0.852576\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:35 INFO 140043348993664] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742505.722736, \"EndTime\": 1646742515.8364441, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10112.956762313843, \"count\": 1, \"min\": 10112.956762313843, \"max\": 10112.956762313843}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.49313379475651 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 47.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=188, train loss <loss>=-0.8551466524600982\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:38 INFO 140043348993664] Epoch[189] Batch[0] avg_epoch_loss=-0.883611\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=-0.8836105465888977\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:42 INFO 140043348993664] Epoch[189] Batch[5] avg_epoch_loss=-0.924645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=-0.9246446887652079\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:42 INFO 140043348993664] Epoch[189] Batch [5]#011Speed: 74.29 samples/sec#011loss=-0.924645\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] Epoch[189] Batch[10] avg_epoch_loss=-0.935917\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=-0.9494429349899292\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] Epoch[189] Batch [10]#011Speed: 72.95 samples/sec#011loss=-0.949443\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742515.8365562, \"EndTime\": 1646742526.7312498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10893.92638206482, \"count\": 1, \"min\": 10893.92638206482, \"max\": 10893.92638206482}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.603026411704356 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 47.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=189, train loss <loss>=-0.935916618867354\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:46 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_69d4c5d2-a0c1-4b01-aee1-e30d4c66560f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742526.731326, \"EndTime\": 1646742526.846359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 114.48478698730469, \"count\": 1, \"min\": 114.48478698730469, \"max\": 114.48478698730469}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:49 INFO 140043348993664] Epoch[190] Batch[0] avg_epoch_loss=-0.982114\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=-0.9821136593818665\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:53 INFO 140043348993664] Epoch[190] Batch[5] avg_epoch_loss=-0.942719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=-0.9427191019058228\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:53 INFO 140043348993664] Epoch[190] Batch [5]#011Speed: 73.84 samples/sec#011loss=-0.942719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] Epoch[190] Batch[10] avg_epoch_loss=-0.947491\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=-0.953217339515686\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] Epoch[190] Batch [10]#011Speed: 74.40 samples/sec#011loss=-0.953217\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742526.846429, \"EndTime\": 1646742537.701365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10854.868173599243, \"count\": 1, \"min\": 10854.868173599243, \"max\": 10854.868173599243}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.92043334147538 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 47.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=190, train loss <loss>=-0.9474910280921243\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:28:57 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_3cf016d0-d789-4aa1-b45d-68f9517502b3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742537.7014406, \"EndTime\": 1646742537.8285868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 126.66440010070801, \"count\": 1, \"min\": 126.66440010070801, \"max\": 126.66440010070801}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:00 INFO 140043348993664] Epoch[191] Batch[0] avg_epoch_loss=-0.915036\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=-0.9150363206863403\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:04 INFO 140043348993664] Epoch[191] Batch[5] avg_epoch_loss=-0.850197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=-0.8501971662044525\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:04 INFO 140043348993664] Epoch[191] Batch [5]#011Speed: 73.05 samples/sec#011loss=-0.850197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] Epoch[191] Batch[10] avg_epoch_loss=-0.823465\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=-0.7913861870765686\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] Epoch[191] Batch [10]#011Speed: 64.74 samples/sec#011loss=-0.791386\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742537.8289912, \"EndTime\": 1646742549.3925967, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11563.505172729492, \"count\": 1, \"min\": 11563.505172729492, \"max\": 11563.505172729492}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.333554819974516 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=191, train loss <loss>=-0.8234649029645053\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:09 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:11 INFO 140043348993664] Epoch[192] Batch[0] avg_epoch_loss=-0.388674\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=-0.3886740207672119\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:16 INFO 140043348993664] Epoch[192] Batch[5] avg_epoch_loss=-0.527050\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=-0.5270500083764394\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:16 INFO 140043348993664] Epoch[192] Batch [5]#011Speed: 71.63 samples/sec#011loss=-0.527050\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] Epoch[192] Batch[10] avg_epoch_loss=-0.629517\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=-0.7524768352508545\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] Epoch[192] Batch [10]#011Speed: 73.21 samples/sec#011loss=-0.752477\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742549.3929608, \"EndTime\": 1646742560.4439988, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11049.645185470581, \"count\": 1, \"min\": 11049.645185470581, \"max\": 11049.645185470581}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.986935246543204 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 48.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=192, train loss <loss>=-0.6295167478648099\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:22 INFO 140043348993664] Epoch[193] Batch[0] avg_epoch_loss=-0.793849\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=-0.7938488125801086\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:27 INFO 140043348993664] Epoch[193] Batch[5] avg_epoch_loss=-0.782657\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=-0.7826568186283112\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:27 INFO 140043348993664] Epoch[193] Batch [5]#011Speed: 73.18 samples/sec#011loss=-0.782657\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:30 INFO 140043348993664] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742560.4440885, \"EndTime\": 1646742570.4864497, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10041.120767593384, \"count\": 1, \"min\": 10041.120767593384, \"max\": 10041.120767593384}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:30 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.246198611719535 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:30 INFO 140043348993664] #progress_metric: host=algo-1, completed 48.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=193, train loss <loss>=-0.8150672614574432\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:30 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:32 INFO 140043348993664] Epoch[194] Batch[0] avg_epoch_loss=-0.894195\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=-0.8941951990127563\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:37 INFO 140043348993664] Epoch[194] Batch[5] avg_epoch_loss=-0.889510\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=-0.8895099957784017\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:37 INFO 140043348993664] Epoch[194] Batch [5]#011Speed: 72.80 samples/sec#011loss=-0.889510\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] Epoch[194] Batch[10] avg_epoch_loss=-0.898257\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=-0.9087528228759766\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] Epoch[194] Batch [10]#011Speed: 71.54 samples/sec#011loss=-0.908753\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742570.4867215, \"EndTime\": 1646742581.635505, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11147.273540496826, \"count\": 1, \"min\": 11147.273540496826, \"max\": 11147.273540496826}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.34643995212802 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 48.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=194, train loss <loss>=-0.8982567353682085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:41 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:43 INFO 140043348993664] Epoch[195] Batch[0] avg_epoch_loss=-0.951190\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=-0.951190173625946\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:48 INFO 140043348993664] Epoch[195] Batch[5] avg_epoch_loss=-0.967785\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=-0.9677851796150208\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:48 INFO 140043348993664] Epoch[195] Batch [5]#011Speed: 74.65 samples/sec#011loss=-0.967785\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] Epoch[195] Batch[10] avg_epoch_loss=-0.994884\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=-1.027401614189148\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] Epoch[195] Batch [10]#011Speed: 73.87 samples/sec#011loss=-1.027402\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742581.635583, \"EndTime\": 1646742592.5851538, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10949.117660522461, \"count\": 1, \"min\": 10949.117660522461, \"max\": 10949.117660522461}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.27801733134134 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=195, train loss <loss>=-0.9948835589668967\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:52 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_3236378d-71ef-46db-9bde-3912dadc56db-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742592.5852644, \"EndTime\": 1646742592.7056673, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 119.32969093322754, \"count\": 1, \"min\": 119.32969093322754, \"max\": 119.32969093322754}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:54 INFO 140043348993664] Epoch[196] Batch[0] avg_epoch_loss=-0.974548\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=-0.974547803401947\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:59 INFO 140043348993664] Epoch[196] Batch[5] avg_epoch_loss=-0.916176\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=-0.9161762197812399\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:29:59 INFO 140043348993664] Epoch[196] Batch [5]#011Speed: 75.22 samples/sec#011loss=-0.916176\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:02 INFO 140043348993664] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742592.7057843, \"EndTime\": 1646742602.8411076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10135.244846343994, \"count\": 1, \"min\": 10135.244846343994, \"max\": 10135.244846343994}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:02 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.256003953362814 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:02 INFO 140043348993664] #progress_metric: host=algo-1, completed 49.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=196, train loss <loss>=-0.9114844501018524\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:02 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:05 INFO 140043348993664] Epoch[197] Batch[0] avg_epoch_loss=-0.970196\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=-0.9701958298683167\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:09 INFO 140043348993664] Epoch[197] Batch[5] avg_epoch_loss=-0.951065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=-0.9510654111703237\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:09 INFO 140043348993664] Epoch[197] Batch [5]#011Speed: 71.94 samples/sec#011loss=-0.951065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] Epoch[197] Batch[10] avg_epoch_loss=-0.938535\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=-0.9234987735748291\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] Epoch[197] Batch [10]#011Speed: 72.90 samples/sec#011loss=-0.923499\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742602.8412132, \"EndTime\": 1646742614.0532525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11210.519552230835, \"count\": 1, \"min\": 11210.519552230835, \"max\": 11210.519552230835}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.89050118851792 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 49.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=197, train loss <loss>=-0.9385351213541898\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:14 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:16 INFO 140043348993664] Epoch[198] Batch[0] avg_epoch_loss=-1.006749\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=-1.006749153137207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:20 INFO 140043348993664] Epoch[198] Batch[5] avg_epoch_loss=-0.914539\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=-0.9145394563674927\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:20 INFO 140043348993664] Epoch[198] Batch [5]#011Speed: 74.70 samples/sec#011loss=-0.914539\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] Epoch[198] Batch[10] avg_epoch_loss=-0.933614\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=-0.9565024971961975\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] Epoch[198] Batch [10]#011Speed: 74.26 samples/sec#011loss=-0.956502\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742614.05333, \"EndTime\": 1646742624.9631155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10909.336805343628, \"count\": 1, \"min\": 10909.336805343628, \"max\": 10909.336805343628}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.40625224825941 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 49.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=198, train loss <loss>=-0.9336135658350858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:27 INFO 140043348993664] Epoch[199] Batch[0] avg_epoch_loss=-0.973115\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=-0.9731151461601257\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:31 INFO 140043348993664] Epoch[199] Batch[5] avg_epoch_loss=-0.920235\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=-0.9202349583307902\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:31 INFO 140043348993664] Epoch[199] Batch [5]#011Speed: 75.63 samples/sec#011loss=-0.920235\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] Epoch[199] Batch[10] avg_epoch_loss=-0.916028\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=-0.9109806656837464\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] Epoch[199] Batch [10]#011Speed: 70.98 samples/sec#011loss=-0.910981\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742624.9632056, \"EndTime\": 1646742636.0990841, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11134.835481643677, \"count\": 1, \"min\": 11134.835481643677, \"max\": 11134.835481643677}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.91202704109763 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=199, train loss <loss>=-0.916028461673043\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:36 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:38 INFO 140043348993664] Epoch[200] Batch[0] avg_epoch_loss=-0.923263\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=-0.9232629537582397\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:42 INFO 140043348993664] Epoch[200] Batch[5] avg_epoch_loss=-0.928930\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=-0.928930252790451\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:42 INFO 140043348993664] Epoch[200] Batch [5]#011Speed: 76.60 samples/sec#011loss=-0.928930\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] Epoch[200] Batch[10] avg_epoch_loss=-0.885919\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=-0.8343044400215149\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] Epoch[200] Batch [10]#011Speed: 75.23 samples/sec#011loss=-0.834304\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742636.0993884, \"EndTime\": 1646742646.829821, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10729.231357574463, \"count\": 1, \"min\": 10729.231357574463, \"max\": 10729.231357574463}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.75037353214516 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 50.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=200, train loss <loss>=-0.8859185197136619\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:49 INFO 140043348993664] Epoch[201] Batch[0] avg_epoch_loss=-0.949971\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=-0.949970543384552\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:53 INFO 140043348993664] Epoch[201] Batch[5] avg_epoch_loss=-0.906207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=-0.9062071144580841\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:53 INFO 140043348993664] Epoch[201] Batch [5]#011Speed: 76.56 samples/sec#011loss=-0.906207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] Epoch[201] Batch[10] avg_epoch_loss=-0.907546\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=-0.909152376651764\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] Epoch[201] Batch [10]#011Speed: 74.61 samples/sec#011loss=-0.909152\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742646.8298993, \"EndTime\": 1646742657.5048614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10674.494981765747, \"count\": 1, \"min\": 10674.494981765747, \"max\": 10674.494981765747}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.20199168830378 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 50.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=201, train loss <loss>=-0.9075458700006659\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:59 INFO 140043348993664] Epoch[202] Batch[0] avg_epoch_loss=-0.875341\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:30:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=-0.8753411769866943\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:04 INFO 140043348993664] Epoch[202] Batch[5] avg_epoch_loss=-0.833487\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=-0.8334868351618449\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:04 INFO 140043348993664] Epoch[202] Batch [5]#011Speed: 70.85 samples/sec#011loss=-0.833487\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] Epoch[202] Batch[10] avg_epoch_loss=-0.855299\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=-0.8814735174179077\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] Epoch[202] Batch [10]#011Speed: 68.40 samples/sec#011loss=-0.881474\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742657.5052254, \"EndTime\": 1646742668.9621484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11455.49726486206, \"count\": 1, \"min\": 11455.49726486206, \"max\": 11455.49726486206}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.534143256966594 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] #progress_metric: host=algo-1, completed 50.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=202, train loss <loss>=-0.8552989634600553\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:08 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:11 INFO 140043348993664] Epoch[203] Batch[0] avg_epoch_loss=-0.775595\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=-0.7755951881408691\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:15 INFO 140043348993664] Epoch[203] Batch[5] avg_epoch_loss=-0.818162\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=-0.8181617756684622\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:15 INFO 140043348993664] Epoch[203] Batch [5]#011Speed: 72.82 samples/sec#011loss=-0.818162\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:19 INFO 140043348993664] Epoch[203] Batch[10] avg_epoch_loss=-0.862419\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=-0.9155285239219666\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:19 INFO 140043348993664] Epoch[203] Batch [10]#011Speed: 74.13 samples/sec#011loss=-0.915529\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:20 INFO 140043348993664] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742668.962226, \"EndTime\": 1646742680.650429, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11687.735319137573, \"count\": 1, \"min\": 11687.735319137573, \"max\": 11687.735319137573}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.17284421287817 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 51.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=203, train loss <loss>=-0.8716561744610468\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:22 INFO 140043348993664] Epoch[204] Batch[0] avg_epoch_loss=-0.794659\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=-0.7946592569351196\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:27 INFO 140043348993664] Epoch[204] Batch[5] avg_epoch_loss=-0.890362\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=-0.890362004439036\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:27 INFO 140043348993664] Epoch[204] Batch [5]#011Speed: 75.24 samples/sec#011loss=-0.890362\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:30 INFO 140043348993664] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742680.6508384, \"EndTime\": 1646742690.5874028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9935.082912445068, \"count\": 1, \"min\": 9935.082912445068, \"max\": 9935.082912445068}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:30 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.31677747288862 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:30 INFO 140043348993664] #progress_metric: host=algo-1, completed 51.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=204, train loss <loss>=-0.892129099369049\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:30 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:32 INFO 140043348993664] Epoch[205] Batch[0] avg_epoch_loss=-0.911605\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=-0.9116052389144897\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:36 INFO 140043348993664] Epoch[205] Batch[5] avg_epoch_loss=-0.947750\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=-0.9477497140566508\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:36 INFO 140043348993664] Epoch[205] Batch [5]#011Speed: 76.06 samples/sec#011loss=-0.947750\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] Epoch[205] Batch[10] avg_epoch_loss=-0.942652\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=-0.9365351915359497\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] Epoch[205] Batch [10]#011Speed: 73.39 samples/sec#011loss=-0.936535\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742690.5874798, \"EndTime\": 1646742701.3526075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10764.639377593994, \"count\": 1, \"min\": 10764.639377593994, \"max\": 10764.639377593994}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.23825359092912 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 51.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=205, train loss <loss>=-0.9426522038199685\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:41 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:43 INFO 140043348993664] Epoch[206] Batch[0] avg_epoch_loss=-0.966785\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=-0.9667852520942688\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:47 INFO 140043348993664] Epoch[206] Batch[5] avg_epoch_loss=-0.975447\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=-0.9754474659760793\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:47 INFO 140043348993664] Epoch[206] Batch [5]#011Speed: 75.04 samples/sec#011loss=-0.975447\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:51 INFO 140043348993664] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742701.352985, \"EndTime\": 1646742711.3639827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10009.58228111267, \"count\": 1, \"min\": 10009.58228111267, \"max\": 10009.58228111267}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:51 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.93748178475008 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:51 INFO 140043348993664] #progress_metric: host=algo-1, completed 51.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=206, train loss <loss>=-0.9869147837162018\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:51 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:53 INFO 140043348993664] Epoch[207] Batch[0] avg_epoch_loss=-0.971851\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=-0.9718509316444397\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:58 INFO 140043348993664] Epoch[207] Batch[5] avg_epoch_loss=-0.868718\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=-0.8687177300453186\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:31:58 INFO 140043348993664] Epoch[207] Batch [5]#011Speed: 73.03 samples/sec#011loss=-0.868718\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] Epoch[207] Batch[10] avg_epoch_loss=-0.920784\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=-0.9832635402679444\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] Epoch[207] Batch [10]#011Speed: 71.78 samples/sec#011loss=-0.983264\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742711.364136, \"EndTime\": 1646742722.4915023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11126.511335372925, \"count\": 1, \"min\": 11126.511335372925, \"max\": 11126.511335372925}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.31704333500455 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=207, train loss <loss>=-0.9207840074192394\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:02 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:04 INFO 140043348993664] Epoch[208] Batch[0] avg_epoch_loss=-0.937384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=-0.9373844265937805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:09 INFO 140043348993664] Epoch[208] Batch[5] avg_epoch_loss=-0.970125\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=-0.9701246420542399\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:09 INFO 140043348993664] Epoch[208] Batch [5]#011Speed: 69.73 samples/sec#011loss=-0.970125\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] Epoch[208] Batch[10] avg_epoch_loss=-0.968957\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=-0.9675561666488648\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] Epoch[208] Batch [10]#011Speed: 70.98 samples/sec#011loss=-0.967556\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742722.4916024, \"EndTime\": 1646742733.862442, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11370.216846466064, \"count\": 1, \"min\": 11370.216846466064, \"max\": 11370.216846466064}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.33080658154968 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 52.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=208, train loss <loss>=-0.9689571532336149\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:16 INFO 140043348993664] Epoch[209] Batch[0] avg_epoch_loss=-0.928115\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=-0.92811518907547\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:20 INFO 140043348993664] Epoch[209] Batch[5] avg_epoch_loss=-0.906715\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=-0.9067153831322988\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:20 INFO 140043348993664] Epoch[209] Batch [5]#011Speed: 75.77 samples/sec#011loss=-0.906715\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] Epoch[209] Batch[10] avg_epoch_loss=-0.910660\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=-0.9153942346572876\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] Epoch[209] Batch [10]#011Speed: 71.64 samples/sec#011loss=-0.915394\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742733.8628042, \"EndTime\": 1646742744.782211, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10918.016195297241, \"count\": 1, \"min\": 10918.016195297241, \"max\": 10918.016195297241}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.563710345274565 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 52.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=209, train loss <loss>=-0.9106603156436573\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:27 INFO 140043348993664] Epoch[210] Batch[0] avg_epoch_loss=-0.995682\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=-0.9956817626953125\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:31 INFO 140043348993664] Epoch[210] Batch[5] avg_epoch_loss=-0.936046\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=-0.936045914888382\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:31 INFO 140043348993664] Epoch[210] Batch [5]#011Speed: 74.52 samples/sec#011loss=-0.936046\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] Epoch[210] Batch[10] avg_epoch_loss=-0.866719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=-0.7835256099700928\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] Epoch[210] Batch [10]#011Speed: 73.80 samples/sec#011loss=-0.783526\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742744.7823355, \"EndTime\": 1646742755.7062688, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10923.230171203613, \"count\": 1, \"min\": 10923.230171203613, \"max\": 10923.230171203613}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.71504339846905 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 52.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=210, train loss <loss>=-0.8667185035618868\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:37 INFO 140043348993664] Epoch[211] Batch[0] avg_epoch_loss=-0.921299\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=-0.921299159526825\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:42 INFO 140043348993664] Epoch[211] Batch[5] avg_epoch_loss=-0.880935\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=-0.8809348940849304\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:42 INFO 140043348993664] Epoch[211] Batch [5]#011Speed: 75.50 samples/sec#011loss=-0.880935\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] Epoch[211] Batch[10] avg_epoch_loss=-0.869508\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=-0.8557950377464294\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] Epoch[211] Batch [10]#011Speed: 74.40 samples/sec#011loss=-0.855795\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742755.706629, \"EndTime\": 1646742766.4935057, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10785.562753677368, \"count\": 1, \"min\": 10785.562753677368, \"max\": 10785.562753677368}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.61576696533967 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 53.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=211, train loss <loss>=-0.8695076866583391\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:48 INFO 140043348993664] Epoch[212] Batch[0] avg_epoch_loss=-0.668929\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=-0.6689291000366211\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:52 INFO 140043348993664] Epoch[212] Batch[5] avg_epoch_loss=-0.754368\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=-0.7543676296869913\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:52 INFO 140043348993664] Epoch[212] Batch [5]#011Speed: 75.77 samples/sec#011loss=-0.754368\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] Epoch[212] Batch[10] avg_epoch_loss=-0.799334\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=-0.8532944321632385\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] Epoch[212] Batch [10]#011Speed: 73.44 samples/sec#011loss=-0.853294\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742766.493644, \"EndTime\": 1646742777.3342052, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10839.478015899658, \"count\": 1, \"min\": 10839.478015899658, \"max\": 10839.478015899658}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.79548048167865 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 53.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=212, train loss <loss>=-0.7993343580852855\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:59 INFO 140043348993664] Epoch[213] Batch[0] avg_epoch_loss=-0.821198\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:32:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=-0.8211981654167175\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:04 INFO 140043348993664] Epoch[213] Batch[5] avg_epoch_loss=-0.860220\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=-0.8602203726768494\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:04 INFO 140043348993664] Epoch[213] Batch [5]#011Speed: 70.61 samples/sec#011loss=-0.860220\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] Epoch[213] Batch[10] avg_epoch_loss=-0.896996\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=-0.9411257028579711\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] Epoch[213] Batch [10]#011Speed: 70.86 samples/sec#011loss=-0.941126\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742777.3342946, \"EndTime\": 1646742788.6310635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11296.069383621216, \"count\": 1, \"min\": 11296.069383621216, \"max\": 11296.069383621216}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.690883824080544 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] #progress_metric: host=algo-1, completed 53.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=213, train loss <loss>=-0.8969955227591775\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:08 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:10 INFO 140043348993664] Epoch[214] Batch[0] avg_epoch_loss=-0.909207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=-0.9092073440551758\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:15 INFO 140043348993664] Epoch[214] Batch[5] avg_epoch_loss=-0.949373\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=-0.9493726094563802\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:15 INFO 140043348993664] Epoch[214] Batch [5]#011Speed: 70.71 samples/sec#011loss=-0.949373\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] Epoch[214] Batch[10] avg_epoch_loss=-0.951497\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=-0.9540452241897583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] Epoch[214] Batch [10]#011Speed: 70.81 samples/sec#011loss=-0.954045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742788.631401, \"EndTime\": 1646742800.0209715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11388.25535774231, \"count\": 1, \"min\": 11388.25535774231, \"max\": 11388.25535774231}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.464578113873856 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 53.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=214, train loss <loss>=-0.9514965252442793\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:22 INFO 140043348993664] Epoch[215] Batch[0] avg_epoch_loss=-1.016620\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=-1.0166199207305908\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:26 INFO 140043348993664] Epoch[215] Batch[5] avg_epoch_loss=-0.920273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=-0.9202732046445211\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:26 INFO 140043348993664] Epoch[215] Batch [5]#011Speed: 72.78 samples/sec#011loss=-0.920273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] Epoch[215] Batch[10] avg_epoch_loss=-0.933103\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=-0.948499596118927\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] Epoch[215] Batch [10]#011Speed: 72.17 samples/sec#011loss=-0.948500\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742800.0213473, \"EndTime\": 1646742811.0958655, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11073.0881690979, \"count\": 1, \"min\": 11073.0881690979, \"max\": 11073.0881690979}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.78980370563534 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] #progress_metric: host=algo-1, completed 54.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=215, train loss <loss>=-0.9331033825874329\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:31 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:33 INFO 140043348993664] Epoch[216] Batch[0] avg_epoch_loss=-0.986736\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=-0.9867359399795532\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:37 INFO 140043348993664] Epoch[216] Batch[5] avg_epoch_loss=-0.907959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=-0.9079594214757284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:37 INFO 140043348993664] Epoch[216] Batch [5]#011Speed: 76.80 samples/sec#011loss=-0.907959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] Epoch[216] Batch[10] avg_epoch_loss=-0.912453\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=-0.9178461194038391\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] Epoch[216] Batch [10]#011Speed: 71.34 samples/sec#011loss=-0.917846\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742811.0959482, \"EndTime\": 1646742822.0288353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10931.575298309326, \"count\": 1, \"min\": 10931.575298309326, \"max\": 10931.575298309326}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.10492928648082 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] #progress_metric: host=algo-1, completed 54.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=216, train loss <loss>=-0.912453375079415\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:42 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:44 INFO 140043348993664] Epoch[217] Batch[0] avg_epoch_loss=-0.752582\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=-0.7525818347930908\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:48 INFO 140043348993664] Epoch[217] Batch[5] avg_epoch_loss=-0.883685\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=-0.8836845556894938\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:48 INFO 140043348993664] Epoch[217] Batch [5]#011Speed: 73.24 samples/sec#011loss=-0.883685\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] Epoch[217] Batch[10] avg_epoch_loss=-0.868248\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=-0.8497250556945801\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] Epoch[217] Batch [10]#011Speed: 74.77 samples/sec#011loss=-0.849725\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742822.029226, \"EndTime\": 1646742833.027262, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10996.591567993164, \"count\": 1, \"min\": 10996.591567993164, \"max\": 10996.591567993164}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.288931790912876 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] #progress_metric: host=algo-1, completed 54.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=217, train loss <loss>=-0.8682484193281694\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:53 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:55 INFO 140043348993664] Epoch[218] Batch[0] avg_epoch_loss=-0.659983\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=-0.6599828600883484\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:59 INFO 140043348993664] Epoch[218] Batch[5] avg_epoch_loss=-0.732062\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=-0.7320622404416403\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:33:59 INFO 140043348993664] Epoch[218] Batch [5]#011Speed: 71.88 samples/sec#011loss=-0.732062\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] Epoch[218] Batch[10] avg_epoch_loss=-0.808465\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=-0.9001484155654907\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] Epoch[218] Batch [10]#011Speed: 71.12 samples/sec#011loss=-0.900148\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742833.0276167, \"EndTime\": 1646742844.3019826, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11273.020267486572, \"count\": 1, \"min\": 11273.020267486572, \"max\": 11273.020267486572}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.21568243197701 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 54.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=218, train loss <loss>=-0.8084650473161177\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:04 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:06 INFO 140043348993664] Epoch[219] Batch[0] avg_epoch_loss=-0.416203\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=-0.41620302200317383\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:10 INFO 140043348993664] Epoch[219] Batch[5] avg_epoch_loss=-0.667171\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=-0.6671706338723501\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:10 INFO 140043348993664] Epoch[219] Batch [5]#011Speed: 73.97 samples/sec#011loss=-0.667171\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] Epoch[219] Batch[10] avg_epoch_loss=-0.715798\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=-0.7741508722305298\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] Epoch[219] Batch [10]#011Speed: 72.84 samples/sec#011loss=-0.774151\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742844.302057, \"EndTime\": 1646742855.3652682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11062.755107879639, \"count\": 1, \"min\": 11062.755107879639, \"max\": 11062.755107879639}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.911722193220896 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=219, train loss <loss>=-0.7157980149442499\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:15 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:17 INFO 140043348993664] Epoch[220] Batch[0] avg_epoch_loss=-0.826396\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=-0.826395571231842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:22 INFO 140043348993664] Epoch[220] Batch[5] avg_epoch_loss=-0.875230\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=-0.8752303520838419\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:22 INFO 140043348993664] Epoch[220] Batch [5]#011Speed: 72.72 samples/sec#011loss=-0.875230\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] Epoch[220] Batch[10] avg_epoch_loss=-0.912351\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=-0.9568963766098022\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] Epoch[220] Batch [10]#011Speed: 71.27 samples/sec#011loss=-0.956896\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742855.3655958, \"EndTime\": 1646742866.5320678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11165.115356445312, \"count\": 1, \"min\": 11165.115356445312, \"max\": 11165.115356445312}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.21643627204701 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 55.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=220, train loss <loss>=-0.9123512723229148\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:26 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:28 INFO 140043348993664] Epoch[221] Batch[0] avg_epoch_loss=-0.737087\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=-0.7370867133140564\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:33 INFO 140043348993664] Epoch[221] Batch[5] avg_epoch_loss=-0.825677\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=-0.8256765802701315\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:33 INFO 140043348993664] Epoch[221] Batch [5]#011Speed: 72.32 samples/sec#011loss=-0.825677\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] Epoch[221] Batch[10] avg_epoch_loss=-0.884046\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=-0.9540888667106628\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] Epoch[221] Batch [10]#011Speed: 72.03 samples/sec#011loss=-0.954089\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742866.5321457, \"EndTime\": 1646742877.6189847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11086.377143859863, \"count\": 1, \"min\": 11086.377143859863, \"max\": 11086.377143859863}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.99849815460715 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 55.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=221, train loss <loss>=-0.8840458013794639\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:40 INFO 140043348993664] Epoch[222] Batch[0] avg_epoch_loss=-0.894816\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=-0.8948161005973816\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:44 INFO 140043348993664] Epoch[222] Batch[5] avg_epoch_loss=-0.904803\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=-0.904803454875946\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:44 INFO 140043348993664] Epoch[222] Batch [5]#011Speed: 74.71 samples/sec#011loss=-0.904803\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] Epoch[222] Batch[10] avg_epoch_loss=-0.929267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=-0.9586242437362671\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] Epoch[222] Batch [10]#011Speed: 70.86 samples/sec#011loss=-0.958624\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742877.6190653, \"EndTime\": 1646742888.8135872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11194.071769714355, \"count\": 1, \"min\": 11194.071769714355, \"max\": 11194.071769714355}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.77899121963043 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 55.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=222, train loss <loss>=-0.9292674498124556\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:51 INFO 140043348993664] Epoch[223] Batch[0] avg_epoch_loss=-0.998096\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=-0.9980963468551636\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:55 INFO 140043348993664] Epoch[223] Batch[5] avg_epoch_loss=-0.927942\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=-0.927941769361496\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:55 INFO 140043348993664] Epoch[223] Batch [5]#011Speed: 76.21 samples/sec#011loss=-0.927942\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] Epoch[223] Batch[10] avg_epoch_loss=-0.936810\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=-0.9474520325660706\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] Epoch[223] Batch [10]#011Speed: 73.05 samples/sec#011loss=-0.947452\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742888.813951, \"EndTime\": 1646742899.67702, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10861.68098449707, \"count\": 1, \"min\": 10861.68098449707, \"max\": 10861.68098449707}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.49815394368416 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=223, train loss <loss>=-0.9368100708181207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:34:59 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:02 INFO 140043348993664] Epoch[224] Batch[0] avg_epoch_loss=-0.819133\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=-0.8191325068473816\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:06 INFO 140043348993664] Epoch[224] Batch[5] avg_epoch_loss=-0.772016\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=-0.7720163563887278\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:06 INFO 140043348993664] Epoch[224] Batch [5]#011Speed: 73.71 samples/sec#011loss=-0.772016\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] Epoch[224] Batch[10] avg_epoch_loss=-0.799269\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=-0.8319731235504151\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] Epoch[224] Batch [10]#011Speed: 68.11 samples/sec#011loss=-0.831973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742899.6773906, \"EndTime\": 1646742911.2330024, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11554.041385650635, \"count\": 1, \"min\": 11554.041385650635, \"max\": 11554.041385650635}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.89964459676965 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] #progress_metric: host=algo-1, completed 56.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=224, train loss <loss>=-0.7992694323713129\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:11 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:13 INFO 140043348993664] Epoch[225] Batch[0] avg_epoch_loss=-0.800235\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=-0.800235390663147\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:17 INFO 140043348993664] Epoch[225] Batch[5] avg_epoch_loss=-0.898812\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=-0.8988116284211477\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:17 INFO 140043348993664] Epoch[225] Batch [5]#011Speed: 72.93 samples/sec#011loss=-0.898812\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] Epoch[225] Batch[10] avg_epoch_loss=-0.918919\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=-0.9430468797683715\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] Epoch[225] Batch [10]#011Speed: 72.20 samples/sec#011loss=-0.943047\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742911.2330978, \"EndTime\": 1646742922.3734128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11139.138221740723, \"count\": 1, \"min\": 11139.138221740723, \"max\": 11139.138221740723}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.13291524488686 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 56.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=225, train loss <loss>=-0.918918560851704\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:24 INFO 140043348993664] Epoch[226] Batch[0] avg_epoch_loss=-0.940413\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=-0.9404132962226868\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:28 INFO 140043348993664] Epoch[226] Batch[5] avg_epoch_loss=-0.944582\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=-0.9445817470550537\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:28 INFO 140043348993664] Epoch[226] Batch [5]#011Speed: 76.31 samples/sec#011loss=-0.944582\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] Epoch[226] Batch[10] avg_epoch_loss=-0.955617\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=-0.9688602328300476\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] Epoch[226] Batch [10]#011Speed: 73.63 samples/sec#011loss=-0.968860\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742922.373734, \"EndTime\": 1646742933.1017811, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10726.461410522461, \"count\": 1, \"min\": 10726.461410522461, \"max\": 10726.461410522461}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.62975283606596 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 56.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=226, train loss <loss>=-0.9556174224073236\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:35 INFO 140043348993664] Epoch[227] Batch[0] avg_epoch_loss=-0.903759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=-0.9037590026855469\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:39 INFO 140043348993664] Epoch[227] Batch[5] avg_epoch_loss=-0.971781\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=-0.9717805584271749\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:39 INFO 140043348993664] Epoch[227] Batch [5]#011Speed: 72.94 samples/sec#011loss=-0.971781\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] Epoch[227] Batch[10] avg_epoch_loss=-0.995584\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=-1.024148404598236\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] Epoch[227] Batch [10]#011Speed: 70.64 samples/sec#011loss=-1.024148\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742933.1021202, \"EndTime\": 1646742944.30125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11197.786808013916, \"count\": 1, \"min\": 11197.786808013916, \"max\": 11197.786808013916}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.33136391611463 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 57.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=227, train loss <loss>=-0.9955841248685663\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:44 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_9f220ffb-59c4-4531-b0ff-4a95a6739a00-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742944.301614, \"EndTime\": 1646742944.4232652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 120.12887001037598, \"count\": 1, \"min\": 120.12887001037598, \"max\": 120.12887001037598}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:46 INFO 140043348993664] Epoch[228] Batch[0] avg_epoch_loss=-0.965811\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=-0.9658113718032837\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:50 INFO 140043348993664] Epoch[228] Batch[5] avg_epoch_loss=-1.009467\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=-1.0094670454661052\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:50 INFO 140043348993664] Epoch[228] Batch [5]#011Speed: 77.36 samples/sec#011loss=-1.009467\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] Epoch[228] Batch[10] avg_epoch_loss=-0.995915\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=-0.9796536326408386\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] Epoch[228] Batch [10]#011Speed: 73.48 samples/sec#011loss=-0.979654\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742944.423716, \"EndTime\": 1646742955.2100556, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10786.22579574585, \"count\": 1, \"min\": 10786.22579574585, \"max\": 10786.22579574585}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.2997311841623 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 57.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=228, train loss <loss>=-0.9959154941818931\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:55 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_42c3c3cb-8963-49d5-84fb-f1e94200b24d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742955.2103531, \"EndTime\": 1646742955.3388937, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 126.35111808776855, \"count\": 1, \"min\": 126.35111808776855, \"max\": 126.35111808776855}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:57 INFO 140043348993664] Epoch[229] Batch[0] avg_epoch_loss=-0.822178\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:35:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=-0.822177529335022\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:01 INFO 140043348993664] Epoch[229] Batch[5] avg_epoch_loss=-0.881452\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=-0.8814517458279928\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:01 INFO 140043348993664] Epoch[229] Batch [5]#011Speed: 74.92 samples/sec#011loss=-0.881452\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] Epoch[229] Batch[10] avg_epoch_loss=-0.911690\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=-0.9479767322540283\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] Epoch[229] Batch [10]#011Speed: 67.38 samples/sec#011loss=-0.947977\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742955.339295, \"EndTime\": 1646742966.5737274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11234.341144561768, \"count\": 1, \"min\": 11234.341144561768, \"max\": 11234.341144561768}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.507015129389586 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] #progress_metric: host=algo-1, completed 57.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=229, train loss <loss>=-0.9116903760216453\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:06 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:08 INFO 140043348993664] Epoch[230] Batch[0] avg_epoch_loss=-1.040231\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=-1.0402311086654663\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:12 INFO 140043348993664] Epoch[230] Batch[5] avg_epoch_loss=-0.973229\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=-0.9732285638650259\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:12 INFO 140043348993664] Epoch[230] Batch [5]#011Speed: 76.41 samples/sec#011loss=-0.973229\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] Epoch[230] Batch[10] avg_epoch_loss=-0.984719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=-0.9985074400901794\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] Epoch[230] Batch [10]#011Speed: 73.25 samples/sec#011loss=-0.998507\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742966.5738318, \"EndTime\": 1646742977.3468945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10772.277116775513, \"count\": 1, \"min\": 10772.277116775513, \"max\": 10772.277116775513}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.43041999122567 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 57.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=230, train loss <loss>=-0.9847189621491865\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:17 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:19 INFO 140043348993664] Epoch[231] Batch[0] avg_epoch_loss=-0.905570\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=-0.9055702686309814\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:23 INFO 140043348993664] Epoch[231] Batch[5] avg_epoch_loss=-0.893267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=-0.8932665884494781\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:23 INFO 140043348993664] Epoch[231] Batch [5]#011Speed: 75.15 samples/sec#011loss=-0.893267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] Epoch[231] Batch[10] avg_epoch_loss=-0.913658\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=-0.9381269454956055\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] Epoch[231] Batch [10]#011Speed: 72.14 samples/sec#011loss=-0.938127\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742977.3472958, \"EndTime\": 1646742988.323838, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10975.172758102417, \"count\": 1, \"min\": 10975.172758102417, \"max\": 10975.172758102417}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.77575724294022 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=231, train loss <loss>=-0.9136576598340814\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:30 INFO 140043348993664] Epoch[232] Batch[0] avg_epoch_loss=-0.989004\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=-0.9890044331550598\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:34 INFO 140043348993664] Epoch[232] Batch[5] avg_epoch_loss=-0.947204\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=-0.9472042222817739\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:34 INFO 140043348993664] Epoch[232] Batch [5]#011Speed: 74.46 samples/sec#011loss=-0.947204\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:38 INFO 140043348993664] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742988.324196, \"EndTime\": 1646742998.3845289, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10058.911323547363, \"count\": 1, \"min\": 10058.911323547363, \"max\": 10058.911323547363}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:38 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.640218771901424 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:38 INFO 140043348993664] #progress_metric: host=algo-1, completed 58.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=232, train loss <loss>=-0.9379769504070282\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:38 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:40 INFO 140043348993664] Epoch[233] Batch[0] avg_epoch_loss=-0.956962\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=-0.9569621086120605\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:44 INFO 140043348993664] Epoch[233] Batch[5] avg_epoch_loss=-0.977956\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=-0.9779557287693024\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:44 INFO 140043348993664] Epoch[233] Batch [5]#011Speed: 73.66 samples/sec#011loss=-0.977956\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] Epoch[233] Batch[10] avg_epoch_loss=-1.014553\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=-1.0584702134132384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] Epoch[233] Batch [10]#011Speed: 73.07 samples/sec#011loss=-1.058470\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646742998.384903, \"EndTime\": 1646743009.337184, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10950.865030288696, \"count\": 1, \"min\": 10950.865030288696, \"max\": 10950.865030288696}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.36318232513972 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] #progress_metric: host=algo-1, completed 58.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=233, train loss <loss>=-1.0145532217892734\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:49 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_8946ee9a-5013-492b-8dfb-8ebbff530213-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743009.3374717, \"EndTime\": 1646743009.4607885, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 122.26653099060059, \"count\": 1, \"min\": 122.26653099060059, \"max\": 122.26653099060059}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:51 INFO 140043348993664] Epoch[234] Batch[0] avg_epoch_loss=-0.973973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=-0.9739728569984436\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:56 INFO 140043348993664] Epoch[234] Batch[5] avg_epoch_loss=-0.995501\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=-0.9955010215441386\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:36:56 INFO 140043348993664] Epoch[234] Batch [5]#011Speed: 75.63 samples/sec#011loss=-0.995501\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] Epoch[234] Batch[10] avg_epoch_loss=-1.001922\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=-1.0096276164054871\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] Epoch[234] Batch [10]#011Speed: 71.96 samples/sec#011loss=-1.009628\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743009.4610116, \"EndTime\": 1646743020.45845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10997.268199920654, \"count\": 1, \"min\": 10997.268199920654, \"max\": 10997.268199920654}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.55787356738969 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] #progress_metric: host=algo-1, completed 58.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=234, train loss <loss>=-1.0019222010265698\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:00 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:03 INFO 140043348993664] Epoch[235] Batch[0] avg_epoch_loss=-0.890626\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=-0.890625536441803\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:07 INFO 140043348993664] Epoch[235] Batch[5] avg_epoch_loss=-0.933996\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=-0.9339955548445383\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:07 INFO 140043348993664] Epoch[235] Batch [5]#011Speed: 69.42 samples/sec#011loss=-0.933996\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] Epoch[235] Batch[10] avg_epoch_loss=-0.945099\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=-0.9584237933158875\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] Epoch[235] Batch [10]#011Speed: 70.27 samples/sec#011loss=-0.958424\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743020.4588077, \"EndTime\": 1646743032.1813002, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11721.059083938599, \"count\": 1, \"min\": 11721.059083938599, \"max\": 11721.059083938599}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.41559153200719 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=235, train loss <loss>=-0.9450992996042425\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:12 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:14 INFO 140043348993664] Epoch[236] Batch[0] avg_epoch_loss=-1.017715\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=-1.0177152156829834\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:18 INFO 140043348993664] Epoch[236] Batch[5] avg_epoch_loss=-0.964904\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=-0.9649040400981903\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:18 INFO 140043348993664] Epoch[236] Batch [5]#011Speed: 72.75 samples/sec#011loss=-0.964904\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] Epoch[236] Batch[10] avg_epoch_loss=-0.991757\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=-1.0239803910255432\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] Epoch[236] Batch [10]#011Speed: 70.01 samples/sec#011loss=-1.023980\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743032.181729, \"EndTime\": 1646743043.440708, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11257.560014724731, \"count\": 1, \"min\": 11257.560014724731, \"max\": 11257.560014724731}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.823239913793294 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] #progress_metric: host=algo-1, completed 59.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=236, train loss <loss>=-0.9917569268833507\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:23 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:25 INFO 140043348993664] Epoch[237] Batch[0] avg_epoch_loss=-0.977757\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=-0.9777572751045227\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:29 INFO 140043348993664] Epoch[237] Batch[5] avg_epoch_loss=-0.946954\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=-0.9469536344210306\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:29 INFO 140043348993664] Epoch[237] Batch [5]#011Speed: 76.43 samples/sec#011loss=-0.946954\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] Epoch[237] Batch[10] avg_epoch_loss=-0.953630\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=-0.9616427063941956\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] Epoch[237] Batch [10]#011Speed: 72.69 samples/sec#011loss=-0.961643\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743043.4409995, \"EndTime\": 1646743054.187843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10745.792627334595, \"count\": 1, \"min\": 10745.792627334595, \"max\": 10745.792627334595}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.46580894100549 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] #progress_metric: host=algo-1, completed 59.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=237, train loss <loss>=-0.9536304853179238\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:34 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:36 INFO 140043348993664] Epoch[238] Batch[0] avg_epoch_loss=-0.893538\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=-0.8935375213623047\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:40 INFO 140043348993664] Epoch[238] Batch[5] avg_epoch_loss=-0.948672\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=-0.9486722846825918\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:40 INFO 140043348993664] Epoch[238] Batch [5]#011Speed: 75.41 samples/sec#011loss=-0.948672\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:44 INFO 140043348993664] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743054.18794, \"EndTime\": 1646743064.1540625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9965.439558029175, \"count\": 1, \"min\": 9965.439558029175, \"max\": 9965.439558029175}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.41858623833971 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 59.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=238, train loss <loss>=-0.9708377599716187\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:46 INFO 140043348993664] Epoch[239] Batch[0] avg_epoch_loss=-0.934817\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=-0.934816837310791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:50 INFO 140043348993664] Epoch[239] Batch[5] avg_epoch_loss=-0.942467\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=-0.9424673914909363\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:50 INFO 140043348993664] Epoch[239] Batch [5]#011Speed: 76.05 samples/sec#011loss=-0.942467\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] Epoch[239] Batch[10] avg_epoch_loss=-0.949008\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=-0.9568578124046325\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] Epoch[239] Batch [10]#011Speed: 71.68 samples/sec#011loss=-0.956858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743064.1541255, \"EndTime\": 1646743075.7780402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11623.527526855469, \"count\": 1, \"min\": 11623.527526855469, \"max\": 11623.527526855469}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.7373899729377 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=239, train loss <loss>=-0.9812420954306921\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:57 INFO 140043348993664] Epoch[240] Batch[0] avg_epoch_loss=-0.908416\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:37:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=-0.908416211605072\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:02 INFO 140043348993664] Epoch[240] Batch[5] avg_epoch_loss=-0.803691\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=-0.8036912878354391\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:02 INFO 140043348993664] Epoch[240] Batch [5]#011Speed: 70.80 samples/sec#011loss=-0.803691\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] Epoch[240] Batch[10] avg_epoch_loss=-0.819872\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=-0.8392893195152282\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] Epoch[240] Batch [10]#011Speed: 66.70 samples/sec#011loss=-0.839289\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743075.7782803, \"EndTime\": 1646743087.2963252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11516.50619506836, \"count\": 1, \"min\": 11516.50619506836, \"max\": 11516.50619506836}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.4334115847318 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 60.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=240, train loss <loss>=-0.8198722113262523\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:07 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:09 INFO 140043348993664] Epoch[241] Batch[0] avg_epoch_loss=-0.945668\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=-0.9456682205200195\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:13 INFO 140043348993664] Epoch[241] Batch[5] avg_epoch_loss=-0.825037\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=-0.8250367442766825\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:13 INFO 140043348993664] Epoch[241] Batch [5]#011Speed: 75.89 samples/sec#011loss=-0.825037\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:17 INFO 140043348993664] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743087.296411, \"EndTime\": 1646743097.457297, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10159.34681892395, \"count\": 1, \"min\": 10159.34681892395, \"max\": 10159.34681892395}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.69767525685716 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 60.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=241, train loss <loss>=-0.8379965960979462\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:17 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:19 INFO 140043348993664] Epoch[242] Batch[0] avg_epoch_loss=-0.814493\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=-0.8144931793212891\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:24 INFO 140043348993664] Epoch[242] Batch[5] avg_epoch_loss=-0.885240\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=-0.8852396706740061\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:24 INFO 140043348993664] Epoch[242] Batch [5]#011Speed: 72.92 samples/sec#011loss=-0.885240\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] Epoch[242] Batch[10] avg_epoch_loss=-0.913431\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=-0.9472604513168335\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] Epoch[242] Batch [10]#011Speed: 73.01 samples/sec#011loss=-0.947260\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743097.4577177, \"EndTime\": 1646743108.6090863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11149.818181991577, \"count\": 1, \"min\": 11149.818181991577, \"max\": 11149.818181991577}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.653164134296816 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 60.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=242, train loss <loss>=-0.9134309346025641\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:30 INFO 140043348993664] Epoch[243] Batch[0] avg_epoch_loss=-0.953379\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=-0.9533791542053223\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:35 INFO 140043348993664] Epoch[243] Batch[5] avg_epoch_loss=-0.925349\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=-0.9253487487634023\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:35 INFO 140043348993664] Epoch[243] Batch [5]#011Speed: 74.82 samples/sec#011loss=-0.925349\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] Epoch[243] Batch[10] avg_epoch_loss=-0.920266\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=-0.9141666293144226\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] Epoch[243] Batch [10]#011Speed: 71.84 samples/sec#011loss=-0.914167\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743108.609497, \"EndTime\": 1646743119.650829, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11039.905071258545, \"count\": 1, \"min\": 11039.905071258545, \"max\": 11039.905071258545}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.589827039118944 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 61.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=243, train loss <loss>=-0.9202659671956842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:41 INFO 140043348993664] Epoch[244] Batch[0] avg_epoch_loss=-0.805730\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=-0.8057302832603455\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:46 INFO 140043348993664] Epoch[244] Batch[5] avg_epoch_loss=-0.899098\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=-0.8990980287392935\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:46 INFO 140043348993664] Epoch[244] Batch [5]#011Speed: 73.30 samples/sec#011loss=-0.899098\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] Epoch[244] Batch[10] avg_epoch_loss=-0.900548\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=-0.9022872686386109\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] Epoch[244] Batch [10]#011Speed: 71.93 samples/sec#011loss=-0.902287\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743119.650898, \"EndTime\": 1646743130.7330947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11081.248998641968, \"count\": 1, \"min\": 11081.248998641968, \"max\": 11081.248998641968}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.100727846659204 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] #progress_metric: host=algo-1, completed 61.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=244, train loss <loss>=-0.9005476832389832\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:50 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:52 INFO 140043348993664] Epoch[245] Batch[0] avg_epoch_loss=-0.868179\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=-0.868179202079773\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:57 INFO 140043348993664] Epoch[245] Batch[5] avg_epoch_loss=-0.864668\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=-0.8646681209405264\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:38:57 INFO 140043348993664] Epoch[245] Batch [5]#011Speed: 75.62 samples/sec#011loss=-0.864668\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] Epoch[245] Batch[10] avg_epoch_loss=-0.867245\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=-0.8703369498252869\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] Epoch[245] Batch [10]#011Speed: 69.97 samples/sec#011loss=-0.870337\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743130.7331843, \"EndTime\": 1646743141.7163246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10981.768131256104, \"count\": 1, \"min\": 10981.768131256104, \"max\": 10981.768131256104}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.55584493729655 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] #progress_metric: host=algo-1, completed 61.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=245, train loss <loss>=-0.8672448613426902\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:01 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:04 INFO 140043348993664] Epoch[246] Batch[0] avg_epoch_loss=-0.888459\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=-0.8884594440460205\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:08 INFO 140043348993664] Epoch[246] Batch[5] avg_epoch_loss=-0.893346\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=-0.8933455248673757\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:08 INFO 140043348993664] Epoch[246] Batch [5]#011Speed: 68.60 samples/sec#011loss=-0.893346\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] Epoch[246] Batch[10] avg_epoch_loss=-0.920002\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=-0.9519896626472473\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] Epoch[246] Batch [10]#011Speed: 71.68 samples/sec#011loss=-0.951990\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743141.7164106, \"EndTime\": 1646743153.252005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11534.326314926147, \"count\": 1, \"min\": 11534.326314926147, \"max\": 11534.326314926147}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.826830600257054 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 61.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=246, train loss <loss>=-0.9200019511309537\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:15 INFO 140043348993664] Epoch[247] Batch[0] avg_epoch_loss=-0.948435\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=-0.948434591293335\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:19 INFO 140043348993664] Epoch[247] Batch[5] avg_epoch_loss=-0.876456\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=-0.8764556248982748\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:19 INFO 140043348993664] Epoch[247] Batch [5]#011Speed: 76.01 samples/sec#011loss=-0.876456\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] Epoch[247] Batch[10] avg_epoch_loss=-0.876710\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=-0.877014982700348\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] Epoch[247] Batch [10]#011Speed: 72.39 samples/sec#011loss=-0.877015\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743153.2520814, \"EndTime\": 1646743164.153251, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10900.718212127686, \"count\": 1, \"min\": 10900.718212127686, \"max\": 10900.718212127686}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.369771397610855 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 62.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=247, train loss <loss>=-0.8767098784446716\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:26 INFO 140043348993664] Epoch[248] Batch[0] avg_epoch_loss=-1.018795\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=-1.0187950134277344\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:30 INFO 140043348993664] Epoch[248] Batch[5] avg_epoch_loss=-0.923920\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=-0.9239198466142019\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:30 INFO 140043348993664] Epoch[248] Batch [5]#011Speed: 71.31 samples/sec#011loss=-0.923920\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] Epoch[248] Batch[10] avg_epoch_loss=-0.947170\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=-0.9750699996948242\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] Epoch[248] Batch [10]#011Speed: 71.57 samples/sec#011loss=-0.975070\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743164.1536252, \"EndTime\": 1646743175.4570496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11302.149057388306, \"count\": 1, \"min\": 11302.149057388306, \"max\": 11302.149057388306}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.27741003927895 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 62.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=248, train loss <loss>=-0.947169916196303\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:37 INFO 140043348993664] Epoch[249] Batch[0] avg_epoch_loss=-0.762765\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=-0.7627646923065186\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:42 INFO 140043348993664] Epoch[249] Batch[5] avg_epoch_loss=-0.867376\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=-0.8673762579758962\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:42 INFO 140043348993664] Epoch[249] Batch [5]#011Speed: 72.58 samples/sec#011loss=-0.867376\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] Epoch[249] Batch[10] avg_epoch_loss=-0.876814\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=-0.888139283657074\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] Epoch[249] Batch [10]#011Speed: 72.65 samples/sec#011loss=-0.888139\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743175.4576466, \"EndTime\": 1646743186.4928496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11033.846139907837, \"count\": 1, \"min\": 11033.846139907837, \"max\": 11033.846139907837}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.534218725076855 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 62.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=249, train loss <loss>=-0.8768139969218861\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:48 INFO 140043348993664] Epoch[250] Batch[0] avg_epoch_loss=-0.746358\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=-0.7463576793670654\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:53 INFO 140043348993664] Epoch[250] Batch[5] avg_epoch_loss=-0.824119\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=-0.8241194585959116\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:53 INFO 140043348993664] Epoch[250] Batch [5]#011Speed: 72.01 samples/sec#011loss=-0.824119\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] Epoch[250] Batch[10] avg_epoch_loss=-0.872129\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=-0.9297399282455444\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] Epoch[250] Batch [10]#011Speed: 74.16 samples/sec#011loss=-0.929740\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743186.492926, \"EndTime\": 1646743197.542229, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11048.027038574219, \"count\": 1, \"min\": 11048.027038574219, \"max\": 11048.027038574219}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.73690167569454 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 62.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=250, train loss <loss>=-0.8721287629821084\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:59 INFO 140043348993664] Epoch[251] Batch[0] avg_epoch_loss=-0.824396\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:39:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=-0.8243957161903381\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:04 INFO 140043348993664] Epoch[251] Batch[5] avg_epoch_loss=-0.815838\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=-0.8158380488554636\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:04 INFO 140043348993664] Epoch[251] Batch [5]#011Speed: 70.18 samples/sec#011loss=-0.815838\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] Epoch[251] Batch[10] avg_epoch_loss=-0.830077\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=-0.847163724899292\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] Epoch[251] Batch [10]#011Speed: 68.69 samples/sec#011loss=-0.847164\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743197.542583, \"EndTime\": 1646743208.9968486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11452.780485153198, \"count\": 1, \"min\": 11452.780485153198, \"max\": 11452.780485153198}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.03251373306165 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] #progress_metric: host=algo-1, completed 63.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=251, train loss <loss>=-0.8300769925117493\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:08 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:11 INFO 140043348993664] Epoch[252] Batch[0] avg_epoch_loss=-0.880999\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=-0.8809986710548401\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:15 INFO 140043348993664] Epoch[252] Batch[5] avg_epoch_loss=-0.926300\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=-0.9263002276420593\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:15 INFO 140043348993664] Epoch[252] Batch [5]#011Speed: 72.81 samples/sec#011loss=-0.926300\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] Epoch[252] Batch[10] avg_epoch_loss=-0.975176\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=-1.0338273763656616\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] Epoch[252] Batch [10]#011Speed: 71.66 samples/sec#011loss=-1.033827\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743208.9969366, \"EndTime\": 1646743220.2265673, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11228.233098983765, \"count\": 1, \"min\": 11228.233098983765, \"max\": 11228.233098983765}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.709376000406316 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 63.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=252, train loss <loss>=-0.9751762043346058\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:22 INFO 140043348993664] Epoch[253] Batch[0] avg_epoch_loss=-0.817821\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=-0.8178212642669678\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:26 INFO 140043348993664] Epoch[253] Batch[5] avg_epoch_loss=-0.864614\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=-0.8646136124928793\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:26 INFO 140043348993664] Epoch[253] Batch [5]#011Speed: 74.39 samples/sec#011loss=-0.864614\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] Epoch[253] Batch[10] avg_epoch_loss=-0.930042\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=-1.0085565090179442\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] Epoch[253] Batch [10]#011Speed: 72.50 samples/sec#011loss=-1.008557\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743220.2269447, \"EndTime\": 1646743231.2075994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10979.20560836792, \"count\": 1, \"min\": 10979.20560836792, \"max\": 10979.20560836792}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.565706315462535 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] #progress_metric: host=algo-1, completed 63.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=253, train loss <loss>=-0.9300422018224542\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:31 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:33 INFO 140043348993664] Epoch[254] Batch[0] avg_epoch_loss=-0.807381\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=-0.8073813915252686\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:37 INFO 140043348993664] Epoch[254] Batch[5] avg_epoch_loss=-0.825421\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=-0.8254210452238718\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:37 INFO 140043348993664] Epoch[254] Batch [5]#011Speed: 74.54 samples/sec#011loss=-0.825421\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:41 INFO 140043348993664] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743231.2076883, \"EndTime\": 1646743241.3171325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10108.144521713257, \"count\": 1, \"min\": 10108.144521713257, \"max\": 10108.144521713257}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.21549991000585 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 63.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=254, train loss <loss>=-0.8337374866008759\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:41 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:43 INFO 140043348993664] Epoch[255] Batch[0] avg_epoch_loss=-0.837652\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=-0.8376516103744507\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:47 INFO 140043348993664] Epoch[255] Batch[5] avg_epoch_loss=-0.903621\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=-0.9036209980646769\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:47 INFO 140043348993664] Epoch[255] Batch [5]#011Speed: 74.68 samples/sec#011loss=-0.903621\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:52 INFO 140043348993664] Epoch[255] Batch[10] avg_epoch_loss=-0.918044\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=-0.9353518724441529\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:52 INFO 140043348993664] Epoch[255] Batch [10]#011Speed: 67.66 samples/sec#011loss=-0.935352\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:53 INFO 140043348993664] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743241.3172264, \"EndTime\": 1646743253.6237514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12305.028915405273, \"count\": 1, \"min\": 12305.028915405273, \"max\": 12305.028915405273}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:53 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.372525956644175 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:53 INFO 140043348993664] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=255, train loss <loss>=-0.9202783157428106\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:53 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:55 INFO 140043348993664] Epoch[256] Batch[0] avg_epoch_loss=-0.947421\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:40:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=-0.9474207758903503\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:00 INFO 140043348993664] Epoch[256] Batch[5] avg_epoch_loss=-0.962181\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=-0.9621805051962534\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:00 INFO 140043348993664] Epoch[256] Batch [5]#011Speed: 75.90 samples/sec#011loss=-0.962181\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] Epoch[256] Batch[10] avg_epoch_loss=-0.974107\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=-0.9884188532829284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] Epoch[256] Batch [10]#011Speed: 68.56 samples/sec#011loss=-0.988419\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743253.6241755, \"EndTime\": 1646743264.8039649, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11178.226232528687, \"count\": 1, \"min\": 11178.226232528687, \"max\": 11178.226232528687}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.68453697668731 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 64.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=256, train loss <loss>=-0.974107027053833\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:04 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:07 INFO 140043348993664] Epoch[257] Batch[0] avg_epoch_loss=-0.904982\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=-0.9049815535545349\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:11 INFO 140043348993664] Epoch[257] Batch[5] avg_epoch_loss=-0.843765\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=-0.8437648514906565\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:11 INFO 140043348993664] Epoch[257] Batch [5]#011Speed: 75.33 samples/sec#011loss=-0.843765\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] Epoch[257] Batch[10] avg_epoch_loss=-0.904701\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=-0.9778244853019714\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] Epoch[257] Batch [10]#011Speed: 70.92 samples/sec#011loss=-0.977824\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743264.8040957, \"EndTime\": 1646743276.0410714, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11236.215829849243, \"count\": 1, \"min\": 11236.215829849243, \"max\": 11236.215829849243}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.51715082126315 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] #progress_metric: host=algo-1, completed 64.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=257, train loss <loss>=-0.9047010486776178\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:16 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:18 INFO 140043348993664] Epoch[258] Batch[0] avg_epoch_loss=-0.937713\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=-0.9377127885818481\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:22 INFO 140043348993664] Epoch[258] Batch[5] avg_epoch_loss=-0.918771\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=-0.9187714656194051\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:22 INFO 140043348993664] Epoch[258] Batch [5]#011Speed: 75.59 samples/sec#011loss=-0.918771\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] Epoch[258] Batch[10] avg_epoch_loss=-0.976004\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=-1.044681978225708\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] Epoch[258] Batch [10]#011Speed: 74.70 samples/sec#011loss=-1.044682\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743276.0411623, \"EndTime\": 1646743286.8578777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10815.188884735107, \"count\": 1, \"min\": 10815.188884735107, \"max\": 10815.188884735107}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.45194598534318 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 64.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=258, train loss <loss>=-0.9760035168040883\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:26 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:29 INFO 140043348993664] Epoch[259] Batch[0] avg_epoch_loss=-0.992667\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=-0.9926671385765076\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:33 INFO 140043348993664] Epoch[259] Batch[5] avg_epoch_loss=-0.947045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=-0.9470448791980743\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:33 INFO 140043348993664] Epoch[259] Batch [5]#011Speed: 75.43 samples/sec#011loss=-0.947045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] Epoch[259] Batch[10] avg_epoch_loss=-0.934826\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=-0.9201631784439087\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] Epoch[259] Batch [10]#011Speed: 73.73 samples/sec#011loss=-0.920163\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743286.8579674, \"EndTime\": 1646743297.7719896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10912.662267684937, \"count\": 1, \"min\": 10912.662267684937, \"max\": 10912.662267684937}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.387072812589786 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=259, train loss <loss>=-0.9348259243098173\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:39 INFO 140043348993664] Epoch[260] Batch[0] avg_epoch_loss=-1.000733\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=-1.0007328987121582\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:44 INFO 140043348993664] Epoch[260] Batch[5] avg_epoch_loss=-0.987873\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=-0.9878731071949005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:44 INFO 140043348993664] Epoch[260] Batch [5]#011Speed: 73.38 samples/sec#011loss=-0.987873\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] Epoch[260] Batch[10] avg_epoch_loss=-0.994042\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=-1.0014445900917053\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] Epoch[260] Batch [10]#011Speed: 67.86 samples/sec#011loss=-1.001445\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743297.7720773, \"EndTime\": 1646743309.07774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11304.442167282104, \"count\": 1, \"min\": 11304.442167282104, \"max\": 11304.442167282104}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.65477081021268 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] #progress_metric: host=algo-1, completed 65.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=260, train loss <loss>=-0.9940419630570845\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:49 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:51 INFO 140043348993664] Epoch[261] Batch[0] avg_epoch_loss=-1.045446\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=-1.0454455614089966\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:55 INFO 140043348993664] Epoch[261] Batch[5] avg_epoch_loss=-1.038566\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=-1.0385664800802867\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:41:55 INFO 140043348993664] Epoch[261] Batch [5]#011Speed: 75.28 samples/sec#011loss=-1.038566\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] Epoch[261] Batch[10] avg_epoch_loss=-1.057330\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=-1.0798456788063049\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] Epoch[261] Batch [10]#011Speed: 73.61 samples/sec#011loss=-1.079846\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743309.0781355, \"EndTime\": 1646743320.0877936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11008.220911026001, \"count\": 1, \"min\": 11008.220911026001, \"max\": 11008.220911026001}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.59031920446665 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] #progress_metric: host=algo-1, completed 65.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=261, train loss <loss>=-1.0573297522284768\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:00 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_922c0c3a-d299-4a9c-a3de-f767d23d94e8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743320.088153, \"EndTime\": 1646743320.212273, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 122.60055541992188, \"count\": 1, \"min\": 122.60055541992188, \"max\": 122.60055541992188}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:02 INFO 140043348993664] Epoch[262] Batch[0] avg_epoch_loss=-0.982515\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=-0.9825154542922974\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:07 INFO 140043348993664] Epoch[262] Batch[5] avg_epoch_loss=-0.932689\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=-0.9326886236667633\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:07 INFO 140043348993664] Epoch[262] Batch [5]#011Speed: 72.75 samples/sec#011loss=-0.932689\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:10 INFO 140043348993664] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743320.2126682, \"EndTime\": 1646743330.9083114, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10695.497512817383, \"count\": 1, \"min\": 10695.497512817383, \"max\": 10695.497512817383}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:10 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.62108968505628 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:10 INFO 140043348993664] #progress_metric: host=algo-1, completed 65.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=262, train loss <loss>=-0.9472035109996796\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:10 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:13 INFO 140043348993664] Epoch[263] Batch[0] avg_epoch_loss=-1.014841\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=-1.0148407220840454\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:17 INFO 140043348993664] Epoch[263] Batch[5] avg_epoch_loss=-1.036869\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=-1.0368687808513641\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:17 INFO 140043348993664] Epoch[263] Batch [5]#011Speed: 75.91 samples/sec#011loss=-1.036869\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:20 INFO 140043348993664] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743330.908544, \"EndTime\": 1646743340.811291, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9901.31688117981, \"count\": 1, \"min\": 9901.31688117981, \"max\": 9901.31688117981}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.3337488656656 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 66.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=263, train loss <loss>=-1.0348028540611267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:22 INFO 140043348993664] Epoch[264] Batch[0] avg_epoch_loss=-0.962620\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=-0.9626197814941406\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:27 INFO 140043348993664] Epoch[264] Batch[5] avg_epoch_loss=-0.998842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=-0.9988418718179067\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:27 INFO 140043348993664] Epoch[264] Batch [5]#011Speed: 74.60 samples/sec#011loss=-0.998842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] Epoch[264] Batch[10] avg_epoch_loss=-1.000397\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=-1.0022639870643615\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] Epoch[264] Batch [10]#011Speed: 72.71 samples/sec#011loss=-1.002264\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743340.811422, \"EndTime\": 1646743351.691229, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10879.001379013062, \"count\": 1, \"min\": 10879.001379013062, \"max\": 10879.001379013062}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.032869748012786 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] #progress_metric: host=algo-1, completed 66.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=264, train loss <loss>=-1.0003973787481135\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:31 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:33 INFO 140043348993664] Epoch[265] Batch[0] avg_epoch_loss=-0.960175\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=-0.9601754546165466\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:38 INFO 140043348993664] Epoch[265] Batch[5] avg_epoch_loss=-0.897460\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=-0.8974599043528239\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:38 INFO 140043348993664] Epoch[265] Batch [5]#011Speed: 76.50 samples/sec#011loss=-0.897460\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] Epoch[265] Batch[10] avg_epoch_loss=-0.926599\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=-0.9615664958953858\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] Epoch[265] Batch [10]#011Speed: 72.85 samples/sec#011loss=-0.961566\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743351.6915636, \"EndTime\": 1646743362.5309765, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10837.958574295044, \"count\": 1, \"min\": 10837.958574295044, \"max\": 10837.958574295044}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.18728477913805 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] #progress_metric: host=algo-1, completed 66.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=265, train loss <loss>=-0.9265992641448975\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:42 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:44 INFO 140043348993664] Epoch[266] Batch[0] avg_epoch_loss=-0.853833\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=-0.853833019733429\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:49 INFO 140043348993664] Epoch[266] Batch[5] avg_epoch_loss=-0.818171\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=-0.818171223004659\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:49 INFO 140043348993664] Epoch[266] Batch [5]#011Speed: 75.20 samples/sec#011loss=-0.818171\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] Epoch[266] Batch[10] avg_epoch_loss=-0.826262\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=-0.8359714627265931\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] Epoch[266] Batch [10]#011Speed: 74.04 samples/sec#011loss=-0.835971\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743362.5310702, \"EndTime\": 1646743373.3894708, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10857.231616973877, \"count\": 1, \"min\": 10857.231616973877, \"max\": 10857.231616973877}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.7072683468421 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] #progress_metric: host=algo-1, completed 66.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=266, train loss <loss>=-0.8262622410600836\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:53 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:55 INFO 140043348993664] Epoch[267] Batch[0] avg_epoch_loss=-0.873405\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=-0.873404860496521\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:59 INFO 140043348993664] Epoch[267] Batch[5] avg_epoch_loss=-0.919461\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=-0.9194608430067698\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:42:59 INFO 140043348993664] Epoch[267] Batch [5]#011Speed: 75.55 samples/sec#011loss=-0.919461\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] Epoch[267] Batch[10] avg_epoch_loss=-0.964284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=-1.0180726766586303\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] Epoch[267] Batch [10]#011Speed: 70.96 samples/sec#011loss=-1.018073\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743373.389756, \"EndTime\": 1646743384.3554225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10964.528322219849, \"count\": 1, \"min\": 10964.528322219849, \"max\": 10964.528322219849}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.56149845737212 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 67.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=267, train loss <loss>=-0.9642844037576155\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:04 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:06 INFO 140043348993664] Epoch[268] Batch[0] avg_epoch_loss=-0.997726\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=-0.9977255463600159\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:11 INFO 140043348993664] Epoch[268] Batch[5] avg_epoch_loss=-0.987753\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=-0.987752636273702\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:11 INFO 140043348993664] Epoch[268] Batch [5]#011Speed: 74.43 samples/sec#011loss=-0.987753\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:14 INFO 140043348993664] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743384.3555024, \"EndTime\": 1646743394.8413522, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10485.393047332764, \"count\": 1, \"min\": 10485.393047332764, \"max\": 10485.393047332764}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.41438153551027 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 67.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=268, train loss <loss>=-0.9731507062911987\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:14 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:17 INFO 140043348993664] Epoch[269] Batch[0] avg_epoch_loss=-0.945795\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=-0.9457948803901672\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:21 INFO 140043348993664] Epoch[269] Batch[5] avg_epoch_loss=-0.893842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=-0.8938423494497935\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:21 INFO 140043348993664] Epoch[269] Batch [5]#011Speed: 73.10 samples/sec#011loss=-0.893842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:24 INFO 140043348993664] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743394.8415878, \"EndTime\": 1646743404.8215778, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9978.805541992188, \"count\": 1, \"min\": 9978.805541992188, \"max\": 9978.805541992188}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.63204189072101 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 67.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=269, train loss <loss>=-0.9118737518787384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:26 INFO 140043348993664] Epoch[270] Batch[0] avg_epoch_loss=-1.017137\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=-1.0171372890472412\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:31 INFO 140043348993664] Epoch[270] Batch[5] avg_epoch_loss=-1.042611\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=-1.0426112810770671\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:31 INFO 140043348993664] Epoch[270] Batch [5]#011Speed: 75.90 samples/sec#011loss=-1.042611\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] Epoch[270] Batch[10] avg_epoch_loss=-1.045777\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=-1.0495752573013306\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] Epoch[270] Batch [10]#011Speed: 72.34 samples/sec#011loss=-1.049575\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743404.8216538, \"EndTime\": 1646743415.6410859, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10818.948030471802, \"count\": 1, \"min\": 10818.948030471802, \"max\": 10818.948030471802}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.8336332253863 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 67.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=270, train loss <loss>=-1.0457767248153687\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:37 INFO 140043348993664] Epoch[271] Batch[0] avg_epoch_loss=-1.037092\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=-1.0370923280715942\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:42 INFO 140043348993664] Epoch[271] Batch[5] avg_epoch_loss=-1.009860\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=-1.0098604261875153\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:42 INFO 140043348993664] Epoch[271] Batch [5]#011Speed: 76.24 samples/sec#011loss=-1.009860\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] Epoch[271] Batch[10] avg_epoch_loss=-1.002792\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=-0.9943102717399597\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] Epoch[271] Batch [10]#011Speed: 73.77 samples/sec#011loss=-0.994310\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743415.6414523, \"EndTime\": 1646743426.426138, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10783.271312713623, \"count\": 1, \"min\": 10783.271312713623, \"max\": 10783.271312713623}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.29736352802872 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 68.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=271, train loss <loss>=-1.0027921741658992\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:48 INFO 140043348993664] Epoch[272] Batch[0] avg_epoch_loss=-0.689954\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=-0.6899542808532715\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:53 INFO 140043348993664] Epoch[272] Batch[5] avg_epoch_loss=-0.717193\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=-0.7171925803025564\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:53 INFO 140043348993664] Epoch[272] Batch [5]#011Speed: 74.45 samples/sec#011loss=-0.717193\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] Epoch[272] Batch[10] avg_epoch_loss=-0.733482\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=-0.7530287027359008\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] Epoch[272] Batch [10]#011Speed: 72.57 samples/sec#011loss=-0.753029\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743426.426324, \"EndTime\": 1646743437.4265044, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10999.335765838623, \"count\": 1, \"min\": 10999.335765838623, \"max\": 10999.335765838623}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.91079717955793 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 68.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=272, train loss <loss>=-0.7334817268631675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:59 INFO 140043348993664] Epoch[273] Batch[0] avg_epoch_loss=-0.746311\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:43:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=-0.7463110089302063\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:04 INFO 140043348993664] Epoch[273] Batch[5] avg_epoch_loss=-0.834300\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=-0.8342999219894409\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:04 INFO 140043348993664] Epoch[273] Batch [5]#011Speed: 69.88 samples/sec#011loss=-0.834300\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:07 INFO 140043348993664] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743437.4268165, \"EndTime\": 1646743447.789992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10361.922979354858, \"count\": 1, \"min\": 10361.922979354858, \"max\": 10361.922979354858}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.02646113192224 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 68.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=273, train loss <loss>=-0.8815027356147767\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:07 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:10 INFO 140043348993664] Epoch[274] Batch[0] avg_epoch_loss=-0.860186\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=-0.8601861000061035\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:14 INFO 140043348993664] Epoch[274] Batch[5] avg_epoch_loss=-0.968844\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=-0.9688439766565958\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:14 INFO 140043348993664] Epoch[274] Batch [5]#011Speed: 76.50 samples/sec#011loss=-0.968844\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:17 INFO 140043348993664] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743447.7900958, \"EndTime\": 1646743457.9463077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10155.475378036499, \"count\": 1, \"min\": 10155.475378036499, \"max\": 10155.475378036499}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.82249648696637 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 68.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=274, train loss <loss>=-0.975863641500473\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:17 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:20 INFO 140043348993664] Epoch[275] Batch[0] avg_epoch_loss=-0.986849\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=-0.9868485331535339\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:24 INFO 140043348993664] Epoch[275] Batch[5] avg_epoch_loss=-1.006534\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=-1.0065335830052693\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:24 INFO 140043348993664] Epoch[275] Batch [5]#011Speed: 75.46 samples/sec#011loss=-1.006534\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] Epoch[275] Batch[10] avg_epoch_loss=-1.003764\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=-1.0004410862922668\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] Epoch[275] Batch [10]#011Speed: 71.05 samples/sec#011loss=-1.000441\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743457.9463918, \"EndTime\": 1646743468.9276807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10980.7608127594, \"count\": 1, \"min\": 10980.7608127594, \"max\": 10980.7608127594}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.286501120453835 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 69.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=275, train loss <loss>=-1.003764266317541\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:31 INFO 140043348993664] Epoch[276] Batch[0] avg_epoch_loss=-0.733352\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=-0.7333515882492065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:35 INFO 140043348993664] Epoch[276] Batch[5] avg_epoch_loss=-0.804356\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=-0.8043562571207682\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:35 INFO 140043348993664] Epoch[276] Batch [5]#011Speed: 74.86 samples/sec#011loss=-0.804356\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] Epoch[276] Batch[10] avg_epoch_loss=-0.858461\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=-0.9233875155448914\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] Epoch[276] Batch [10]#011Speed: 72.28 samples/sec#011loss=-0.923388\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743468.9277816, \"EndTime\": 1646743479.84609, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10917.649745941162, \"count\": 1, \"min\": 10917.649745941162, \"max\": 10917.649745941162}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.20734138704556 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 69.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=276, train loss <loss>=-0.8584613745862787\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:42 INFO 140043348993664] Epoch[277] Batch[0] avg_epoch_loss=-0.937254\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=-0.9372543692588806\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:46 INFO 140043348993664] Epoch[277] Batch[5] avg_epoch_loss=-1.001206\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=-1.001205583413442\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:46 INFO 140043348993664] Epoch[277] Batch [5]#011Speed: 74.78 samples/sec#011loss=-1.001206\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] Epoch[277] Batch[10] avg_epoch_loss=-1.008260\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=-1.0167247772216796\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] Epoch[277] Batch [10]#011Speed: 75.14 samples/sec#011loss=-1.016725\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743479.8461611, \"EndTime\": 1646743490.5860991, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10739.28427696228, \"count\": 1, \"min\": 10739.28427696228, \"max\": 10739.28427696228}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.826464505265804 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] #progress_metric: host=algo-1, completed 69.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=277, train loss <loss>=-1.0082597624171863\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:50 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:52 INFO 140043348993664] Epoch[278] Batch[0] avg_epoch_loss=-0.996933\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=-0.9969329237937927\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:57 INFO 140043348993664] Epoch[278] Batch[5] avg_epoch_loss=-1.050099\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=-1.0500989059607189\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:44:57 INFO 140043348993664] Epoch[278] Batch [5]#011Speed: 73.44 samples/sec#011loss=-1.050099\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] Epoch[278] Batch[10] avg_epoch_loss=-1.024273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=-0.9932816743850708\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] Epoch[278] Batch [10]#011Speed: 73.96 samples/sec#011loss=-0.993282\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743490.5865052, \"EndTime\": 1646743501.5898812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11001.96886062622, \"count\": 1, \"min\": 11001.96886062622, \"max\": 11001.96886062622}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.26160086360391 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] #progress_metric: host=algo-1, completed 69.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=278, train loss <loss>=-1.0242728916081516\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:01 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:03 INFO 140043348993664] Epoch[279] Batch[0] avg_epoch_loss=-0.800181\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=-0.8001813888549805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:08 INFO 140043348993664] Epoch[279] Batch[5] avg_epoch_loss=-0.954417\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=-0.9544170598189036\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:08 INFO 140043348993664] Epoch[279] Batch [5]#011Speed: 72.12 samples/sec#011loss=-0.954417\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] Epoch[279] Batch[10] avg_epoch_loss=-0.984217\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=-1.0199764490127563\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] Epoch[279] Batch [10]#011Speed: 67.59 samples/sec#011loss=-1.019976\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743501.5899718, \"EndTime\": 1646743513.1344733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11543.848276138306, \"count\": 1, \"min\": 11543.848276138306, \"max\": 11543.848276138306}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.289605163661605 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=279, train loss <loss>=-0.9842167821797457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:15 INFO 140043348993664] Epoch[280] Batch[0] avg_epoch_loss=-1.042102\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=-1.0421016216278076\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:19 INFO 140043348993664] Epoch[280] Batch[5] avg_epoch_loss=-1.080704\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=-1.0807044704755147\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:19 INFO 140043348993664] Epoch[280] Batch [5]#011Speed: 76.47 samples/sec#011loss=-1.080704\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] Epoch[280] Batch[10] avg_epoch_loss=-1.089093\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=-1.0991592168807984\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] Epoch[280] Batch [10]#011Speed: 72.27 samples/sec#011loss=-1.099159\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743513.1348352, \"EndTime\": 1646743524.0725644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10936.299324035645, \"count\": 1, \"min\": 10936.299324035645, \"max\": 10936.299324035645}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.45030870256416 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 70.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=280, train loss <loss>=-1.0890929915688254\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:24 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_fea932d0-00d1-4aef-a47c-d47c5783aa99-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743524.0729175, \"EndTime\": 1646743524.1978786, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 123.54636192321777, \"count\": 1, \"min\": 123.54636192321777, \"max\": 123.54636192321777}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:26 INFO 140043348993664] Epoch[281] Batch[0] avg_epoch_loss=-1.106619\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=-1.1066185235977173\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:30 INFO 140043348993664] Epoch[281] Batch[5] avg_epoch_loss=-0.985446\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=-0.9854455689589182\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:30 INFO 140043348993664] Epoch[281] Batch [5]#011Speed: 74.70 samples/sec#011loss=-0.985446\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] Epoch[281] Batch[10] avg_epoch_loss=-0.979859\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=-0.9731560349464417\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] Epoch[281] Batch [10]#011Speed: 72.82 samples/sec#011loss=-0.973156\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743524.1982882, \"EndTime\": 1646743535.0912924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10892.907857894897, \"count\": 1, \"min\": 10892.907857894897, \"max\": 10892.907857894897}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.341744990180516 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 70.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=281, train loss <loss>=-0.9798594171350653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:37 INFO 140043348993664] Epoch[282] Batch[0] avg_epoch_loss=-1.007530\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=-1.0075297355651855\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:41 INFO 140043348993664] Epoch[282] Batch[5] avg_epoch_loss=-1.035407\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=-1.0354067087173462\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:41 INFO 140043348993664] Epoch[282] Batch [5]#011Speed: 75.88 samples/sec#011loss=-1.035407\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:45 INFO 140043348993664] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743535.0916328, \"EndTime\": 1646743545.168641, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10075.624465942383, \"count\": 1, \"min\": 10075.624465942383, \"max\": 10075.624465942383}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:45 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.33521251818792 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:45 INFO 140043348993664] #progress_metric: host=algo-1, completed 70.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=282, train loss <loss>=-1.0092411637306213\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:45 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:47 INFO 140043348993664] Epoch[283] Batch[0] avg_epoch_loss=-0.540653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=-0.5406532287597656\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:51 INFO 140043348993664] Epoch[283] Batch[5] avg_epoch_loss=-0.670818\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=-0.6708183089892069\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:51 INFO 140043348993664] Epoch[283] Batch [5]#011Speed: 74.07 samples/sec#011loss=-0.670818\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] Epoch[283] Batch[10] avg_epoch_loss=-0.740577\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=-0.8242882490158081\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] Epoch[283] Batch [10]#011Speed: 72.92 samples/sec#011loss=-0.824288\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743545.168737, \"EndTime\": 1646743556.142526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10972.8684425354, \"count\": 1, \"min\": 10972.8684425354, \"max\": 10972.8684425354}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.15113536838011 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] #progress_metric: host=algo-1, completed 71.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=283, train loss <loss>=-0.740577372637662\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:56 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:58 INFO 140043348993664] Epoch[284] Batch[0] avg_epoch_loss=-1.003973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:45:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=-1.0039725303649902\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:02 INFO 140043348993664] Epoch[284] Batch[5] avg_epoch_loss=-0.953913\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=-0.9539134303728739\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:02 INFO 140043348993664] Epoch[284] Batch [5]#011Speed: 73.37 samples/sec#011loss=-0.953913\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] Epoch[284] Batch[10] avg_epoch_loss=-0.985578\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=-1.023576521873474\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] Epoch[284] Batch [10]#011Speed: 73.31 samples/sec#011loss=-1.023577\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743556.1428647, \"EndTime\": 1646743567.143293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10999.05276298523, \"count\": 1, \"min\": 10999.05276298523, \"max\": 10999.05276298523}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.459065067577185 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 71.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=284, train loss <loss>=-0.9855784719640558\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:07 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:09 INFO 140043348993664] Epoch[285] Batch[0] avg_epoch_loss=-1.016373\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=-1.0163729190826416\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:13 INFO 140043348993664] Epoch[285] Batch[5] avg_epoch_loss=-1.027644\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=-1.0276443163553874\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:13 INFO 140043348993664] Epoch[285] Batch [5]#011Speed: 73.61 samples/sec#011loss=-1.027644\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] Epoch[285] Batch[10] avg_epoch_loss=-1.032457\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=-1.038231575489044\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] Epoch[285] Batch [10]#011Speed: 75.32 samples/sec#011loss=-1.038232\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743567.143367, \"EndTime\": 1646743578.2082202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11064.385414123535, \"count\": 1, \"min\": 11064.385414123535, \"max\": 11064.385414123535}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.10795993136941 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] #progress_metric: host=algo-1, completed 71.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=285, train loss <loss>=-1.032456706870686\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:18 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:20 INFO 140043348993664] Epoch[286] Batch[0] avg_epoch_loss=-1.015234\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=-1.0152336359024048\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:24 INFO 140043348993664] Epoch[286] Batch[5] avg_epoch_loss=-1.039470\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=-1.0394697388013203\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:24 INFO 140043348993664] Epoch[286] Batch [5]#011Speed: 74.42 samples/sec#011loss=-1.039470\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] Epoch[286] Batch[10] avg_epoch_loss=-1.049425\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=-1.0613711953163147\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] Epoch[286] Batch [10]#011Speed: 74.28 samples/sec#011loss=-1.061371\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743578.2082984, \"EndTime\": 1646743589.1356647, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10926.909923553467, \"count\": 1, \"min\": 10926.909923553467, \"max\": 10926.909923553467}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.58359034613297 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] #progress_metric: host=algo-1, completed 71.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=286, train loss <loss>=-1.049424946308136\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:29 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:31 INFO 140043348993664] Epoch[287] Batch[0] avg_epoch_loss=-1.045782\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=-1.0457817316055298\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:35 INFO 140043348993664] Epoch[287] Batch[5] avg_epoch_loss=-1.029723\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=-1.029722899198532\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:35 INFO 140043348993664] Epoch[287] Batch [5]#011Speed: 76.14 samples/sec#011loss=-1.029723\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] Epoch[287] Batch[10] avg_epoch_loss=-1.021396\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=-1.0114041209220885\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] Epoch[287] Batch [10]#011Speed: 71.89 samples/sec#011loss=-1.011404\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743589.1357658, \"EndTime\": 1646743600.013547, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10876.832723617554, \"count\": 1, \"min\": 10876.832723617554, \"max\": 10876.832723617554}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.40089537695147 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] #progress_metric: host=algo-1, completed 72.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=287, train loss <loss>=-1.0213961818001487\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:40 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:42 INFO 140043348993664] Epoch[288] Batch[0] avg_epoch_loss=-0.804551\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=-0.8045511841773987\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:46 INFO 140043348993664] Epoch[288] Batch[5] avg_epoch_loss=-0.832919\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=-0.8329193194707235\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:46 INFO 140043348993664] Epoch[288] Batch [5]#011Speed: 74.45 samples/sec#011loss=-0.832919\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] Epoch[288] Batch[10] avg_epoch_loss=-0.873223\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=288, batch=10 train loss <loss>=-0.921587610244751\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] Epoch[288] Batch [10]#011Speed: 74.91 samples/sec#011loss=-0.921588\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743600.0139322, \"EndTime\": 1646743610.9925423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10977.219104766846, \"count\": 1, \"min\": 10977.219104766846, \"max\": 10977.219104766846}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.66626008435975 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] #progress_metric: host=algo-1, completed 72.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=288, train loss <loss>=-0.8732230880043723\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:50 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:53 INFO 140043348993664] Epoch[289] Batch[0] avg_epoch_loss=-0.837019\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=-0.8370189666748047\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:57 INFO 140043348993664] Epoch[289] Batch[5] avg_epoch_loss=-0.897738\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=-0.8977382977803549\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:46:57 INFO 140043348993664] Epoch[289] Batch [5]#011Speed: 76.76 samples/sec#011loss=-0.897738\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] Epoch[289] Batch[10] avg_epoch_loss=-0.920169\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=-0.9470856070518494\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] Epoch[289] Batch [10]#011Speed: 70.49 samples/sec#011loss=-0.947086\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743610.992633, \"EndTime\": 1646743621.941771, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10948.11725616455, \"count\": 1, \"min\": 10948.11725616455, \"max\": 10948.11725616455}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.30265660721285 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] #progress_metric: host=algo-1, completed 72.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=289, train loss <loss>=-0.9201688929037615\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:01 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:04 INFO 140043348993664] Epoch[290] Batch[0] avg_epoch_loss=-0.999292\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=-0.9992921352386475\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:08 INFO 140043348993664] Epoch[290] Batch[5] avg_epoch_loss=-0.984705\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=-0.9847052892049154\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:08 INFO 140043348993664] Epoch[290] Batch [5]#011Speed: 69.26 samples/sec#011loss=-0.984705\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] Epoch[290] Batch[10] avg_epoch_loss=-1.031008\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=-1.0865722179412842\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] Epoch[290] Batch [10]#011Speed: 73.17 samples/sec#011loss=-1.086572\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743621.9418454, \"EndTime\": 1646743633.1513746, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11209.139108657837, \"count\": 1, \"min\": 11209.139108657837, \"max\": 11209.139108657837}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.08990040915835 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 72.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=290, train loss <loss>=-1.0310084386305376\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:15 INFO 140043348993664] Epoch[291] Batch[0] avg_epoch_loss=-1.097225\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=-1.0972247123718262\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:19 INFO 140043348993664] Epoch[291] Batch[5] avg_epoch_loss=-1.043848\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=-1.0438478489716847\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:19 INFO 140043348993664] Epoch[291] Batch [5]#011Speed: 77.05 samples/sec#011loss=-1.043848\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] Epoch[291] Batch[10] avg_epoch_loss=-1.075553\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=-1.113600206375122\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] Epoch[291] Batch [10]#011Speed: 72.07 samples/sec#011loss=-1.113600\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743633.1517506, \"EndTime\": 1646743644.0990703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10945.90163230896, \"count\": 1, \"min\": 10945.90163230896, \"max\": 10945.90163230896}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.38728059163455 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 73.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=291, train loss <loss>=-1.075553465973247\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:26 INFO 140043348993664] Epoch[292] Batch[0] avg_epoch_loss=-1.053367\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=-1.0533665418624878\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:30 INFO 140043348993664] Epoch[292] Batch[5] avg_epoch_loss=-1.033362\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=-1.0333618819713593\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:30 INFO 140043348993664] Epoch[292] Batch [5]#011Speed: 74.28 samples/sec#011loss=-1.033362\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] Epoch[292] Batch[10] avg_epoch_loss=-1.046900\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=292, batch=10 train loss <loss>=-1.0631452083587647\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] Epoch[292] Batch [10]#011Speed: 69.67 samples/sec#011loss=-1.063145\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] processed a total of 728 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743644.099147, \"EndTime\": 1646743655.9628277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11863.231182098389, \"count\": 1, \"min\": 11863.231182098389, \"max\": 11863.231182098389}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.364628975460306 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 73.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=292, train loss <loss>=-1.0630629112323124\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:38 INFO 140043348993664] Epoch[293] Batch[0] avg_epoch_loss=-0.910040\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=-0.9100396037101746\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:42 INFO 140043348993664] Epoch[293] Batch[5] avg_epoch_loss=-0.981127\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=-0.981127142906189\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:42 INFO 140043348993664] Epoch[293] Batch [5]#011Speed: 76.24 samples/sec#011loss=-0.981127\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] Epoch[293] Batch[10] avg_epoch_loss=-1.000307\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=-1.0233224034309387\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] Epoch[293] Batch [10]#011Speed: 72.95 samples/sec#011loss=-1.023322\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743655.963052, \"EndTime\": 1646743666.7958884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10831.634521484375, \"count\": 1, \"min\": 10831.634521484375, \"max\": 10831.634521484375}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.37637991647157 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 73.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=293, train loss <loss>=-1.0003068067810752\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:49 INFO 140043348993664] Epoch[294] Batch[0] avg_epoch_loss=-1.084145\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=-1.084145426750183\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:53 INFO 140043348993664] Epoch[294] Batch[5] avg_epoch_loss=-1.067333\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=-1.0673331518967946\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:53 INFO 140043348993664] Epoch[294] Batch [5]#011Speed: 74.65 samples/sec#011loss=-1.067333\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] Epoch[294] Batch[10] avg_epoch_loss=-1.060038\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=-1.0512840151786804\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] Epoch[294] Batch [10]#011Speed: 72.56 samples/sec#011loss=-1.051284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743666.7959871, \"EndTime\": 1646743677.7688026, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10971.601247787476, \"count\": 1, \"min\": 10971.601247787476, \"max\": 10971.601247787476}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.06566970547389 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 73.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=294, train loss <loss>=-1.0600380897521973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:57 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:59 INFO 140043348993664] Epoch[295] Batch[0] avg_epoch_loss=-1.100029\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:47:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=-1.100029468536377\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:04 INFO 140043348993664] Epoch[295] Batch[5] avg_epoch_loss=-1.062448\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=-1.0624481638272603\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:04 INFO 140043348993664] Epoch[295] Batch [5]#011Speed: 72.84 samples/sec#011loss=-1.062448\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] Epoch[295] Batch[10] avg_epoch_loss=-1.041112\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=-1.015509295463562\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] Epoch[295] Batch [10]#011Speed: 69.18 samples/sec#011loss=-1.015509\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743677.7689252, \"EndTime\": 1646743688.9724607, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11202.813386917114, \"count\": 1, \"min\": 11202.813386917114, \"max\": 11202.813386917114}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.394019814179444 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] #progress_metric: host=algo-1, completed 74.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=295, train loss <loss>=-1.041112314571034\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:08 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:11 INFO 140043348993664] Epoch[296] Batch[0] avg_epoch_loss=-0.901244\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=-0.9012442231178284\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:15 INFO 140043348993664] Epoch[296] Batch[5] avg_epoch_loss=-1.029065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=-1.029064764579137\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:15 INFO 140043348993664] Epoch[296] Batch [5]#011Speed: 74.43 samples/sec#011loss=-1.029065\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] Epoch[296] Batch[10] avg_epoch_loss=-1.025523\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=-1.0212734937667847\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] Epoch[296] Batch [10]#011Speed: 74.24 samples/sec#011loss=-1.021273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743688.9726038, \"EndTime\": 1646743699.850088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10876.514911651611, \"count\": 1, \"min\": 10876.514911651611, \"max\": 10876.514911651611}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.86261375233329 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] #progress_metric: host=algo-1, completed 74.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=296, train loss <loss>=-1.0255232778462497\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:19 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:22 INFO 140043348993664] Epoch[297] Batch[0] avg_epoch_loss=-0.919950\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=-0.9199503660202026\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:26 INFO 140043348993664] Epoch[297] Batch[5] avg_epoch_loss=-0.952226\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=-0.9522263904412588\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:26 INFO 140043348993664] Epoch[297] Batch [5]#011Speed: 75.71 samples/sec#011loss=-0.952226\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] Epoch[297] Batch[10] avg_epoch_loss=-0.979056\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=297, batch=10 train loss <loss>=-1.0112522840499878\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] Epoch[297] Batch [10]#011Speed: 73.67 samples/sec#011loss=-1.011252\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743699.8504817, \"EndTime\": 1646743710.7275915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10875.707626342773, \"count\": 1, \"min\": 10875.707626342773, \"max\": 10875.707626342773}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.673655278243615 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] #progress_metric: host=algo-1, completed 74.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=297, train loss <loss>=-0.9790563420815901\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:30 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:32 INFO 140043348993664] Epoch[298] Batch[0] avg_epoch_loss=-0.805223\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=-0.8052234053611755\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:37 INFO 140043348993664] Epoch[298] Batch[5] avg_epoch_loss=-0.844425\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=-0.8444253404935201\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:37 INFO 140043348993664] Epoch[298] Batch [5]#011Speed: 75.60 samples/sec#011loss=-0.844425\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] Epoch[298] Batch[10] avg_epoch_loss=-0.897278\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=298, batch=10 train loss <loss>=-0.9607001066207885\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] Epoch[298] Batch [10]#011Speed: 71.29 samples/sec#011loss=-0.960700\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743710.7276685, \"EndTime\": 1646743721.6499665, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10921.241283416748, \"count\": 1, \"min\": 10921.241283416748, \"max\": 10921.241283416748}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.71223894401324 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 74.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=298, train loss <loss>=-0.8972775069150057\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:41 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:43 INFO 140043348993664] Epoch[299] Batch[0] avg_epoch_loss=-0.962084\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=-0.9620837569236755\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:48 INFO 140043348993664] Epoch[299] Batch[5] avg_epoch_loss=-0.949136\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=-0.9491359194119772\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:48 INFO 140043348993664] Epoch[299] Batch [5]#011Speed: 76.52 samples/sec#011loss=-0.949136\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] Epoch[299] Batch[10] avg_epoch_loss=-0.981559\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=299, batch=10 train loss <loss>=-1.020467174053192\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] Epoch[299] Batch [10]#011Speed: 73.67 samples/sec#011loss=-1.020467\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743721.650343, \"EndTime\": 1646743732.491528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10839.768171310425, \"count\": 1, \"min\": 10839.768171310425, \"max\": 10839.768171310425}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.05461663013929 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=299, train loss <loss>=-0.9815592169761658\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:52 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:54 INFO 140043348993664] Epoch[300] Batch[0] avg_epoch_loss=-0.996432\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=-0.9964322447776794\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:59 INFO 140043348993664] Epoch[300] Batch[5] avg_epoch_loss=-1.044141\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=-1.0441409250100453\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:48:59 INFO 140043348993664] Epoch[300] Batch [5]#011Speed: 75.26 samples/sec#011loss=-1.044141\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] Epoch[300] Batch[10] avg_epoch_loss=-1.052601\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=300, batch=10 train loss <loss>=-1.0627525210380555\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] Epoch[300] Batch [10]#011Speed: 70.40 samples/sec#011loss=-1.062753\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743732.49185, \"EndTime\": 1646743743.599604, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11106.468439102173, \"count\": 1, \"min\": 11106.468439102173, \"max\": 11106.468439102173}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.51425448677706 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] #progress_metric: host=algo-1, completed 75.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=300, train loss <loss>=-1.0526007413864136\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:03 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:06 INFO 140043348993664] Epoch[301] Batch[0] avg_epoch_loss=-0.989340\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=-0.9893401861190796\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:10 INFO 140043348993664] Epoch[301] Batch[5] avg_epoch_loss=-0.983805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=-0.9838051597277323\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:10 INFO 140043348993664] Epoch[301] Batch [5]#011Speed: 72.55 samples/sec#011loss=-0.983805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] Epoch[301] Batch[10] avg_epoch_loss=-0.987516\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=-0.9919700503349305\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] Epoch[301] Batch [10]#011Speed: 73.75 samples/sec#011loss=-0.991970\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743743.5996819, \"EndTime\": 1646743754.7672136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11167.093515396118, \"count\": 1, \"min\": 11167.093515396118, \"max\": 11167.093515396118}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.10162535623621 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 75.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=301, train loss <loss>=-0.9875164736400951\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:14 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:16 INFO 140043348993664] Epoch[302] Batch[0] avg_epoch_loss=-1.002954\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=-1.0029542446136475\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:21 INFO 140043348993664] Epoch[302] Batch[5] avg_epoch_loss=-1.044670\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=-1.0446697374184926\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:21 INFO 140043348993664] Epoch[302] Batch [5]#011Speed: 75.69 samples/sec#011loss=-1.044670\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] Epoch[302] Batch[10] avg_epoch_loss=-1.065383\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=302, batch=10 train loss <loss>=-1.0902386903762817\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] Epoch[302] Batch [10]#011Speed: 74.15 samples/sec#011loss=-1.090239\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743754.7672906, \"EndTime\": 1646743765.5351522, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10767.402172088623, \"count\": 1, \"min\": 10767.402172088623, \"max\": 10767.402172088623}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.757935102816376 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] #progress_metric: host=algo-1, completed 75.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=302, train loss <loss>=-1.0653828978538513\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:25 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:27 INFO 140043348993664] Epoch[303] Batch[0] avg_epoch_loss=-0.949967\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=-0.9499669075012207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:31 INFO 140043348993664] Epoch[303] Batch[5] avg_epoch_loss=-0.898587\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=-0.8985868891080221\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:31 INFO 140043348993664] Epoch[303] Batch [5]#011Speed: 76.71 samples/sec#011loss=-0.898587\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:35 INFO 140043348993664] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743765.5355535, \"EndTime\": 1646743775.4945962, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9957.614421844482, \"count\": 1, \"min\": 9957.614421844482, \"max\": 9957.614421844482}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:35 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.86117713045579 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:35 INFO 140043348993664] #progress_metric: host=algo-1, completed 76.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=303, train loss <loss>=-0.9117811322212219\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:35 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:37 INFO 140043348993664] Epoch[304] Batch[0] avg_epoch_loss=-1.061285\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=-1.0612845420837402\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:42 INFO 140043348993664] Epoch[304] Batch[5] avg_epoch_loss=-0.989966\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=-0.9899664024511973\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:42 INFO 140043348993664] Epoch[304] Batch [5]#011Speed: 73.92 samples/sec#011loss=-0.989966\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] Epoch[304] Batch[10] avg_epoch_loss=-0.998120\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=-1.0079032897949218\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] Epoch[304] Batch [10]#011Speed: 72.61 samples/sec#011loss=-1.007903\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743775.4947152, \"EndTime\": 1646743786.508657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11012.643098831177, \"count\": 1, \"min\": 11012.643098831177, \"max\": 11012.643098831177}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.65574046751055 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 76.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=304, train loss <loss>=-0.9981195330619812\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:48 INFO 140043348993664] Epoch[305] Batch[0] avg_epoch_loss=-1.065832\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=-1.0658320188522339\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:53 INFO 140043348993664] Epoch[305] Batch[5] avg_epoch_loss=-1.080974\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=-1.0809741616249084\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:53 INFO 140043348993664] Epoch[305] Batch [5]#011Speed: 74.89 samples/sec#011loss=-1.080974\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] Epoch[305] Batch[10] avg_epoch_loss=-1.093286\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=-1.1080591678619385\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] Epoch[305] Batch [10]#011Speed: 72.46 samples/sec#011loss=-1.108059\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743786.5087373, \"EndTime\": 1646743797.5069513, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10997.724294662476, \"count\": 1, \"min\": 10997.724294662476, \"max\": 10997.724294662476}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.46574126209022 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] #progress_metric: host=algo-1, completed 76.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=305, train loss <loss>=-1.0932855280962857\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:57 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_e38426ab-f9d5-4ba9-80e7-f41c3c703fa6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743797.5070808, \"EndTime\": 1646743797.6631756, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 155.2736759185791, \"count\": 1, \"min\": 155.2736759185791, \"max\": 155.2736759185791}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:59 INFO 140043348993664] Epoch[306] Batch[0] avg_epoch_loss=-0.760959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:49:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=-0.7609590888023376\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:04 INFO 140043348993664] Epoch[306] Batch[5] avg_epoch_loss=-0.929822\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=-0.9298222661018372\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:04 INFO 140043348993664] Epoch[306] Batch [5]#011Speed: 70.08 samples/sec#011loss=-0.929822\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] Epoch[306] Batch[10] avg_epoch_loss=-0.973024\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=-1.024865734577179\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] Epoch[306] Batch [10]#011Speed: 69.16 samples/sec#011loss=-1.024866\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743797.6633463, \"EndTime\": 1646743809.1749465, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11511.489152908325, \"count\": 1, \"min\": 11511.489152908325, \"max\": 11511.489152908325}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.072789893398564 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] #progress_metric: host=algo-1, completed 76.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=306, train loss <loss>=-0.973023842681538\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:09 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:11 INFO 140043348993664] Epoch[307] Batch[0] avg_epoch_loss=-1.050319\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=-1.0503191947937012\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:15 INFO 140043348993664] Epoch[307] Batch[5] avg_epoch_loss=-1.042810\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=-1.0428097347418468\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:15 INFO 140043348993664] Epoch[307] Batch [5]#011Speed: 76.86 samples/sec#011loss=-1.042810\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] Epoch[307] Batch[10] avg_epoch_loss=-1.033256\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=-1.021790659427643\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] Epoch[307] Batch [10]#011Speed: 77.16 samples/sec#011loss=-1.021791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743809.1750324, \"EndTime\": 1646743819.8834484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10706.897735595703, \"count\": 1, \"min\": 10706.897735595703, \"max\": 10706.897735595703}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.42729053307195 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] #progress_metric: host=algo-1, completed 77.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=307, train loss <loss>=-1.0332556095990268\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:19 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:22 INFO 140043348993664] Epoch[308] Batch[0] avg_epoch_loss=-0.965872\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=-0.9658724665641785\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:26 INFO 140043348993664] Epoch[308] Batch[5] avg_epoch_loss=-0.979254\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=-0.979254017273585\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:26 INFO 140043348993664] Epoch[308] Batch [5]#011Speed: 74.24 samples/sec#011loss=-0.979254\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] Epoch[308] Batch[10] avg_epoch_loss=-1.019157\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=-1.0670410990715027\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] Epoch[308] Batch [10]#011Speed: 72.00 samples/sec#011loss=-1.067041\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743819.8835576, \"EndTime\": 1646743830.8296525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10945.441484451294, \"count\": 1, \"min\": 10945.441484451294, \"max\": 10945.441484451294}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.677025690783786 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] #progress_metric: host=algo-1, completed 77.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=308, train loss <loss>=-1.0191572362726384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:30 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:33 INFO 140043348993664] Epoch[309] Batch[0] avg_epoch_loss=-1.088158\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=-1.088158130645752\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:37 INFO 140043348993664] Epoch[309] Batch[5] avg_epoch_loss=-1.088589\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=-1.088588813940684\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:37 INFO 140043348993664] Epoch[309] Batch [5]#011Speed: 75.85 samples/sec#011loss=-1.088589\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] Epoch[309] Batch[10] avg_epoch_loss=-1.082422\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=-1.0750226020812987\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] Epoch[309] Batch [10]#011Speed: 72.35 samples/sec#011loss=-1.075023\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743830.8300185, \"EndTime\": 1646743841.748255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10916.878938674927, \"count\": 1, \"min\": 10916.878938674927, \"max\": 10916.878938674927}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.187427610328214 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 77.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=309, train loss <loss>=-1.0824223540045999\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:41 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:44 INFO 140043348993664] Epoch[310] Batch[0] avg_epoch_loss=-1.029521\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=-1.0295206308364868\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:48 INFO 140043348993664] Epoch[310] Batch[5] avg_epoch_loss=-1.028932\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=-1.0289317965507507\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:48 INFO 140043348993664] Epoch[310] Batch [5]#011Speed: 75.70 samples/sec#011loss=-1.028932\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] Epoch[310] Batch[10] avg_epoch_loss=-1.060736\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=310, batch=10 train loss <loss>=-1.098901104927063\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] Epoch[310] Batch [10]#011Speed: 74.32 samples/sec#011loss=-1.098901\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743841.7486062, \"EndTime\": 1646743852.544535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10794.594526290894, \"count\": 1, \"min\": 10794.594526290894, \"max\": 10794.594526290894}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.41858393816035 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] #progress_metric: host=algo-1, completed 77.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=310, train loss <loss>=-1.0607360276308926\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:52 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:54 INFO 140043348993664] Epoch[311] Batch[0] avg_epoch_loss=-0.887320\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=-0.8873199820518494\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:59 INFO 140043348993664] Epoch[311] Batch[5] avg_epoch_loss=-0.927511\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=-0.927510937054952\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:50:59 INFO 140043348993664] Epoch[311] Batch [5]#011Speed: 74.68 samples/sec#011loss=-0.927511\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] Epoch[311] Batch[10] avg_epoch_loss=-0.947578\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=311, batch=10 train loss <loss>=-0.9716590642929077\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] Epoch[311] Batch [10]#011Speed: 69.32 samples/sec#011loss=-0.971659\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743852.5446758, \"EndTime\": 1646743863.665484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11119.950532913208, \"count\": 1, \"min\": 11119.950532913208, \"max\": 11119.950532913208}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.4187148436016 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] #progress_metric: host=algo-1, completed 78.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=311, train loss <loss>=-0.9475782676176592\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:03 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:06 INFO 140043348993664] Epoch[312] Batch[0] avg_epoch_loss=-0.822215\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=-0.8222148418426514\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:10 INFO 140043348993664] Epoch[312] Batch[5] avg_epoch_loss=-0.931103\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=-0.9311025242010752\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:10 INFO 140043348993664] Epoch[312] Batch [5]#011Speed: 70.38 samples/sec#011loss=-0.931103\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] Epoch[312] Batch[10] avg_epoch_loss=-0.984931\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=-1.049525213241577\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] Epoch[312] Batch [10]#011Speed: 72.95 samples/sec#011loss=-1.049525\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743863.6658628, \"EndTime\": 1646743874.9353578, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11268.05830001831, \"count\": 1, \"min\": 11268.05830001831, \"max\": 11268.05830001831}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.104230091850226 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] #progress_metric: host=algo-1, completed 78.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=312, train loss <loss>=-0.9849310192194852\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:14 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:17 INFO 140043348993664] Epoch[313] Batch[0] avg_epoch_loss=-1.068603\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=-1.0686028003692627\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:21 INFO 140043348993664] Epoch[313] Batch[5] avg_epoch_loss=-1.089838\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=-1.089838445186615\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:21 INFO 140043348993664] Epoch[313] Batch [5]#011Speed: 74.56 samples/sec#011loss=-1.089838\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] Epoch[313] Batch[10] avg_epoch_loss=-1.070778\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=313, batch=10 train loss <loss>=-1.0479065656661988\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] Epoch[313] Batch [10]#011Speed: 71.85 samples/sec#011loss=-1.047907\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743874.9354868, \"EndTime\": 1646743885.9493554, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11013.25249671936, \"count\": 1, \"min\": 11013.25249671936, \"max\": 11013.25249671936}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.65184267908696 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] #progress_metric: host=algo-1, completed 78.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=313, train loss <loss>=-1.0707784999500622\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:25 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:28 INFO 140043348993664] Epoch[314] Batch[0] avg_epoch_loss=-1.066196\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=-1.066196084022522\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:32 INFO 140043348993664] Epoch[314] Batch[5] avg_epoch_loss=-0.984291\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=-0.9842912356058756\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:32 INFO 140043348993664] Epoch[314] Batch [5]#011Speed: 75.76 samples/sec#011loss=-0.984291\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] Epoch[314] Batch[10] avg_epoch_loss=-1.015834\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=314, batch=10 train loss <loss>=-1.0536857485771178\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] Epoch[314] Batch [10]#011Speed: 77.71 samples/sec#011loss=-1.053686\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743885.949736, \"EndTime\": 1646743896.687523, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10736.315488815308, \"count\": 1, \"min\": 10736.315488815308, \"max\": 10736.315488815308}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.53989563315176 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 78.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=314, train loss <loss>=-1.0158341960473494\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:36 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:38 INFO 140043348993664] Epoch[315] Batch[0] avg_epoch_loss=-0.908016\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=-0.9080160856246948\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:43 INFO 140043348993664] Epoch[315] Batch[5] avg_epoch_loss=-0.964273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=-0.9642725984255472\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:43 INFO 140043348993664] Epoch[315] Batch [5]#011Speed: 75.84 samples/sec#011loss=-0.964273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] Epoch[315] Batch[10] avg_epoch_loss=-0.994317\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=315, batch=10 train loss <loss>=-1.0303692460060119\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] Epoch[315] Batch [10]#011Speed: 72.44 samples/sec#011loss=-1.030369\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743896.687888, \"EndTime\": 1646743907.585729, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10896.39687538147, \"count\": 1, \"min\": 10896.39687538147, \"max\": 10896.39687538147}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.201195309911185 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] #progress_metric: host=algo-1, completed 79.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=315, train loss <loss>=-0.9943165291439403\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:47 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:49 INFO 140043348993664] Epoch[316] Batch[0] avg_epoch_loss=-1.060020\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=-1.0600202083587646\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:54 INFO 140043348993664] Epoch[316] Batch[5] avg_epoch_loss=-1.016719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=-1.0167191127936046\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:54 INFO 140043348993664] Epoch[316] Batch [5]#011Speed: 74.13 samples/sec#011loss=-1.016719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] Epoch[316] Batch[10] avg_epoch_loss=-1.001467\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=316, batch=10 train loss <loss>=-0.9831648111343384\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] Epoch[316] Batch [10]#011Speed: 74.24 samples/sec#011loss=-0.983165\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743907.5860653, \"EndTime\": 1646743918.5567462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10969.29121017456, \"count\": 1, \"min\": 10969.29121017456, \"max\": 10969.29121017456}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.433511001883616 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] #progress_metric: host=algo-1, completed 79.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=316, train loss <loss>=-1.001467157493938\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:51:58 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:01 INFO 140043348993664] Epoch[317] Batch[0] avg_epoch_loss=-0.937778\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=-0.937777578830719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:05 INFO 140043348993664] Epoch[317] Batch[5] avg_epoch_loss=-0.921153\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=-0.9211525420347849\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:05 INFO 140043348993664] Epoch[317] Batch [5]#011Speed: 72.18 samples/sec#011loss=-0.921153\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] Epoch[317] Batch[10] avg_epoch_loss=-0.947534\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=317, batch=10 train loss <loss>=-0.9791928172111511\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] Epoch[317] Batch [10]#011Speed: 68.06 samples/sec#011loss=-0.979193\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743918.5571213, \"EndTime\": 1646743930.1502879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11591.816663742065, \"count\": 1, \"min\": 11591.816663742065, \"max\": 11591.816663742065}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.28112955935586 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] #progress_metric: host=algo-1, completed 79.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=317, train loss <loss>=-0.9475344852967695\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:10 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:12 INFO 140043348993664] Epoch[318] Batch[0] avg_epoch_loss=-0.915382\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=-0.9153816103935242\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:16 INFO 140043348993664] Epoch[318] Batch[5] avg_epoch_loss=-0.979465\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=-0.9794653654098511\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:16 INFO 140043348993664] Epoch[318] Batch [5]#011Speed: 74.80 samples/sec#011loss=-0.979465\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:20 INFO 140043348993664] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743930.1503665, \"EndTime\": 1646743940.0421546, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9891.138553619385, \"count\": 1, \"min\": 9891.138553619385, \"max\": 9891.138553619385}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:20 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.19773626455209 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:20 INFO 140043348993664] #progress_metric: host=algo-1, completed 79.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=318, train loss <loss>=-1.011361563205719\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:20 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:22 INFO 140043348993664] Epoch[319] Batch[0] avg_epoch_loss=-1.113339\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=-1.1133387088775635\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:26 INFO 140043348993664] Epoch[319] Batch[5] avg_epoch_loss=-1.107343\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=-1.1073426206906636\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:26 INFO 140043348993664] Epoch[319] Batch [5]#011Speed: 75.22 samples/sec#011loss=-1.107343\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] Epoch[319] Batch[10] avg_epoch_loss=-1.105296\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=-1.1028406381607057\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] Epoch[319] Batch [10]#011Speed: 74.78 samples/sec#011loss=-1.102841\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743940.0422702, \"EndTime\": 1646743950.758007, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10715.025663375854, \"count\": 1, \"min\": 10715.025663375854, \"max\": 10715.025663375854}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.71496263198591 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=319, train loss <loss>=-1.1052962649952283\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:30 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_0e174bfb-2c8a-413f-965b-b00d8bb5a174-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743950.7580924, \"EndTime\": 1646743950.8734052, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 113.55996131896973, \"count\": 1, \"min\": 113.55996131896973, \"max\": 113.55996131896973}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:33 INFO 140043348993664] Epoch[320] Batch[0] avg_epoch_loss=-0.827817\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=-0.8278173804283142\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:37 INFO 140043348993664] Epoch[320] Batch[5] avg_epoch_loss=-0.926233\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=-0.926233321428299\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:37 INFO 140043348993664] Epoch[320] Batch [5]#011Speed: 74.80 samples/sec#011loss=-0.926233\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] Epoch[320] Batch[10] avg_epoch_loss=-0.985982\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=-1.0576801657676698\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] Epoch[320] Batch [10]#011Speed: 73.49 samples/sec#011loss=-1.057680\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743950.8734748, \"EndTime\": 1646743961.7711382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10897.48740196228, \"count\": 1, \"min\": 10897.48740196228, \"max\": 10897.48740196228}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.37891621473032 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] #progress_metric: host=algo-1, completed 80.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=320, train loss <loss>=-0.9859818870371039\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:41 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:44 INFO 140043348993664] Epoch[321] Batch[0] avg_epoch_loss=-1.000768\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=-1.0007680654525757\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:48 INFO 140043348993664] Epoch[321] Batch[5] avg_epoch_loss=-1.021583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=-1.021583080291748\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:48 INFO 140043348993664] Epoch[321] Batch [5]#011Speed: 74.68 samples/sec#011loss=-1.021583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] Epoch[321] Batch[10] avg_epoch_loss=-1.039632\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=-1.061290979385376\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] Epoch[321] Batch [10]#011Speed: 71.80 samples/sec#011loss=-1.061291\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743961.7714455, \"EndTime\": 1646743972.8055956, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11033.018827438354, \"count\": 1, \"min\": 11033.018827438354, \"max\": 11033.018827438354}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.72802715323707 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] #progress_metric: host=algo-1, completed 80.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=321, train loss <loss>=-1.0396321253343062\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:52 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:55 INFO 140043348993664] Epoch[322] Batch[0] avg_epoch_loss=-1.060012\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=-1.0600124597549438\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:59 INFO 140043348993664] Epoch[322] Batch[5] avg_epoch_loss=-1.076538\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=-1.0765382448832195\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:52:59 INFO 140043348993664] Epoch[322] Batch [5]#011Speed: 72.92 samples/sec#011loss=-1.076538\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] Epoch[322] Batch[10] avg_epoch_loss=-1.089958\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=322, batch=10 train loss <loss>=-1.1060613870620728\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] Epoch[322] Batch [10]#011Speed: 69.70 samples/sec#011loss=-1.106061\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743972.8058765, \"EndTime\": 1646743984.108848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11301.776885986328, \"count\": 1, \"min\": 11301.776885986328, \"max\": 11301.776885986328}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=56.714135806296134 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 80.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=322, train loss <loss>=-1.0899578549645164\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:04 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:06 INFO 140043348993664] Epoch[323] Batch[0] avg_epoch_loss=-0.868791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=-0.8687911629676819\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:10 INFO 140043348993664] Epoch[323] Batch[5] avg_epoch_loss=-0.824495\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=-0.8244951168696085\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:10 INFO 140043348993664] Epoch[323] Batch [5]#011Speed: 73.19 samples/sec#011loss=-0.824495\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] Epoch[323] Batch[10] avg_epoch_loss=-0.840258\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=-0.8591732144355774\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] Epoch[323] Batch [10]#011Speed: 72.90 samples/sec#011loss=-0.859173\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743984.1093028, \"EndTime\": 1646743995.1234212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11012.61043548584, \"count\": 1, \"min\": 11012.61043548584, \"max\": 11012.61043548584}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.11184781951689 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] #progress_metric: host=algo-1, completed 81.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=323, train loss <loss>=-0.8402578884905035\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:15 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:17 INFO 140043348993664] Epoch[324] Batch[0] avg_epoch_loss=-0.933928\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=-0.9339275360107422\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:21 INFO 140043348993664] Epoch[324] Batch[5] avg_epoch_loss=-0.973611\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=-0.9736108481884003\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:21 INFO 140043348993664] Epoch[324] Batch [5]#011Speed: 75.75 samples/sec#011loss=-0.973611\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] Epoch[324] Batch[10] avg_epoch_loss=-0.990361\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=-1.0104611039161682\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] Epoch[324] Batch [10]#011Speed: 73.81 samples/sec#011loss=-1.010461\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646743995.1235511, \"EndTime\": 1646744005.9054513, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10781.279563903809, \"count\": 1, \"min\": 10781.279563903809, \"max\": 10781.279563903809}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.401657477891675 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] #progress_metric: host=algo-1, completed 81.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=324, train loss <loss>=-0.9903609644282948\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:25 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:28 INFO 140043348993664] Epoch[325] Batch[0] avg_epoch_loss=-0.837583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=-0.837582528591156\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:32 INFO 140043348993664] Epoch[325] Batch[5] avg_epoch_loss=-0.910269\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=-0.9102685252825419\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:32 INFO 140043348993664] Epoch[325] Batch [5]#011Speed: 74.35 samples/sec#011loss=-0.910269\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] Epoch[325] Batch[10] avg_epoch_loss=-0.905248\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=325, batch=10 train loss <loss>=-0.8992227554321289\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] Epoch[325] Batch [10]#011Speed: 76.35 samples/sec#011loss=-0.899223\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744005.9055846, \"EndTime\": 1646744016.6701062, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10763.789653778076, \"count\": 1, \"min\": 10763.789653778076, \"max\": 10763.789653778076}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.849724917302204 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] #progress_metric: host=algo-1, completed 81.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=325, train loss <loss>=-0.9052477208050814\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:36 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:38 INFO 140043348993664] Epoch[326] Batch[0] avg_epoch_loss=-0.627972\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=-0.6279721856117249\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:43 INFO 140043348993664] Epoch[326] Batch[5] avg_epoch_loss=-0.804653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=-0.8046527703603109\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:43 INFO 140043348993664] Epoch[326] Batch [5]#011Speed: 73.46 samples/sec#011loss=-0.804653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:47 INFO 140043348993664] Epoch[326] Batch[10] avg_epoch_loss=-0.866544\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=-0.9408124566078186\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:47 INFO 140043348993664] Epoch[326] Batch [10]#011Speed: 71.34 samples/sec#011loss=-0.940812\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:48 INFO 140043348993664] processed a total of 710 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744016.6704798, \"EndTime\": 1646744028.6405013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11968.753099441528, \"count\": 1, \"min\": 11968.753099441528, \"max\": 11968.753099441528}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.320387831212074 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 81.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=326, train loss <loss>=-0.8643142580986023\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:50 INFO 140043348993664] Epoch[327] Batch[0] avg_epoch_loss=-0.963131\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=-0.9631307125091553\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:55 INFO 140043348993664] Epoch[327] Batch[5] avg_epoch_loss=-0.984232\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=-0.9842319985230764\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:55 INFO 140043348993664] Epoch[327] Batch [5]#011Speed: 75.57 samples/sec#011loss=-0.984232\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:59 INFO 140043348993664] Epoch[327] Batch[10] avg_epoch_loss=-1.012487\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=-1.0463932514190675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:53:59 INFO 140043348993664] Epoch[327] Batch [10]#011Speed: 71.76 samples/sec#011loss=-1.046393\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:00 INFO 140043348993664] processed a total of 713 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744028.6406145, \"EndTime\": 1646744040.387358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11746.05131149292, \"count\": 1, \"min\": 11746.05131149292, \"max\": 11746.05131149292}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:00 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.698479375135065 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:00 INFO 140043348993664] #progress_metric: host=algo-1, completed 82.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=327, train loss <loss>=-1.0328927884499233\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:00 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:02 INFO 140043348993664] Epoch[328] Batch[0] avg_epoch_loss=-0.882214\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=-0.882214367389679\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:07 INFO 140043348993664] Epoch[328] Batch[5] avg_epoch_loss=-0.967959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=-0.9679591159025828\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:07 INFO 140043348993664] Epoch[328] Batch [5]#011Speed: 69.37 samples/sec#011loss=-0.967959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] Epoch[328] Batch[10] avg_epoch_loss=-0.974541\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=328, batch=10 train loss <loss>=-0.9824402809143067\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] Epoch[328] Batch [10]#011Speed: 75.82 samples/sec#011loss=-0.982440\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744040.3878293, \"EndTime\": 1646744051.7089057, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11319.43655014038, \"count\": 1, \"min\": 11319.43655014038, \"max\": 11319.43655014038}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.95271033885673 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] #progress_metric: host=algo-1, completed 82.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=328, train loss <loss>=-0.9745414636351846\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:11 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:14 INFO 140043348993664] Epoch[329] Batch[0] avg_epoch_loss=-0.793756\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=-0.7937561869621277\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:18 INFO 140043348993664] Epoch[329] Batch[5] avg_epoch_loss=-0.961972\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=-0.9619719187418619\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:18 INFO 140043348993664] Epoch[329] Batch [5]#011Speed: 75.37 samples/sec#011loss=-0.961972\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] Epoch[329] Batch[10] avg_epoch_loss=-0.998941\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=-1.0433037400245666\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] Epoch[329] Batch [10]#011Speed: 71.46 samples/sec#011loss=-1.043304\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744051.709004, \"EndTime\": 1646744062.7436907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11033.54525566101, \"count\": 1, \"min\": 11033.54525566101, \"max\": 11033.54525566101}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.813091131519776 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 82.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=329, train loss <loss>=-0.9989409284158186\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:24 INFO 140043348993664] Epoch[330] Batch[0] avg_epoch_loss=-1.114532\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=-1.1145321130752563\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:29 INFO 140043348993664] Epoch[330] Batch[5] avg_epoch_loss=-1.093395\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=-1.0933948159217834\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:29 INFO 140043348993664] Epoch[330] Batch [5]#011Speed: 74.83 samples/sec#011loss=-1.093395\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] Epoch[330] Batch[10] avg_epoch_loss=-1.095092\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=330, batch=10 train loss <loss>=-1.0971289157867432\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] Epoch[330] Batch [10]#011Speed: 73.20 samples/sec#011loss=-1.097129\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744062.7437875, \"EndTime\": 1646744073.6334064, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10888.926982879639, \"count\": 1, \"min\": 10888.926982879639, \"max\": 10888.926982879639}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.08876074125811 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 82.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=330, train loss <loss>=-1.0950921340422197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:35 INFO 140043348993664] Epoch[331] Batch[0] avg_epoch_loss=-1.124681\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=-1.1246808767318726\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:40 INFO 140043348993664] Epoch[331] Batch[5] avg_epoch_loss=-1.093955\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=-1.0939554075400035\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:40 INFO 140043348993664] Epoch[331] Batch [5]#011Speed: 75.07 samples/sec#011loss=-1.093955\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] Epoch[331] Batch[10] avg_epoch_loss=-1.093425\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=331, batch=10 train loss <loss>=-1.0927878379821778\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] Epoch[331] Batch [10]#011Speed: 74.25 samples/sec#011loss=-1.092788\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744073.633851, \"EndTime\": 1646744084.4352043, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10800.012350082397, \"count\": 1, \"min\": 10800.012350082397, \"max\": 10800.012350082397}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.406669248179526 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 83.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=331, train loss <loss>=-1.0934246941046282\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:46 INFO 140043348993664] Epoch[332] Batch[0] avg_epoch_loss=-1.041988\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=-1.041988492012024\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:50 INFO 140043348993664] Epoch[332] Batch[5] avg_epoch_loss=-1.080258\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=-1.0802576740582783\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:50 INFO 140043348993664] Epoch[332] Batch [5]#011Speed: 74.83 samples/sec#011loss=-1.080258\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] Epoch[332] Batch[10] avg_epoch_loss=-1.067209\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=332, batch=10 train loss <loss>=-1.051550281047821\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] Epoch[332] Batch [10]#011Speed: 74.96 samples/sec#011loss=-1.051550\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744084.4352827, \"EndTime\": 1646744095.2551582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10819.297313690186, \"count\": 1, \"min\": 10819.297313690186, \"max\": 10819.297313690186}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.924216632184915 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 83.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=332, train loss <loss>=-1.0672088590535251\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:57 INFO 140043348993664] Epoch[333] Batch[0] avg_epoch_loss=-0.943258\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:54:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=-0.9432582855224609\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:02 INFO 140043348993664] Epoch[333] Batch[5] avg_epoch_loss=-1.029059\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=-1.0290589531262715\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:02 INFO 140043348993664] Epoch[333] Batch [5]#011Speed: 71.22 samples/sec#011loss=-1.029059\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:05 INFO 140043348993664] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744095.2554998, \"EndTime\": 1646744105.412798, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10155.894756317139, \"count\": 1, \"min\": 10155.894756317139, \"max\": 10155.894756317139}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:05 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.468881790673336 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:05 INFO 140043348993664] #progress_metric: host=algo-1, completed 83.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=333, train loss <loss>=-1.0381714582443238\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:05 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:08 INFO 140043348993664] Epoch[334] Batch[0] avg_epoch_loss=-1.041497\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=-1.0414968729019165\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:12 INFO 140043348993664] Epoch[334] Batch[5] avg_epoch_loss=-1.082565\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=-1.0825646320978801\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:12 INFO 140043348993664] Epoch[334] Batch [5]#011Speed: 75.01 samples/sec#011loss=-1.082565\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:15 INFO 140043348993664] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744105.4133856, \"EndTime\": 1646744115.8423045, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10427.447080612183, \"count\": 1, \"min\": 10427.447080612183, \"max\": 10427.447080612183}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:15 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.93730298004391 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:15 INFO 140043348993664] #progress_metric: host=algo-1, completed 83.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=334, train loss <loss>=-1.1039064645767211\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:15 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:18 INFO 140043348993664] Epoch[335] Batch[0] avg_epoch_loss=-1.134806\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=-1.1348059177398682\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:22 INFO 140043348993664] Epoch[335] Batch[5] avg_epoch_loss=-1.133434\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=-1.1334341963132222\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:22 INFO 140043348993664] Epoch[335] Batch [5]#011Speed: 74.93 samples/sec#011loss=-1.133434\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] Epoch[335] Batch[10] avg_epoch_loss=-1.123944\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=335, batch=10 train loss <loss>=-1.1125550508499145\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] Epoch[335] Batch [10]#011Speed: 75.97 samples/sec#011loss=-1.112555\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744115.8423812, \"EndTime\": 1646744126.5962868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10753.428936004639, \"count\": 1, \"min\": 10753.428936004639, \"max\": 10753.428936004639}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.60634023456603 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 84.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=335, train loss <loss>=-1.1239436756480823\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:26 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_6b16c6cb-24a9-4251-acc0-fd931a52d15c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744126.5966837, \"EndTime\": 1646744126.7154555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 117.3257827758789, \"count\": 1, \"min\": 117.3257827758789, \"max\": 117.3257827758789}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:28 INFO 140043348993664] Epoch[336] Batch[0] avg_epoch_loss=-1.100653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=-1.100653052330017\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:33 INFO 140043348993664] Epoch[336] Batch[5] avg_epoch_loss=-1.002906\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=-1.0029062231381733\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:33 INFO 140043348993664] Epoch[336] Batch [5]#011Speed: 74.60 samples/sec#011loss=-1.002906\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] Epoch[336] Batch[10] avg_epoch_loss=-1.002854\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=336, batch=10 train loss <loss>=-1.0027905583381653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] Epoch[336] Batch [10]#011Speed: 72.93 samples/sec#011loss=-1.002791\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744126.7158523, \"EndTime\": 1646744137.6241083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10908.157348632812, \"count\": 1, \"min\": 10908.157348632812, \"max\": 10908.157348632812}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.496139192427165 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] #progress_metric: host=algo-1, completed 84.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=336, train loss <loss>=-1.0028536482290789\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:37 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:40 INFO 140043348993664] Epoch[337] Batch[0] avg_epoch_loss=-1.021572\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=-1.021572232246399\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:44 INFO 140043348993664] Epoch[337] Batch[5] avg_epoch_loss=-1.071381\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=-1.071380575497945\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:44 INFO 140043348993664] Epoch[337] Batch [5]#011Speed: 74.97 samples/sec#011loss=-1.071381\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] Epoch[337] Batch[10] avg_epoch_loss=-1.114959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=337, batch=10 train loss <loss>=-1.167253589630127\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] Epoch[337] Batch [10]#011Speed: 73.20 samples/sec#011loss=-1.167254\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744137.6241858, \"EndTime\": 1646744148.6418843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11017.240524291992, \"count\": 1, \"min\": 11017.240524291992, \"max\": 11017.240524291992}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.54370723970693 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 84.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=337, train loss <loss>=-1.1149592182853005\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:50 INFO 140043348993664] Epoch[338] Batch[0] avg_epoch_loss=-0.955599\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=-0.9555993676185608\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:55 INFO 140043348993664] Epoch[338] Batch[5] avg_epoch_loss=-0.922520\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=-0.9225204189618429\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:55 INFO 140043348993664] Epoch[338] Batch [5]#011Speed: 75.53 samples/sec#011loss=-0.922520\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] Epoch[338] Batch[10] avg_epoch_loss=-0.954440\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=-0.9927437424659729\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] Epoch[338] Batch [10]#011Speed: 73.50 samples/sec#011loss=-0.992744\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744148.6420138, \"EndTime\": 1646744159.4995136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10856.662034988403, \"count\": 1, \"min\": 10856.662034988403, \"max\": 10856.662034988403}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.895076251636326 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] #progress_metric: host=algo-1, completed 84.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=338, train loss <loss>=-0.9544401114637201\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:55:59 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:01 INFO 140043348993664] Epoch[339] Batch[0] avg_epoch_loss=-0.984022\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=-0.9840216040611267\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:06 INFO 140043348993664] Epoch[339] Batch[5] avg_epoch_loss=-1.038424\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=-1.0384244918823242\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:06 INFO 140043348993664] Epoch[339] Batch [5]#011Speed: 73.47 samples/sec#011loss=-1.038424\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] Epoch[339] Batch[10] avg_epoch_loss=-1.020441\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=339, batch=10 train loss <loss>=-0.9988613605499268\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] Epoch[339] Batch [10]#011Speed: 64.19 samples/sec#011loss=-0.998861\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744159.4998875, \"EndTime\": 1646744171.3362741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11834.686517715454, \"count\": 1, \"min\": 11834.686517715454, \"max\": 11834.686517715454}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=56.35783233041829 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=339, train loss <loss>=-1.0204412503675981\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:11 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:13 INFO 140043348993664] Epoch[340] Batch[0] avg_epoch_loss=-1.106444\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=-1.1064437627792358\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:17 INFO 140043348993664] Epoch[340] Batch[5] avg_epoch_loss=-1.092678\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=-1.0926779508590698\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:17 INFO 140043348993664] Epoch[340] Batch [5]#011Speed: 77.65 samples/sec#011loss=-1.092678\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] Epoch[340] Batch[10] avg_epoch_loss=-1.076415\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=340, batch=10 train loss <loss>=-1.0568987727165222\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] Epoch[340] Batch [10]#011Speed: 71.34 samples/sec#011loss=-1.056899\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744171.3366344, \"EndTime\": 1646744182.0584707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10720.269918441772, \"count\": 1, \"min\": 10720.269918441772, \"max\": 10720.269918441772}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.12296649444007 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 85.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=340, train loss <loss>=-1.0764146880670027\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:24 INFO 140043348993664] Epoch[341] Batch[0] avg_epoch_loss=-1.060860\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=-1.0608597993850708\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:28 INFO 140043348993664] Epoch[341] Batch[5] avg_epoch_loss=-1.101558\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=-1.1015583276748657\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:28 INFO 140043348993664] Epoch[341] Batch [5]#011Speed: 74.80 samples/sec#011loss=-1.101558\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] Epoch[341] Batch[10] avg_epoch_loss=-1.134951\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=341, batch=10 train loss <loss>=-1.1750232458114624\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] Epoch[341] Batch [10]#011Speed: 74.90 samples/sec#011loss=-1.175023\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744182.0588315, \"EndTime\": 1646744192.9022617, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10841.961860656738, \"count\": 1, \"min\": 10841.961860656738, \"max\": 10841.961860656738}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.673092702198595 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] #progress_metric: host=algo-1, completed 85.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=341, train loss <loss>=-1.1349514722824097\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:32 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:33 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_e208acfd-1597-464f-8ad3-4a6aea69e8cd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744192.9026418, \"EndTime\": 1646744193.023096, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 119.0180778503418, \"count\": 1, \"min\": 119.0180778503418, \"max\": 119.0180778503418}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:35 INFO 140043348993664] Epoch[342] Batch[0] avg_epoch_loss=-1.056566\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=-1.056565523147583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:39 INFO 140043348993664] Epoch[342] Batch[5] avg_epoch_loss=-0.954316\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=-0.9543158908685049\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:39 INFO 140043348993664] Epoch[342] Batch [5]#011Speed: 75.24 samples/sec#011loss=-0.954316\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] Epoch[342] Batch[10] avg_epoch_loss=-0.994252\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=-1.042176115512848\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] Epoch[342] Batch [10]#011Speed: 75.63 samples/sec#011loss=-1.042176\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744193.023523, \"EndTime\": 1646744203.7262845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10702.679872512817, \"count\": 1, \"min\": 10702.679872512817, \"max\": 10702.679872512817}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.97413409145111 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] #progress_metric: host=algo-1, completed 85.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=342, train loss <loss>=-0.9942523566159335\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:43 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:46 INFO 140043348993664] Epoch[343] Batch[0] avg_epoch_loss=-0.985370\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=-0.9853702783584595\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:50 INFO 140043348993664] Epoch[343] Batch[5] avg_epoch_loss=-0.872583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=-0.8725829621156057\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:50 INFO 140043348993664] Epoch[343] Batch [5]#011Speed: 75.57 samples/sec#011loss=-0.872583\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] Epoch[343] Batch[10] avg_epoch_loss=-0.903664\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=343, batch=10 train loss <loss>=-0.9409613609313965\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] Epoch[343] Batch [10]#011Speed: 75.95 samples/sec#011loss=-0.940961\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744203.7263713, \"EndTime\": 1646744214.528798, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10801.56683921814, \"count\": 1, \"min\": 10801.56683921814, \"max\": 10801.56683921814}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.099885081283375 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] #progress_metric: host=algo-1, completed 86.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=343, train loss <loss>=-0.9036640524864197\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:54 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:56 INFO 140043348993664] Epoch[344] Batch[0] avg_epoch_loss=-1.027187\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:56:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=-1.027186632156372\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:00 INFO 140043348993664] Epoch[344] Batch[5] avg_epoch_loss=-1.003463\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=-1.0034625331560771\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:00 INFO 140043348993664] Epoch[344] Batch [5]#011Speed: 75.43 samples/sec#011loss=-1.003463\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:04 INFO 140043348993664] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744214.5291395, \"EndTime\": 1646744224.557526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10025.644302368164, \"count\": 1, \"min\": 10025.644302368164, \"max\": 10025.644302368164}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:04 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.527450805232895 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:04 INFO 140043348993664] #progress_metric: host=algo-1, completed 86.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=344, train loss <loss>=-1.022392350435257\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:04 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:06 INFO 140043348993664] Epoch[345] Batch[0] avg_epoch_loss=-1.079727\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=-1.0797268152236938\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:11 INFO 140043348993664] Epoch[345] Batch[5] avg_epoch_loss=-1.088847\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=-1.0888465543588002\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:11 INFO 140043348993664] Epoch[345] Batch [5]#011Speed: 74.50 samples/sec#011loss=-1.088847\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] Epoch[345] Batch[10] avg_epoch_loss=-1.052180\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=345, batch=10 train loss <loss>=-1.0081790804862976\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] Epoch[345] Batch [10]#011Speed: 73.65 samples/sec#011loss=-1.008179\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744224.5576422, \"EndTime\": 1646744235.5875041, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11029.026746749878, \"count\": 1, \"min\": 11029.026746749878, \"max\": 11029.026746749878}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.108178241134055 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] #progress_metric: host=algo-1, completed 86.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=345, train loss <loss>=-1.05217952078039\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:15 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:17 INFO 140043348993664] Epoch[346] Batch[0] avg_epoch_loss=-1.105214\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=346, batch=0 train loss <loss>=-1.105214238166809\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:22 INFO 140043348993664] Epoch[346] Batch[5] avg_epoch_loss=-1.115048\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=346, batch=5 train loss <loss>=-1.1150484482447307\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:22 INFO 140043348993664] Epoch[346] Batch [5]#011Speed: 73.93 samples/sec#011loss=-1.115048\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] Epoch[346] Batch[10] avg_epoch_loss=-1.109675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=346, batch=10 train loss <loss>=-1.103227424621582\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] Epoch[346] Batch [10]#011Speed: 72.29 samples/sec#011loss=-1.103227\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744235.5875835, \"EndTime\": 1646744246.5699205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10981.68969154358, \"count\": 1, \"min\": 10981.68969154358, \"max\": 10981.68969154358}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.558480711291594 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] #progress_metric: host=algo-1, completed 86.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=346, train loss <loss>=-1.109675255688754\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:26 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:28 INFO 140043348993664] Epoch[347] Batch[0] avg_epoch_loss=-1.167980\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=347, batch=0 train loss <loss>=-1.1679801940917969\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:33 INFO 140043348993664] Epoch[347] Batch[5] avg_epoch_loss=-1.097368\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=347, batch=5 train loss <loss>=-1.097367525100708\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:33 INFO 140043348993664] Epoch[347] Batch [5]#011Speed: 75.12 samples/sec#011loss=-1.097368\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:37 INFO 140043348993664] Epoch[347] Batch[10] avg_epoch_loss=-1.088907\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=347, batch=10 train loss <loss>=-1.0787534832954406\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:37 INFO 140043348993664] Epoch[347] Batch [10]#011Speed: 71.90 samples/sec#011loss=-1.078753\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:38 INFO 140043348993664] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744246.570019, \"EndTime\": 1646744258.3916135, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11820.034265518188, \"count\": 1, \"min\": 11820.034265518188, \"max\": 11820.034265518188}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:38 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.89722220339656 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:38 INFO 140043348993664] #progress_metric: host=algo-1, completed 87.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=347, train loss <loss>=-1.084365392724673\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:38 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:40 INFO 140043348993664] Epoch[348] Batch[0] avg_epoch_loss=-0.585105\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=348, batch=0 train loss <loss>=-0.5851054787635803\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:44 INFO 140043348993664] Epoch[348] Batch[5] avg_epoch_loss=-0.642727\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=348, batch=5 train loss <loss>=-0.6427266597747803\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:44 INFO 140043348993664] Epoch[348] Batch [5]#011Speed: 75.18 samples/sec#011loss=-0.642727\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:48 INFO 140043348993664] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744258.3917828, \"EndTime\": 1646744268.3715398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9978.737831115723, \"count\": 1, \"min\": 9978.737831115723, \"max\": 9978.737831115723}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:48 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.12898242341213 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:48 INFO 140043348993664] #progress_metric: host=algo-1, completed 87.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=348, train loss <loss>=-0.66664137840271\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:48 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:50 INFO 140043348993664] Epoch[349] Batch[0] avg_epoch_loss=-0.745077\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=349, batch=0 train loss <loss>=-0.7450774908065796\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:54 INFO 140043348993664] Epoch[349] Batch[5] avg_epoch_loss=-0.795886\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=349, batch=5 train loss <loss>=-0.7958862582842509\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:54 INFO 140043348993664] Epoch[349] Batch [5]#011Speed: 76.55 samples/sec#011loss=-0.795886\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] Epoch[349] Batch[10] avg_epoch_loss=-0.826568\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=349, batch=10 train loss <loss>=-0.863385283946991\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] Epoch[349] Batch [10]#011Speed: 73.87 samples/sec#011loss=-0.863385\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744268.371645, \"EndTime\": 1646744279.170484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10797.448635101318, \"count\": 1, \"min\": 10797.448635101318, \"max\": 10797.448635101318}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.47480226979187 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] #progress_metric: host=algo-1, completed 87.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] #quality_metric: host=algo-1, epoch=349, train loss <loss>=-0.8265676335854963\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:57:59 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:01 INFO 140043348993664] Epoch[350] Batch[0] avg_epoch_loss=-0.929744\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=350, batch=0 train loss <loss>=-0.9297441840171814\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:05 INFO 140043348993664] Epoch[350] Batch[5] avg_epoch_loss=-0.959041\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=350, batch=5 train loss <loss>=-0.9590408007303873\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:05 INFO 140043348993664] Epoch[350] Batch [5]#011Speed: 71.11 samples/sec#011loss=-0.959041\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] Epoch[350] Batch[10] avg_epoch_loss=-0.994288\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=350, batch=10 train loss <loss>=-1.0365836858749389\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] Epoch[350] Batch [10]#011Speed: 71.54 samples/sec#011loss=-1.036584\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744279.1708748, \"EndTime\": 1646744290.407252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11234.982252120972, \"count\": 1, \"min\": 11234.982252120972, \"max\": 11234.982252120972}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.812213945635115 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] #progress_metric: host=algo-1, completed 87.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=350, train loss <loss>=-0.9942875667051836\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:10 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:12 INFO 140043348993664] Epoch[351] Batch[0] avg_epoch_loss=-1.147617\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=351, batch=0 train loss <loss>=-1.1476168632507324\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:16 INFO 140043348993664] Epoch[351] Batch[5] avg_epoch_loss=-1.092635\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=351, batch=5 train loss <loss>=-1.0926350752512615\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:16 INFO 140043348993664] Epoch[351] Batch [5]#011Speed: 74.09 samples/sec#011loss=-1.092635\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] Epoch[351] Batch[10] avg_epoch_loss=-1.110015\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=351, batch=10 train loss <loss>=-1.130870509147644\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] Epoch[351] Batch [10]#011Speed: 71.04 samples/sec#011loss=-1.130871\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744290.4073935, \"EndTime\": 1646744301.4462812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11037.434101104736, \"count\": 1, \"min\": 11037.434101104736, \"max\": 11037.434101104736}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.41819605697357 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] #progress_metric: host=algo-1, completed 88.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] #quality_metric: host=algo-1, epoch=351, train loss <loss>=-1.1100148179314353\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:21 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:23 INFO 140043348993664] Epoch[352] Batch[0] avg_epoch_loss=-1.091151\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=352, batch=0 train loss <loss>=-1.0911513566970825\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:27 INFO 140043348993664] Epoch[352] Batch[5] avg_epoch_loss=-1.113212\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=352, batch=5 train loss <loss>=-1.1132123271624248\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:27 INFO 140043348993664] Epoch[352] Batch [5]#011Speed: 75.49 samples/sec#011loss=-1.113212\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] Epoch[352] Batch[10] avg_epoch_loss=-1.122059\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=352, batch=10 train loss <loss>=-1.1326746702194215\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] Epoch[352] Batch [10]#011Speed: 74.72 samples/sec#011loss=-1.132675\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744301.446645, \"EndTime\": 1646744312.2038069, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10755.784749984741, \"count\": 1, \"min\": 10755.784749984741, \"max\": 10755.784749984741}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.2893713416114 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] #progress_metric: host=algo-1, completed 88.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] #quality_metric: host=algo-1, epoch=352, train loss <loss>=-1.1220588467337869\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:32 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:34 INFO 140043348993664] Epoch[353] Batch[0] avg_epoch_loss=-1.004937\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=353, batch=0 train loss <loss>=-1.0049368143081665\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:38 INFO 140043348993664] Epoch[353] Batch[5] avg_epoch_loss=-1.016351\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:38 INFO 140043348993664] #quality_metric: host=algo-1, epoch=353, batch=5 train loss <loss>=-1.0163514912128448\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:38 INFO 140043348993664] Epoch[353] Batch [5]#011Speed: 76.49 samples/sec#011loss=-1.016351\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] Epoch[353] Batch[10] avg_epoch_loss=-1.030762\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=353, batch=10 train loss <loss>=-1.0480542302131652\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] Epoch[353] Batch [10]#011Speed: 71.98 samples/sec#011loss=-1.048054\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744312.204173, \"EndTime\": 1646744323.0785015, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10871.756315231323, \"count\": 1, \"min\": 10871.756315231323, \"max\": 10871.756315231323}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.27077538232888 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] #progress_metric: host=algo-1, completed 88.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] #quality_metric: host=algo-1, epoch=353, train loss <loss>=-1.0307618271220813\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:43 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:45 INFO 140043348993664] Epoch[354] Batch[0] avg_epoch_loss=-1.123474\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=354, batch=0 train loss <loss>=-1.1234736442565918\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:49 INFO 140043348993664] Epoch[354] Batch[5] avg_epoch_loss=-1.077907\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=354, batch=5 train loss <loss>=-1.0779067476590474\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:49 INFO 140043348993664] Epoch[354] Batch [5]#011Speed: 73.93 samples/sec#011loss=-1.077907\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] Epoch[354] Batch[10] avg_epoch_loss=-1.077476\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=354, batch=10 train loss <loss>=-1.0769593834877014\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] Epoch[354] Batch [10]#011Speed: 72.63 samples/sec#011loss=-1.076959\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] processed a total of 703 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744323.0785804, \"EndTime\": 1646744334.0563958, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10977.339267730713, \"count\": 1, \"min\": 10977.339267730713, \"max\": 10977.339267730713}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.03933114398397 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] #progress_metric: host=algo-1, completed 88.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] #quality_metric: host=algo-1, epoch=354, train loss <loss>=-1.0774761275811628\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:54 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:56 INFO 140043348993664] Epoch[355] Batch[0] avg_epoch_loss=-1.178273\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:58:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=355, batch=0 train loss <loss>=-1.17827308177948\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:00 INFO 140043348993664] Epoch[355] Batch[5] avg_epoch_loss=-1.100908\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=355, batch=5 train loss <loss>=-1.10090837876002\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:00 INFO 140043348993664] Epoch[355] Batch [5]#011Speed: 73.97 samples/sec#011loss=-1.100908\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] Epoch[355] Batch[10] avg_epoch_loss=-1.107886\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=355, batch=10 train loss <loss>=-1.1162590742111207\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] Epoch[355] Batch [10]#011Speed: 70.50 samples/sec#011loss=-1.116259\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744334.0566406, \"EndTime\": 1646744345.2360494, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11178.282737731934, \"count\": 1, \"min\": 11178.282737731934, \"max\": 11178.282737731934}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.635799649339035 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] #progress_metric: host=algo-1, completed 89.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=355, train loss <loss>=-1.1078859676014294\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:05 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:07 INFO 140043348993664] Epoch[356] Batch[0] avg_epoch_loss=-1.102934\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=356, batch=0 train loss <loss>=-1.1029338836669922\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:11 INFO 140043348993664] Epoch[356] Batch[5] avg_epoch_loss=-1.086760\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=356, batch=5 train loss <loss>=-1.0867597858111064\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:11 INFO 140043348993664] Epoch[356] Batch [5]#011Speed: 75.31 samples/sec#011loss=-1.086760\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:16 INFO 140043348993664] Epoch[356] Batch[10] avg_epoch_loss=-1.099204\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:16 INFO 140043348993664] #quality_metric: host=algo-1, epoch=356, batch=10 train loss <loss>=-1.114137387275696\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:16 INFO 140043348993664] Epoch[356] Batch [10]#011Speed: 67.47 samples/sec#011loss=-1.114137\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:17 INFO 140043348993664] processed a total of 718 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744345.2362893, \"EndTime\": 1646744357.285085, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12047.462224960327, \"count\": 1, \"min\": 12047.462224960327, \"max\": 12047.462224960327}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.59684120206191 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 89.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=356, train loss <loss>=-1.0900784581899643\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:17 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:19 INFO 140043348993664] Epoch[357] Batch[0] avg_epoch_loss=-1.125741\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=357, batch=0 train loss <loss>=-1.125740647315979\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:23 INFO 140043348993664] Epoch[357] Batch[5] avg_epoch_loss=-1.124311\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=357, batch=5 train loss <loss>=-1.1243106722831726\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:23 INFO 140043348993664] Epoch[357] Batch [5]#011Speed: 74.21 samples/sec#011loss=-1.124311\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] Epoch[357] Batch[10] avg_epoch_loss=-1.108390\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=357, batch=10 train loss <loss>=-1.0892847418785094\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] Epoch[357] Batch [10]#011Speed: 72.67 samples/sec#011loss=-1.089285\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744357.285182, \"EndTime\": 1646744368.3132656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11027.416706085205, \"count\": 1, \"min\": 11027.416706085205, \"max\": 11027.416706085205}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.20877614388683 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 89.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=357, train loss <loss>=-1.1083897948265076\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:30 INFO 140043348993664] Epoch[358] Batch[0] avg_epoch_loss=-0.953175\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=358, batch=0 train loss <loss>=-0.9531751871109009\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:34 INFO 140043348993664] Epoch[358] Batch[5] avg_epoch_loss=-1.024045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=358, batch=5 train loss <loss>=-1.0240445534388225\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:34 INFO 140043348993664] Epoch[358] Batch [5]#011Speed: 75.98 samples/sec#011loss=-1.024045\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] Epoch[358] Batch[10] avg_epoch_loss=-1.069562\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=358, batch=10 train loss <loss>=-1.124183464050293\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] Epoch[358] Batch [10]#011Speed: 74.13 samples/sec#011loss=-1.124183\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744368.313625, \"EndTime\": 1646744379.834109, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11518.994808197021, \"count\": 1, \"min\": 11518.994808197021, \"max\": 11518.994808197021}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.54789549132343 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 89.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=358, train loss <loss>=-1.0692815283934276\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:42 INFO 140043348993664] Epoch[359] Batch[0] avg_epoch_loss=-1.173899\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=359, batch=0 train loss <loss>=-1.1738992929458618\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:46 INFO 140043348993664] Epoch[359] Batch[5] avg_epoch_loss=-1.123379\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=359, batch=5 train loss <loss>=-1.1233789920806885\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:46 INFO 140043348993664] Epoch[359] Batch [5]#011Speed: 74.57 samples/sec#011loss=-1.123379\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] Epoch[359] Batch[10] avg_epoch_loss=-1.117593\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=359, batch=10 train loss <loss>=-1.110649037361145\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] Epoch[359] Batch [10]#011Speed: 73.89 samples/sec#011loss=-1.110649\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744379.8345404, \"EndTime\": 1646744390.727159, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10891.157865524292, \"count\": 1, \"min\": 10891.157865524292, \"max\": 10891.157865524292}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.0680631755295 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=359, train loss <loss>=-1.1175926490263506\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:50 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:52 INFO 140043348993664] Epoch[360] Batch[0] avg_epoch_loss=-1.071805\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=360, batch=0 train loss <loss>=-1.0718051195144653\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:57 INFO 140043348993664] Epoch[360] Batch[5] avg_epoch_loss=-1.080636\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=360, batch=5 train loss <loss>=-1.0806358456611633\u001b[0m\n",
      "\u001b[34m[03/08/2022 12:59:57 INFO 140043348993664] Epoch[360] Batch [5]#011Speed: 75.07 samples/sec#011loss=-1.080636\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] Epoch[360] Batch[10] avg_epoch_loss=-1.064957\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=360, batch=10 train loss <loss>=-1.04614315032959\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] Epoch[360] Batch [10]#011Speed: 70.83 samples/sec#011loss=-1.046143\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744390.727233, \"EndTime\": 1646744401.7079823, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10980.307817459106, \"count\": 1, \"min\": 10980.307817459106, \"max\": 10980.307817459106}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.02064824891387 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] #progress_metric: host=algo-1, completed 90.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=360, train loss <loss>=-1.0649573477831753\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:01 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:04 INFO 140043348993664] Epoch[361] Batch[0] avg_epoch_loss=-1.123184\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=361, batch=0 train loss <loss>=-1.1231842041015625\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:08 INFO 140043348993664] Epoch[361] Batch[5] avg_epoch_loss=-1.095183\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=361, batch=5 train loss <loss>=-1.0951825976371765\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:08 INFO 140043348993664] Epoch[361] Batch [5]#011Speed: 71.55 samples/sec#011loss=-1.095183\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] Epoch[361] Batch[10] avg_epoch_loss=-1.126006\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=361, batch=10 train loss <loss>=-1.1629931926727295\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] Epoch[361] Batch [10]#011Speed: 73.56 samples/sec#011loss=-1.162993\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744401.7080693, \"EndTime\": 1646744412.8529832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11143.866062164307, \"count\": 1, \"min\": 11143.866062164307, \"max\": 11143.866062164307}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.77575233455621 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] #progress_metric: host=algo-1, completed 90.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=361, train loss <loss>=-1.1260055953806096\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:12 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:15 INFO 140043348993664] Epoch[362] Batch[0] avg_epoch_loss=-1.083032\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=362, batch=0 train loss <loss>=-1.083032250404358\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:19 INFO 140043348993664] Epoch[362] Batch[5] avg_epoch_loss=-1.128632\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=362, batch=5 train loss <loss>=-1.128632167975108\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:19 INFO 140043348993664] Epoch[362] Batch [5]#011Speed: 76.38 samples/sec#011loss=-1.128632\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] Epoch[362] Batch[10] avg_epoch_loss=-1.150332\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=362, batch=10 train loss <loss>=-1.1763715028762818\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] Epoch[362] Batch [10]#011Speed: 72.82 samples/sec#011loss=-1.176372\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744412.8531106, \"EndTime\": 1646744423.7404668, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10886.496305465698, \"count\": 1, \"min\": 10886.496305465698, \"max\": 10886.496305465698}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.46013405031111 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] #progress_metric: host=algo-1, completed 90.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=362, train loss <loss>=-1.1503318656574597\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:23 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_daa11bc9-6bee-42e5-9e2d-6622e02fab8f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744423.7408726, \"EndTime\": 1646744423.8638065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 121.49286270141602, \"count\": 1, \"min\": 121.49286270141602, \"max\": 121.49286270141602}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:26 INFO 140043348993664] Epoch[363] Batch[0] avg_epoch_loss=-1.053563\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:26 INFO 140043348993664] #quality_metric: host=algo-1, epoch=363, batch=0 train loss <loss>=-1.053562879562378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:30 INFO 140043348993664] Epoch[363] Batch[5] avg_epoch_loss=-1.095919\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=363, batch=5 train loss <loss>=-1.0959185560544331\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:30 INFO 140043348993664] Epoch[363] Batch [5]#011Speed: 73.72 samples/sec#011loss=-1.095919\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:33 INFO 140043348993664] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744423.864235, \"EndTime\": 1646744433.887619, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10023.285388946533, \"count\": 1, \"min\": 10023.285388946533, \"max\": 10023.285388946533}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.852805621981034 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 91.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=363, train loss <loss>=-1.1192266464233398\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:36 INFO 140043348993664] Epoch[364] Batch[0] avg_epoch_loss=-1.214832\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:36 INFO 140043348993664] #quality_metric: host=algo-1, epoch=364, batch=0 train loss <loss>=-1.214831829071045\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:40 INFO 140043348993664] Epoch[364] Batch[5] avg_epoch_loss=-1.075639\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=364, batch=5 train loss <loss>=-1.0756394863128662\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:40 INFO 140043348993664] Epoch[364] Batch [5]#011Speed: 74.79 samples/sec#011loss=-1.075639\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] Epoch[364] Batch[10] avg_epoch_loss=-1.078034\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=364, batch=10 train loss <loss>=-1.0809083938598634\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] Epoch[364] Batch [10]#011Speed: 72.84 samples/sec#011loss=-1.080908\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744433.887711, \"EndTime\": 1646744444.8953977, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11006.021738052368, \"count\": 1, \"min\": 11006.021738052368, \"max\": 11006.021738052368}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.69241780073963 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 91.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=364, train loss <loss>=-1.078034444288774\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:47 INFO 140043348993664] Epoch[365] Batch[0] avg_epoch_loss=-1.039983\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:47 INFO 140043348993664] #quality_metric: host=algo-1, epoch=365, batch=0 train loss <loss>=-1.0399833917617798\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:51 INFO 140043348993664] Epoch[365] Batch[5] avg_epoch_loss=-0.965539\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=365, batch=5 train loss <loss>=-0.9655391275882721\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:51 INFO 140043348993664] Epoch[365] Batch [5]#011Speed: 73.12 samples/sec#011loss=-0.965539\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] Epoch[365] Batch[10] avg_epoch_loss=-0.998913\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=365, batch=10 train loss <loss>=-1.0389610648155212\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] Epoch[365] Batch [10]#011Speed: 71.48 samples/sec#011loss=-1.038961\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744444.8957438, \"EndTime\": 1646744455.9055579, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11008.409976959229, \"count\": 1, \"min\": 11008.409976959229, \"max\": 11008.409976959229}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.40496352048851 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 91.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=365, train loss <loss>=-0.9989127354188398\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:58 INFO 140043348993664] Epoch[366] Batch[0] avg_epoch_loss=-1.031019\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:00:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=366, batch=0 train loss <loss>=-1.0310187339782715\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:02 INFO 140043348993664] Epoch[366] Batch[5] avg_epoch_loss=-1.066885\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=366, batch=5 train loss <loss>=-1.0668852925300598\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:02 INFO 140043348993664] Epoch[366] Batch [5]#011Speed: 71.90 samples/sec#011loss=-1.066885\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] Epoch[366] Batch[10] avg_epoch_loss=-1.105609\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=366, batch=10 train loss <loss>=-1.1520780324935913\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] Epoch[366] Batch [10]#011Speed: 69.93 samples/sec#011loss=-1.152078\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744455.9057791, \"EndTime\": 1646744467.212586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11305.765867233276, \"count\": 1, \"min\": 11305.765867233276, \"max\": 11305.765867233276}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.46169293346973 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] #progress_metric: host=algo-1, completed 91.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=366, train loss <loss>=-1.1056092652407559\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:07 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:09 INFO 140043348993664] Epoch[367] Batch[0] avg_epoch_loss=-1.189896\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=367, batch=0 train loss <loss>=-1.1898962259292603\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:13 INFO 140043348993664] Epoch[367] Batch[5] avg_epoch_loss=-1.159931\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=367, batch=5 train loss <loss>=-1.159931222597758\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:13 INFO 140043348993664] Epoch[367] Batch [5]#011Speed: 76.35 samples/sec#011loss=-1.159931\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] Epoch[367] Batch[10] avg_epoch_loss=-1.122829\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=367, batch=10 train loss <loss>=-1.0783052921295166\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] Epoch[367] Batch [10]#011Speed: 73.20 samples/sec#011loss=-1.078305\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] processed a total of 703 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744467.2133212, \"EndTime\": 1646744478.0177507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10802.999019622803, \"count\": 1, \"min\": 10802.999019622803, \"max\": 10802.999019622803}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=65.07329864723879 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] #progress_metric: host=algo-1, completed 92.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=367, train loss <loss>=-1.1228285269303755\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:18 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:20 INFO 140043348993664] Epoch[368] Batch[0] avg_epoch_loss=-1.055506\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:20 INFO 140043348993664] #quality_metric: host=algo-1, epoch=368, batch=0 train loss <loss>=-1.0555061101913452\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:24 INFO 140043348993664] Epoch[368] Batch[5] avg_epoch_loss=-1.115666\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=368, batch=5 train loss <loss>=-1.1156657735506694\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:24 INFO 140043348993664] Epoch[368] Batch [5]#011Speed: 75.60 samples/sec#011loss=-1.115666\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] Epoch[368] Batch[10] avg_epoch_loss=-1.107839\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=368, batch=10 train loss <loss>=-1.098446214199066\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] Epoch[368] Batch [10]#011Speed: 76.82 samples/sec#011loss=-1.098446\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744478.0178978, \"EndTime\": 1646744488.723166, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10704.230308532715, \"count\": 1, \"min\": 10704.230308532715, \"max\": 10704.230308532715}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.93671243258276 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 92.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=368, train loss <loss>=-1.1078387011181225\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:30 INFO 140043348993664] Epoch[369] Batch[0] avg_epoch_loss=-1.023996\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=369, batch=0 train loss <loss>=-1.0239956378936768\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:35 INFO 140043348993664] Epoch[369] Batch[5] avg_epoch_loss=-0.976649\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=369, batch=5 train loss <loss>=-0.9766492545604706\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:35 INFO 140043348993664] Epoch[369] Batch [5]#011Speed: 76.55 samples/sec#011loss=-0.976649\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] Epoch[369] Batch[10] avg_epoch_loss=-0.972800\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=369, batch=10 train loss <loss>=-0.9681814432144165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] Epoch[369] Batch [10]#011Speed: 74.35 samples/sec#011loss=-0.968181\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744488.7232552, \"EndTime\": 1646744499.4286964, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10704.407453536987, \"count\": 1, \"min\": 10704.407453536987, \"max\": 10704.407453536987}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.02975827948862 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 92.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=369, train loss <loss>=-0.9728002494031732\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:41 INFO 140043348993664] Epoch[370] Batch[0] avg_epoch_loss=-1.054910\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=370, batch=0 train loss <loss>=-1.0549100637435913\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:45 INFO 140043348993664] Epoch[370] Batch[5] avg_epoch_loss=-1.012921\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=370, batch=5 train loss <loss>=-1.0129208862781525\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:45 INFO 140043348993664] Epoch[370] Batch [5]#011Speed: 74.73 samples/sec#011loss=-1.012921\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] Epoch[370] Batch[10] avg_epoch_loss=-1.052609\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=370, batch=10 train loss <loss>=-1.1002343893051147\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] Epoch[370] Batch [10]#011Speed: 74.52 samples/sec#011loss=-1.100234\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744499.4287932, \"EndTime\": 1646744510.241337, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10812.100172042847, \"count\": 1, \"min\": 10812.100172042847, \"max\": 10812.100172042847}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.427605257073196 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] #progress_metric: host=algo-1, completed 92.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=370, train loss <loss>=-1.052608842199499\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:50 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:52 INFO 140043348993664] Epoch[371] Batch[0] avg_epoch_loss=-1.060278\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=371, batch=0 train loss <loss>=-1.0602777004241943\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:56 INFO 140043348993664] Epoch[371] Batch[5] avg_epoch_loss=-1.091873\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=371, batch=5 train loss <loss>=-1.0918731490770976\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:01:56 INFO 140043348993664] Epoch[371] Batch [5]#011Speed: 74.29 samples/sec#011loss=-1.091873\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] Epoch[371] Batch[10] avg_epoch_loss=-1.114318\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=371, batch=10 train loss <loss>=-1.1412525415420531\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] Epoch[371] Batch [10]#011Speed: 73.97 samples/sec#011loss=-1.141253\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744510.2417197, \"EndTime\": 1646744521.9352078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11692.030906677246, \"count\": 1, \"min\": 11692.030906677246, \"max\": 11692.030906677246}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.89454676579792 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] #progress_metric: host=algo-1, completed 93.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=371, train loss <loss>=-1.1085050304730732\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:01 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:04 INFO 140043348993664] Epoch[372] Batch[0] avg_epoch_loss=-0.487925\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:04 INFO 140043348993664] #quality_metric: host=algo-1, epoch=372, batch=0 train loss <loss>=-0.48792532086372375\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:08 INFO 140043348993664] Epoch[372] Batch[5] avg_epoch_loss=-0.719816\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=372, batch=5 train loss <loss>=-0.7198162525892258\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:08 INFO 140043348993664] Epoch[372] Batch [5]#011Speed: 70.65 samples/sec#011loss=-0.719816\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] Epoch[372] Batch[10] avg_epoch_loss=-0.794844\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=372, batch=10 train loss <loss>=-0.8848767399787902\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] Epoch[372] Batch [10]#011Speed: 73.01 samples/sec#011loss=-0.884877\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744521.9353065, \"EndTime\": 1646744533.0301814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11093.433856964111, \"count\": 1, \"min\": 11093.433856964111, \"max\": 11093.433856964111}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.18970474089705 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] #progress_metric: host=algo-1, completed 93.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=372, train loss <loss>=-0.7948437468572096\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:13 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:15 INFO 140043348993664] Epoch[373] Batch[0] avg_epoch_loss=-0.980589\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:15 INFO 140043348993664] #quality_metric: host=algo-1, epoch=373, batch=0 train loss <loss>=-0.9805886745452881\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:19 INFO 140043348993664] Epoch[373] Batch[5] avg_epoch_loss=-1.012350\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=373, batch=5 train loss <loss>=-1.0123499035835266\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:19 INFO 140043348993664] Epoch[373] Batch [5]#011Speed: 76.10 samples/sec#011loss=-1.012350\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:22 INFO 140043348993664] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744533.0302615, \"EndTime\": 1646744542.991782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9960.918426513672, \"count\": 1, \"min\": 9960.918426513672, \"max\": 9960.918426513672}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.33498875518036 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 93.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=373, train loss <loss>=-1.019571840763092\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:25 INFO 140043348993664] Epoch[374] Batch[0] avg_epoch_loss=-1.002471\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=374, batch=0 train loss <loss>=-1.002470850944519\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:29 INFO 140043348993664] Epoch[374] Batch[5] avg_epoch_loss=-1.110005\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=374, batch=5 train loss <loss>=-1.1100054581960042\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:29 INFO 140043348993664] Epoch[374] Batch [5]#011Speed: 76.74 samples/sec#011loss=-1.110005\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] Epoch[374] Batch[10] avg_epoch_loss=-1.139927\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=374, batch=10 train loss <loss>=-1.175833034515381\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] Epoch[374] Batch [10]#011Speed: 74.94 samples/sec#011loss=-1.175833\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744542.991862, \"EndTime\": 1646744553.7162075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10723.675727844238, \"count\": 1, \"min\": 10723.675727844238, \"max\": 10723.675727844238}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.82348184819876 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 93.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=374, train loss <loss>=-1.139927083795721\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:35 INFO 140043348993664] Epoch[375] Batch[0] avg_epoch_loss=-1.101362\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=375, batch=0 train loss <loss>=-1.101361632347107\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:40 INFO 140043348993664] Epoch[375] Batch[5] avg_epoch_loss=-1.049417\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=375, batch=5 train loss <loss>=-1.0494171778361003\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:40 INFO 140043348993664] Epoch[375] Batch [5]#011Speed: 75.57 samples/sec#011loss=-1.049417\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] Epoch[375] Batch[10] avg_epoch_loss=-1.036521\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=375, batch=10 train loss <loss>=-1.0210449337959289\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] Epoch[375] Batch [10]#011Speed: 74.93 samples/sec#011loss=-1.021045\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744553.7165742, \"EndTime\": 1646744564.469863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10751.914501190186, \"count\": 1, \"min\": 10751.914501190186, \"max\": 10751.914501190186}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.708855709999355 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 94.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=375, train loss <loss>=-1.036520703272386\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:46 INFO 140043348993664] Epoch[376] Batch[0] avg_epoch_loss=-1.032309\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=376, batch=0 train loss <loss>=-1.0323086977005005\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:51 INFO 140043348993664] Epoch[376] Batch[5] avg_epoch_loss=-0.978458\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=376, batch=5 train loss <loss>=-0.9784580568472544\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:51 INFO 140043348993664] Epoch[376] Batch [5]#011Speed: 73.39 samples/sec#011loss=-0.978458\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] Epoch[376] Batch[10] avg_epoch_loss=-1.034819\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=376, batch=10 train loss <loss>=-1.1024523019790649\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] Epoch[376] Batch [10]#011Speed: 72.08 samples/sec#011loss=-1.102452\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744564.4700763, \"EndTime\": 1646744575.476921, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11005.964517593384, \"count\": 1, \"min\": 11005.964517593384, \"max\": 11005.964517593384}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.51008887447935 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 94.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=376, train loss <loss>=-1.0348190773617139\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:57 INFO 140043348993664] Epoch[377] Batch[0] avg_epoch_loss=-0.911732\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:02:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=377, batch=0 train loss <loss>=-0.9117322564125061\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:02 INFO 140043348993664] Epoch[377] Batch[5] avg_epoch_loss=-1.003140\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=377, batch=5 train loss <loss>=-1.003139813741048\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:02 INFO 140043348993664] Epoch[377] Batch [5]#011Speed: 72.40 samples/sec#011loss=-1.003140\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] Epoch[377] Batch[10] avg_epoch_loss=-1.072758\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=377, batch=10 train loss <loss>=-1.1563007831573486\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] Epoch[377] Batch [10]#011Speed: 69.18 samples/sec#011loss=-1.156301\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744575.4772298, \"EndTime\": 1646744586.751692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11273.30994606018, \"count\": 1, \"min\": 11273.30994606018, \"max\": 11273.30994606018}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.30194573695659 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] #progress_metric: host=algo-1, completed 94.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=377, train loss <loss>=-1.072758436203003\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:06 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:09 INFO 140043348993664] Epoch[378] Batch[0] avg_epoch_loss=-0.980593\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:09 INFO 140043348993664] #quality_metric: host=algo-1, epoch=378, batch=0 train loss <loss>=-0.9805930852890015\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:13 INFO 140043348993664] Epoch[378] Batch[5] avg_epoch_loss=-0.863864\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=378, batch=5 train loss <loss>=-0.8638637165228525\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:13 INFO 140043348993664] Epoch[378] Batch [5]#011Speed: 74.91 samples/sec#011loss=-0.863864\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] Epoch[378] Batch[10] avg_epoch_loss=-0.906107\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=378, batch=10 train loss <loss>=-0.9567984700202942\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] Epoch[378] Batch [10]#011Speed: 73.08 samples/sec#011loss=-0.956798\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744586.7518458, \"EndTime\": 1646744597.6940823, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10941.163778305054, \"count\": 1, \"min\": 10941.163778305054, \"max\": 10941.163778305054}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.52047726279126 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 94.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=378, train loss <loss>=-0.906106786294417\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:17 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:19 INFO 140043348993664] Epoch[379] Batch[0] avg_epoch_loss=-0.987822\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=379, batch=0 train loss <loss>=-0.9878223538398743\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:24 INFO 140043348993664] Epoch[379] Batch[5] avg_epoch_loss=-1.062644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=379, batch=5 train loss <loss>=-1.0626436173915863\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:24 INFO 140043348993664] Epoch[379] Batch [5]#011Speed: 77.00 samples/sec#011loss=-1.062644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] Epoch[379] Batch[10] avg_epoch_loss=-1.059901\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=379, batch=10 train loss <loss>=-1.0566108226776123\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] Epoch[379] Batch [10]#011Speed: 72.44 samples/sec#011loss=-1.056611\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744597.694218, \"EndTime\": 1646744608.4227464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10727.792263031006, \"count\": 1, \"min\": 10727.792263031006, \"max\": 10727.792263031006}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.75789235351706 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=379, train loss <loss>=-1.0599014379761436\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:30 INFO 140043348993664] Epoch[380] Batch[0] avg_epoch_loss=-1.063121\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=380, batch=0 train loss <loss>=-1.06312096118927\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:34 INFO 140043348993664] Epoch[380] Batch[5] avg_epoch_loss=-1.112712\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=380, batch=5 train loss <loss>=-1.1127121249834697\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:34 INFO 140043348993664] Epoch[380] Batch [5]#011Speed: 75.14 samples/sec#011loss=-1.112712\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] Epoch[380] Batch[10] avg_epoch_loss=-1.116190\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=380, batch=10 train loss <loss>=-1.120362401008606\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] Epoch[380] Batch [10]#011Speed: 74.58 samples/sec#011loss=-1.120362\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] processed a total of 714 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744608.422835, \"EndTime\": 1646744619.8823078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11457.995176315308, \"count\": 1, \"min\": 11457.995176315308, \"max\": 11457.995176315308}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.31166842659936 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 95.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=380, train loss <loss>=-1.1059059848388035\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:42 INFO 140043348993664] Epoch[381] Batch[0] avg_epoch_loss=-1.140428\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:42 INFO 140043348993664] #quality_metric: host=algo-1, epoch=381, batch=0 train loss <loss>=-1.140427589416504\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:46 INFO 140043348993664] Epoch[381] Batch[5] avg_epoch_loss=-1.103848\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=381, batch=5 train loss <loss>=-1.10384797056516\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:46 INFO 140043348993664] Epoch[381] Batch [5]#011Speed: 77.35 samples/sec#011loss=-1.103848\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] Epoch[381] Batch[10] avg_epoch_loss=-1.111814\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=381, batch=10 train loss <loss>=-1.12137371301651\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] Epoch[381] Batch [10]#011Speed: 77.31 samples/sec#011loss=-1.121374\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744619.8826544, \"EndTime\": 1646744630.475448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10591.241121292114, \"count\": 1, \"min\": 10591.241121292114, \"max\": 10591.241121292114}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.46517990048216 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] #progress_metric: host=algo-1, completed 95.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=381, train loss <loss>=-1.1118142171339556\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:50 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:52 INFO 140043348993664] Epoch[382] Batch[0] avg_epoch_loss=-1.032801\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:52 INFO 140043348993664] #quality_metric: host=algo-1, epoch=382, batch=0 train loss <loss>=-1.0328010320663452\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:56 INFO 140043348993664] Epoch[382] Batch[5] avg_epoch_loss=-1.053508\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=382, batch=5 train loss <loss>=-1.0535080234209697\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:03:56 INFO 140043348993664] Epoch[382] Batch [5]#011Speed: 76.08 samples/sec#011loss=-1.053508\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] Epoch[382] Batch[10] avg_epoch_loss=-1.073787\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=382, batch=10 train loss <loss>=-1.0981228590011596\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] Epoch[382] Batch [10]#011Speed: 72.59 samples/sec#011loss=-1.098123\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744630.4755297, \"EndTime\": 1646744641.2821767, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10805.66930770874, \"count\": 1, \"min\": 10805.66930770874, \"max\": 10805.66930770874}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.1311175837273 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] #progress_metric: host=algo-1, completed 95.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=382, train loss <loss>=-1.0737874941392378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:01 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:03 INFO 140043348993664] Epoch[383] Batch[0] avg_epoch_loss=-1.115147\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:03 INFO 140043348993664] #quality_metric: host=algo-1, epoch=383, batch=0 train loss <loss>=-1.1151472330093384\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:07 INFO 140043348993664] Epoch[383] Batch[5] avg_epoch_loss=-1.125228\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=383, batch=5 train loss <loss>=-1.1252281069755554\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:07 INFO 140043348993664] Epoch[383] Batch [5]#011Speed: 74.34 samples/sec#011loss=-1.125228\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] Epoch[383] Batch[10] avg_epoch_loss=-1.125725\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=383, batch=10 train loss <loss>=-1.1263211011886596\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] Epoch[383] Batch [10]#011Speed: 71.23 samples/sec#011loss=-1.126321\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744641.2822764, \"EndTime\": 1646744652.3885438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11105.052947998047, \"count\": 1, \"min\": 11105.052947998047, \"max\": 11105.052947998047}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.77301008186743 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] #progress_metric: host=algo-1, completed 96.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=383, train loss <loss>=-1.1257249225269665\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:12 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:14 INFO 140043348993664] Epoch[384] Batch[0] avg_epoch_loss=-1.142610\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=384, batch=0 train loss <loss>=-1.1426098346710205\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:18 INFO 140043348993664] Epoch[384] Batch[5] avg_epoch_loss=-1.155679\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:18 INFO 140043348993664] #quality_metric: host=algo-1, epoch=384, batch=5 train loss <loss>=-1.1556787689526875\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:18 INFO 140043348993664] Epoch[384] Batch [5]#011Speed: 77.43 samples/sec#011loss=-1.155679\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] Epoch[384] Batch[10] avg_epoch_loss=-1.142057\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=384, batch=10 train loss <loss>=-1.1257102727890014\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] Epoch[384] Batch [10]#011Speed: 74.82 samples/sec#011loss=-1.125710\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744652.3886247, \"EndTime\": 1646744662.9822457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10593.01233291626, \"count\": 1, \"min\": 10593.01233291626, \"max\": 10593.01233291626}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=63.719776908831605 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] #progress_metric: host=algo-1, completed 96.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] #quality_metric: host=algo-1, epoch=384, train loss <loss>=-1.1420567252419211\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:22 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:25 INFO 140043348993664] Epoch[385] Batch[0] avg_epoch_loss=-1.114199\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:25 INFO 140043348993664] #quality_metric: host=algo-1, epoch=385, batch=0 train loss <loss>=-1.1141988039016724\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:29 INFO 140043348993664] Epoch[385] Batch[5] avg_epoch_loss=-1.040602\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:29 INFO 140043348993664] #quality_metric: host=algo-1, epoch=385, batch=5 train loss <loss>=-1.040602405865987\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:29 INFO 140043348993664] Epoch[385] Batch [5]#011Speed: 76.91 samples/sec#011loss=-1.040602\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] Epoch[385] Batch[10] avg_epoch_loss=-1.004150\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=385, batch=10 train loss <loss>=-0.9604062914848328\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] Epoch[385] Batch [10]#011Speed: 74.73 samples/sec#011loss=-0.960406\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744662.9823287, \"EndTime\": 1646744673.6421003, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10659.273147583008, \"count\": 1, \"min\": 10659.273147583008, \"max\": 10659.273147583008}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.728027697866885 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] #progress_metric: host=algo-1, completed 96.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] #quality_metric: host=algo-1, epoch=385, train loss <loss>=-1.0041496266018262\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:33 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:35 INFO 140043348993664] Epoch[386] Batch[0] avg_epoch_loss=-0.976150\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:35 INFO 140043348993664] #quality_metric: host=algo-1, epoch=386, batch=0 train loss <loss>=-0.9761499762535095\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:40 INFO 140043348993664] Epoch[386] Batch[5] avg_epoch_loss=-1.063693\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:40 INFO 140043348993664] #quality_metric: host=algo-1, epoch=386, batch=5 train loss <loss>=-1.0636927783489227\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:40 INFO 140043348993664] Epoch[386] Batch [5]#011Speed: 75.37 samples/sec#011loss=-1.063693\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] Epoch[386] Batch[10] avg_epoch_loss=-1.086232\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=386, batch=10 train loss <loss>=-1.1132793188095094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] Epoch[386] Batch [10]#011Speed: 74.23 samples/sec#011loss=-1.113279\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744673.6424468, \"EndTime\": 1646744684.384084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10740.305662155151, \"count\": 1, \"min\": 10740.305662155151, \"max\": 10740.305662155151}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=64.79999691009536 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] #progress_metric: host=algo-1, completed 96.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] #quality_metric: host=algo-1, epoch=386, train loss <loss>=-1.0862321149219165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:44 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:46 INFO 140043348993664] Epoch[387] Batch[0] avg_epoch_loss=-0.965653\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=387, batch=0 train loss <loss>=-0.9656531810760498\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:50 INFO 140043348993664] Epoch[387] Batch[5] avg_epoch_loss=-1.074738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:50 INFO 140043348993664] #quality_metric: host=algo-1, epoch=387, batch=5 train loss <loss>=-1.0747384627660115\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:50 INFO 140043348993664] Epoch[387] Batch [5]#011Speed: 76.71 samples/sec#011loss=-1.074738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] Epoch[387] Batch[10] avg_epoch_loss=-1.114538\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=387, batch=10 train loss <loss>=-1.162297773361206\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] Epoch[387] Batch [10]#011Speed: 75.68 samples/sec#011loss=-1.162298\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744684.3844776, \"EndTime\": 1646744695.072201, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10686.31362915039, \"count\": 1, \"min\": 10686.31362915039, \"max\": 10686.31362915039}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=62.322069419895854 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] #progress_metric: host=algo-1, completed 97.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] #quality_metric: host=algo-1, epoch=387, train loss <loss>=-1.114538149400191\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:55 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:57 INFO 140043348993664] Epoch[388] Batch[0] avg_epoch_loss=-1.130467\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:04:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=388, batch=0 train loss <loss>=-1.1304666996002197\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:01 INFO 140043348993664] Epoch[388] Batch[5] avg_epoch_loss=-1.152090\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=388, batch=5 train loss <loss>=-1.1520896553993225\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:01 INFO 140043348993664] Epoch[388] Batch [5]#011Speed: 74.68 samples/sec#011loss=-1.152090\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] Epoch[388] Batch[10] avg_epoch_loss=-1.177577\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=388, batch=10 train loss <loss>=-1.2081620216369628\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] Epoch[388] Batch [10]#011Speed: 67.55 samples/sec#011loss=-1.208162\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744695.0722752, \"EndTime\": 1646744706.374535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11301.828145980835, \"count\": 1, \"min\": 11301.828145980835, \"max\": 11301.828145980835}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=58.57082095551025 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] #progress_metric: host=algo-1, completed 97.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] #quality_metric: host=algo-1, epoch=388, train loss <loss>=-1.17757709459825\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:06 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_45185921-fe14-4b59-809f-653155d8483d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744706.3752224, \"EndTime\": 1646744706.504116, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 127.42114067077637, \"count\": 1, \"min\": 127.42114067077637, \"max\": 127.42114067077637}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:08 INFO 140043348993664] Epoch[389] Batch[0] avg_epoch_loss=-1.218979\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:08 INFO 140043348993664] #quality_metric: host=algo-1, epoch=389, batch=0 train loss <loss>=-1.2189793586730957\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:13 INFO 140043348993664] Epoch[389] Batch[5] avg_epoch_loss=-1.198048\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:13 INFO 140043348993664] #quality_metric: host=algo-1, epoch=389, batch=5 train loss <loss>=-1.1980479160944622\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:13 INFO 140043348993664] Epoch[389] Batch [5]#011Speed: 74.52 samples/sec#011loss=-1.198048\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] Epoch[389] Batch[10] avg_epoch_loss=-1.215944\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=389, batch=10 train loss <loss>=-1.2374203205108643\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] Epoch[389] Batch [10]#011Speed: 71.88 samples/sec#011loss=-1.237420\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744706.5041914, \"EndTime\": 1646744717.6220272, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11117.76614189148, \"count\": 1, \"min\": 11117.76614189148, \"max\": 11117.76614189148}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=59.72362476888607 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] #progress_metric: host=algo-1, completed 97.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] #quality_metric: host=algo-1, epoch=389, train loss <loss>=-1.2159444635564631\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:17 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/state_5725a04f-de5b-424b-b98d-105d7ebd6596-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744717.6221023, \"EndTime\": 1646744717.749401, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 126.81269645690918, \"count\": 1, \"min\": 126.81269645690918, \"max\": 126.81269645690918}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:19 INFO 140043348993664] Epoch[390] Batch[0] avg_epoch_loss=-1.015769\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=390, batch=0 train loss <loss>=-1.0157687664031982\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:24 INFO 140043348993664] Epoch[390] Batch[5] avg_epoch_loss=-1.051924\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=390, batch=5 train loss <loss>=-1.0519235928853352\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:24 INFO 140043348993664] Epoch[390] Batch [5]#011Speed: 73.95 samples/sec#011loss=-1.051924\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] Epoch[390] Batch[10] avg_epoch_loss=-1.099992\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=390, batch=10 train loss <loss>=-1.1576746225357055\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] Epoch[390] Batch [10]#011Speed: 77.01 samples/sec#011loss=-1.157675\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744717.749472, \"EndTime\": 1646744728.465149, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10715.603828430176, \"count\": 1, \"min\": 10715.603828430176, \"max\": 10715.603828430176}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.09779278317456 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] #progress_metric: host=algo-1, completed 97.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] #quality_metric: host=algo-1, epoch=390, train loss <loss>=-1.0999922427264126\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:28 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:30 INFO 140043348993664] Epoch[391] Batch[0] avg_epoch_loss=-0.452847\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:30 INFO 140043348993664] #quality_metric: host=algo-1, epoch=391, batch=0 train loss <loss>=-0.4528470039367676\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:34 INFO 140043348993664] Epoch[391] Batch[5] avg_epoch_loss=-0.835815\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=391, batch=5 train loss <loss>=-0.8358145654201508\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:34 INFO 140043348993664] Epoch[391] Batch [5]#011Speed: 76.08 samples/sec#011loss=-0.835815\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] Epoch[391] Batch[10] avg_epoch_loss=-0.943405\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=391, batch=10 train loss <loss>=-1.0725128412246705\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] Epoch[391] Batch [10]#011Speed: 75.78 samples/sec#011loss=-1.072513\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744728.465249, \"EndTime\": 1646744739.137822, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10671.416521072388, \"count\": 1, \"min\": 10671.416521072388, \"max\": 10671.416521072388}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.62690313704378 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] #progress_metric: host=algo-1, completed 98.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] #quality_metric: host=algo-1, epoch=391, train loss <loss>=-0.9434046907858415\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:39 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:41 INFO 140043348993664] Epoch[392] Batch[0] avg_epoch_loss=-1.000491\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=392, batch=0 train loss <loss>=-1.0004913806915283\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:45 INFO 140043348993664] Epoch[392] Batch[5] avg_epoch_loss=-1.025896\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:45 INFO 140043348993664] #quality_metric: host=algo-1, epoch=392, batch=5 train loss <loss>=-1.0258960525194805\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:45 INFO 140043348993664] Epoch[392] Batch [5]#011Speed: 77.06 samples/sec#011loss=-1.025896\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] Epoch[392] Batch[10] avg_epoch_loss=-1.064683\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=392, batch=10 train loss <loss>=-1.111228084564209\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] Epoch[392] Batch [10]#011Speed: 76.01 samples/sec#011loss=-1.111228\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744739.1381862, \"EndTime\": 1646744749.7625377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10623.024702072144, \"count\": 1, \"min\": 10623.024702072144, \"max\": 10623.024702072144}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.33958018240468 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] #progress_metric: host=algo-1, completed 98.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] #quality_metric: host=algo-1, epoch=392, train loss <loss>=-1.0646833398125388\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:49 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:51 INFO 140043348993664] Epoch[393] Batch[0] avg_epoch_loss=-1.096806\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:51 INFO 140043348993664] #quality_metric: host=algo-1, epoch=393, batch=0 train loss <loss>=-1.0968056917190552\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:56 INFO 140043348993664] Epoch[393] Batch[5] avg_epoch_loss=-1.041907\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:56 INFO 140043348993664] #quality_metric: host=algo-1, epoch=393, batch=5 train loss <loss>=-1.0419065356254578\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:05:56 INFO 140043348993664] Epoch[393] Batch [5]#011Speed: 75.63 samples/sec#011loss=-1.041907\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] Epoch[393] Batch[10] avg_epoch_loss=-1.076657\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=393, batch=10 train loss <loss>=-1.1183579683303833\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] Epoch[393] Batch [10]#011Speed: 73.74 samples/sec#011loss=-1.118358\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744749.7626655, \"EndTime\": 1646744760.5536194, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10790.225267410278, \"count\": 1, \"min\": 10790.225267410278, \"max\": 10790.225267410278}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=60.239061987072375 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] #progress_metric: host=algo-1, completed 98.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] #quality_metric: host=algo-1, epoch=393, train loss <loss>=-1.0766571868549695\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:00 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:02 INFO 140043348993664] Epoch[394] Batch[0] avg_epoch_loss=-0.946768\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:02 INFO 140043348993664] #quality_metric: host=algo-1, epoch=394, batch=0 train loss <loss>=-0.9467681646347046\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:07 INFO 140043348993664] Epoch[394] Batch[5] avg_epoch_loss=-1.008291\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:07 INFO 140043348993664] #quality_metric: host=algo-1, epoch=394, batch=5 train loss <loss>=-1.0082913041114807\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:07 INFO 140043348993664] Epoch[394] Batch [5]#011Speed: 67.15 samples/sec#011loss=-1.008291\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] Epoch[394] Batch[10] avg_epoch_loss=-1.038921\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=394, batch=10 train loss <loss>=-1.075677216053009\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] Epoch[394] Batch [10]#011Speed: 68.44 samples/sec#011loss=-1.075677\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744760.553698, \"EndTime\": 1646744772.4032326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11849.079370498657, \"count\": 1, \"min\": 11849.079370498657, \"max\": 11849.079370498657}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=55.78314224668864 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] #progress_metric: host=algo-1, completed 98.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] #quality_metric: host=algo-1, epoch=394, train loss <loss>=-1.0389212640849026\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:12 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:14 INFO 140043348993664] Epoch[395] Batch[0] avg_epoch_loss=-1.179091\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:14 INFO 140043348993664] #quality_metric: host=algo-1, epoch=395, batch=0 train loss <loss>=-1.1790908575057983\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:19 INFO 140043348993664] Epoch[395] Batch[5] avg_epoch_loss=-1.139160\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:19 INFO 140043348993664] #quality_metric: host=algo-1, epoch=395, batch=5 train loss <loss>=-1.13916011651357\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:19 INFO 140043348993664] Epoch[395] Batch [5]#011Speed: 72.58 samples/sec#011loss=-1.139160\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:23 INFO 140043348993664] Epoch[395] Batch[10] avg_epoch_loss=-1.158971\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:23 INFO 140043348993664] #quality_metric: host=algo-1, epoch=395, batch=10 train loss <loss>=-1.1827446937561035\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:23 INFO 140043348993664] Epoch[395] Batch [10]#011Speed: 69.25 samples/sec#011loss=-1.182745\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:24 INFO 140043348993664] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744772.4035532, \"EndTime\": 1646744784.6493866, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12244.497537612915, \"count\": 1, \"min\": 12244.497537612915, \"max\": 12244.497537612915}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:24 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.57492880297564 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:24 INFO 140043348993664] #progress_metric: host=algo-1, completed 99.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:24 INFO 140043348993664] #quality_metric: host=algo-1, epoch=395, train loss <loss>=-1.1384542187054951\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:24 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:27 INFO 140043348993664] Epoch[396] Batch[0] avg_epoch_loss=-1.111446\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:27 INFO 140043348993664] #quality_metric: host=algo-1, epoch=396, batch=0 train loss <loss>=-1.1114455461502075\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:31 INFO 140043348993664] Epoch[396] Batch[5] avg_epoch_loss=-1.114911\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:31 INFO 140043348993664] #quality_metric: host=algo-1, epoch=396, batch=5 train loss <loss>=-1.114911437034607\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:31 INFO 140043348993664] Epoch[396] Batch [5]#011Speed: 72.10 samples/sec#011loss=-1.114911\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:34 INFO 140043348993664] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744784.649744, \"EndTime\": 1646744794.928275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10277.154445648193, \"count\": 1, \"min\": 10277.154445648193, \"max\": 10277.154445648193}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:34 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=61.300117772082636 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:34 INFO 140043348993664] #progress_metric: host=algo-1, completed 99.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:34 INFO 140043348993664] #quality_metric: host=algo-1, epoch=396, train loss <loss>=-1.1242539763450623\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:34 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:37 INFO 140043348993664] Epoch[397] Batch[0] avg_epoch_loss=-1.203422\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:37 INFO 140043348993664] #quality_metric: host=algo-1, epoch=397, batch=0 train loss <loss>=-1.2034224271774292\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:41 INFO 140043348993664] Epoch[397] Batch[5] avg_epoch_loss=-1.150721\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:41 INFO 140043348993664] #quality_metric: host=algo-1, epoch=397, batch=5 train loss <loss>=-1.1507209539413452\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:41 INFO 140043348993664] Epoch[397] Batch [5]#011Speed: 70.98 samples/sec#011loss=-1.150721\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] Epoch[397] Batch[10] avg_epoch_loss=-1.175208\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=397, batch=10 train loss <loss>=-1.2045931100845337\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] Epoch[397] Batch [10]#011Speed: 67.64 samples/sec#011loss=-1.204593\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744794.9283657, \"EndTime\": 1646744806.5176263, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11587.900161743164, \"count\": 1, \"min\": 11587.900161743164, \"max\": 11587.900161743164}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=55.48711631091372 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] #progress_metric: host=algo-1, completed 99.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] #quality_metric: host=algo-1, epoch=397, train loss <loss>=-1.1752082976427944\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:46 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:48 INFO 140043348993664] Epoch[398] Batch[0] avg_epoch_loss=-0.944564\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:48 INFO 140043348993664] #quality_metric: host=algo-1, epoch=398, batch=0 train loss <loss>=-0.9445639848709106\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:53 INFO 140043348993664] Epoch[398] Batch[5] avg_epoch_loss=-0.865810\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:53 INFO 140043348993664] #quality_metric: host=algo-1, epoch=398, batch=5 train loss <loss>=-0.865809977054596\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:53 INFO 140043348993664] Epoch[398] Batch [5]#011Speed: 71.69 samples/sec#011loss=-0.865810\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:57 INFO 140043348993664] Epoch[398] Batch[10] avg_epoch_loss=-0.921870\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:57 INFO 140043348993664] #quality_metric: host=algo-1, epoch=398, batch=10 train loss <loss>=-0.9891422510147094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:57 INFO 140043348993664] Epoch[398] Batch [10]#011Speed: 67.62 samples/sec#011loss=-0.989142\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:58 INFO 140043348993664] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744806.5179608, \"EndTime\": 1646744818.9265301, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12407.204627990723, \"count\": 1, \"min\": 12407.204627990723, \"max\": 12407.204627990723}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:58 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=57.141964319341206 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:58 INFO 140043348993664] #progress_metric: host=algo-1, completed 99.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:58 INFO 140043348993664] #quality_metric: host=algo-1, epoch=398, train loss <loss>=-0.9240493277708689\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:06:58 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:01 INFO 140043348993664] Epoch[399] Batch[0] avg_epoch_loss=-0.977014\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:01 INFO 140043348993664] #quality_metric: host=algo-1, epoch=399, batch=0 train loss <loss>=-0.9770141243934631\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:05 INFO 140043348993664] Epoch[399] Batch[5] avg_epoch_loss=-1.069647\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:05 INFO 140043348993664] #quality_metric: host=algo-1, epoch=399, batch=5 train loss <loss>=-1.069647192955017\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:05 INFO 140043348993664] Epoch[399] Batch [5]#011Speed: 69.05 samples/sec#011loss=-1.069647\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:10 INFO 140043348993664] Epoch[399] Batch[10] avg_epoch_loss=-1.088255\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:10 INFO 140043348993664] #quality_metric: host=algo-1, epoch=399, batch=10 train loss <loss>=-1.1105846881866455\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:10 INFO 140043348993664] Epoch[399] Batch [10]#011Speed: 64.03 samples/sec#011loss=-1.110585\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] processed a total of 716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744818.9269743, \"EndTime\": 1646744831.727739, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12799.31616783142, \"count\": 1, \"min\": 12799.31616783142, \"max\": 12799.31616783142}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] #throughput_metric: host=algo-1, train throughput=55.93824102127951 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] #quality_metric: host=algo-1, epoch=399, train loss <loss>=-1.0613345007101695\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] Final loss: -1.2159444635564631 (occurred at epoch 389)\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] #quality_metric: host=algo-1, train final_loss <loss>=-1.2159444635564631\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.6/site-packages/algorithm/run_worker.py:356: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  \"You are using large values for `context_length` and/or `prediction_length`. \"\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 WARNING 140043348993664] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 WARNING 140043348993664] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:11 INFO 140043348993664] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744831.7282035, \"EndTime\": 1646744833.2721703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 1539.9491786956787, \"count\": 1, \"min\": 1539.9491786956787, \"max\": 1539.9491786956787}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:13 INFO 140043348993664] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744833.2727814, \"EndTime\": 1646744833.9341025, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2201.9412517547607, \"count\": 1, \"min\": 2201.9412517547607, \"max\": 2201.9412517547607}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:13 INFO 140043348993664] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:14 INFO 140043348993664] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744833.9345994, \"EndTime\": 1646744834.0325553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 97.89156913757324, \"count\": 1, \"min\": 97.89156913757324, \"max\": 97.89156913757324}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:14 INFO 140043348993664] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:14 INFO 140043348993664] #memory_usage::<batchbuffer> = 51.66389465332031 mb\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:14 INFO 140043348993664] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744834.0330293, \"EndTime\": 1646744834.0351875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.04649162292480469, \"count\": 1, \"min\": 0.04649162292480469, \"max\": 0.04649162292480469}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744834.035586, \"EndTime\": 1646744859.3475506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 25312.408447265625, \"count\": 1, \"min\": 25312.408447265625, \"max\": 25312.408447265625}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, RMSE): 0.5264040985722703\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, mean_absolute_QuantileLoss): 603.8585945448941\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, mean_wQuantileLoss): 0.40326866491753444\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.1]): 0.1527381373853297\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.2]): 0.2652807572593784\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.3]): 0.35352134038948124\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.4]): 0.42425762779133885\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.5]): 0.4783614867085024\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.6]): 0.5138824705483147\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.7]): 0.5255288586379065\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.8]): 0.5013950268001491\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #test_score (algo-1, wQuantileLoss[0.9]): 0.41445227873740903\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #quality_metric: host=algo-1, test RMSE <loss>=0.5264040985722703\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.40326866491753444\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646744859.3481922, \"EndTime\": 1646744859.470466, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 10.677576065063477, \"count\": 1, \"min\": 10.677576065063477, \"max\": 10.677576065063477}, \"totaltime\": {\"sum\": 4225768.968343735, \"count\": 1, \"min\": 4225768.968343735, \"max\": 4225768.968343735}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:07:39 INFO 140043348993664 integration.py:592] worker closed\u001b[0m\n",
      "Training seconds: 4344\n",
      "Billable seconds: 4344\n"
     ]
    }
   ],
   "source": [
    "# Visa loggen av tidigare tr채ning\n",
    "estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tr채na ny modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-08 13:24:56 Starting - Starting the training job...\n",
      "2022-03-08 13:25:20 Starting - Preparing the instances for trainingProfilerReport-1646745895: InProgress\n",
      ".........\n",
      "2022-03-08 13:26:40 Downloading - Downloading input data...\n",
      "2022-03-08 13:27:21 Training - Downloading the training image.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040 integration.py:592] worker started\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '24', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '5E-2', 'mini_batch_size': '64', 'prediction_length': '192', 'time_freq': 'H'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '5E-2', 'likelihood': 'student-t', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '24', 'epochs': '400', 'prediction_length': '192', 'time_freq': 'H'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] random_seed is None\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=47 from dataset.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Training set statistics:\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Real time series\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] number of time series: 56\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] number of observations: 12096\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] mean target length: 216.0\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] min/mean/max target: 0.042100001126527786/0.9895553481641901/6.3850998878479\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] mean abs(target): 0.9895553481641901\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] contains missing values: no\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Small number of time series. Doing 12 passes over dataset with prob 0.9523809523809524 per epoch.\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Test set statistics:\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Real time series\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] number of time series: 9\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] number of observations: 1944\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] mean target length: 216.0\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] min/mean/max target: 0.1145000010728836/0.8530394942672165/4.317800045013428\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] mean abs(target): 0.8530394942672165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] contains missing values: no\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] #memory_usage::<batchbuffer> = 51.66389465332031 mb\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] nvidia-smi took: 0.02521038055419922 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:07 INFO 139828400359040] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746087.5738878, \"EndTime\": 1646746088.4616098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 885.3335380554199, \"count\": 1, \"min\": 885.3335380554199, \"max\": 885.3335380554199}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:08 INFO 139828400359040] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:10 INFO 139828400359040] #memory_usage::<model> = 96 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746088.4621725, \"EndTime\": 1646746090.0795264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 2505.502223968506, \"count\": 1, \"min\": 2505.502223968506, \"max\": 2505.502223968506}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:12 INFO 139828400359040] Epoch[0] Batch[0] avg_epoch_loss=2.966012\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=2.9660117626190186\u001b[0m\n",
      "\n",
      "2022-03-08 13:28:21 Training - Training image download completed. Training in progress.\u001b[34m[03/08/2022 13:28:18 INFO 139828400359040] Epoch[0] Batch[5] avg_epoch_loss=1.796382\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=1.7963818311691284\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:18 INFO 139828400359040] Epoch[0] Batch [5]#011Speed: 51.77 samples/sec#011loss=1.796382\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] Epoch[0] Batch[10] avg_epoch_loss=1.632399\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=1.435620331764221\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] Epoch[0] Batch [10]#011Speed: 62.79 samples/sec#011loss=1.435620\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746090.0796213, \"EndTime\": 1646746103.8089626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 13729.206800460815, \"count\": 1, \"min\": 13729.206800460815, \"max\": 13729.206800460815}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=49.017227376865726 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] #progress_metric: host=algo-1, completed 0.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=0, train loss <loss>=1.6323993314396252\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:23 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_e61e14c3-9b72-4623-9a68-e28e33db62fa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746103.8095646, \"EndTime\": 1646746103.9277878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.20743370056152, \"count\": 1, \"min\": 115.20743370056152, \"max\": 115.20743370056152}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:26 INFO 139828400359040] Epoch[1] Batch[0] avg_epoch_loss=1.417624\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.4176238775253296\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:30 INFO 139828400359040] Epoch[1] Batch[5] avg_epoch_loss=1.311998\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.311997691790263\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:30 INFO 139828400359040] Epoch[1] Batch [5]#011Speed: 76.92 samples/sec#011loss=1.311998\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:33 INFO 139828400359040] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746103.928196, \"EndTime\": 1646746113.849153, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9920.829772949219, \"count\": 1, \"min\": 9920.829772949219, \"max\": 9920.829772949219}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:33 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=63.40074340983949 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:33 INFO 139828400359040] #progress_metric: host=algo-1, completed 0.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.252783739566803\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:33 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:33 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_8d9c9943-6686-463d-adad-3e7868e84b53-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746113.8492982, \"EndTime\": 1646746113.9797192, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 128.83329391479492, \"count\": 1, \"min\": 128.83329391479492, \"max\": 128.83329391479492}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:36 INFO 139828400359040] Epoch[2] Batch[0] avg_epoch_loss=1.141113\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.1411126852035522\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:40 INFO 139828400359040] Epoch[2] Batch[5] avg_epoch_loss=1.111902\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=1.1119016408920288\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:40 INFO 139828400359040] Epoch[2] Batch [5]#011Speed: 81.40 samples/sec#011loss=1.111902\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] Epoch[2] Batch[10] avg_epoch_loss=1.060168\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=0.9980885505676269\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] Epoch[2] Batch [10]#011Speed: 79.71 samples/sec#011loss=0.998089\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746113.9801733, \"EndTime\": 1646746124.3401363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10359.85541343689, \"count\": 1, \"min\": 10359.85541343689, \"max\": 10359.85541343689}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=63.995107250960736 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] #progress_metric: host=algo-1, completed 0.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=2, train loss <loss>=1.0601684180173008\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:44 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_923c2920-b242-4857-85dd-05182253eedd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746124.3404012, \"EndTime\": 1646746124.455124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 113.59643936157227, \"count\": 1, \"min\": 113.59643936157227, \"max\": 113.59643936157227}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:46 INFO 139828400359040] Epoch[3] Batch[0] avg_epoch_loss=0.892747\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=0.8927468061447144\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:50 INFO 139828400359040] Epoch[3] Batch[5] avg_epoch_loss=0.975555\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=0.9755551218986511\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:50 INFO 139828400359040] Epoch[3] Batch [5]#011Speed: 79.14 samples/sec#011loss=0.975555\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] Epoch[3] Batch[10] avg_epoch_loss=0.908373\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=0.8277548670768737\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] Epoch[3] Batch [10]#011Speed: 80.57 samples/sec#011loss=0.827755\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746124.4554293, \"EndTime\": 1646746134.6520298, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10196.520328521729, \"count\": 1, \"min\": 10196.520328521729, \"max\": 10196.520328521729}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.8439834376101 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=3, train loss <loss>=0.9083731878887523\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:54 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_01d0f0a1-a336-4c18-a33e-bd457650a954-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746134.6524138, \"EndTime\": 1646746134.7704923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 116.66202545166016, \"count\": 1, \"min\": 116.66202545166016, \"max\": 116.66202545166016}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:56 INFO 139828400359040] Epoch[4] Batch[0] avg_epoch_loss=0.810866\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:28:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=0.8108658194541931\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:00 INFO 139828400359040] Epoch[4] Batch[5] avg_epoch_loss=0.754345\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=0.7543449004491171\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:00 INFO 139828400359040] Epoch[4] Batch [5]#011Speed: 84.49 samples/sec#011loss=0.754345\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] Epoch[4] Batch[10] avg_epoch_loss=0.704150\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=0.6439160943031311\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] Epoch[4] Batch [10]#011Speed: 79.15 samples/sec#011loss=0.643916\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746134.7708743, \"EndTime\": 1646746144.7475898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9976.614713668823, \"count\": 1, \"min\": 9976.614713668823, \"max\": 9976.614713668823}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.15411344393873 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] #progress_metric: host=algo-1, completed 1.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=4, train loss <loss>=0.704149988564578\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:04 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_a7fc95f8-fa6f-40fd-a651-8ee00b07ba12-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746144.7479632, \"EndTime\": 1646746144.875052, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 125.66304206848145, \"count\": 1, \"min\": 125.66304206848145, \"max\": 125.66304206848145}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:07 INFO 139828400359040] Epoch[5] Batch[0] avg_epoch_loss=0.692907\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=0.6929069757461548\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:10 INFO 139828400359040] Epoch[5] Batch[5] avg_epoch_loss=0.631692\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=0.6316919525464376\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:10 INFO 139828400359040] Epoch[5] Batch [5]#011Speed: 85.20 samples/sec#011loss=0.631692\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] Epoch[5] Batch[10] avg_epoch_loss=0.675378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=0.7278012037277222\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] Epoch[5] Batch [10]#011Speed: 84.04 samples/sec#011loss=0.727801\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746144.8751266, \"EndTime\": 1646746154.7377348, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9862.536430358887, \"count\": 1, \"min\": 9862.536430358887, \"max\": 9862.536430358887}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.91864309298155 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] #progress_metric: host=algo-1, completed 1.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=5, train loss <loss>=0.6753779758106578\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:14 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_60cc2586-c0e7-440c-8ea9-cd042395681d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746154.7378817, \"EndTime\": 1646746154.8557315, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 116.76287651062012, \"count\": 1, \"min\": 116.76287651062012, \"max\": 116.76287651062012}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:16 INFO 139828400359040] Epoch[6] Batch[0] avg_epoch_loss=0.786228\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=0.7862275838851929\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:20 INFO 139828400359040] Epoch[6] Batch[5] avg_epoch_loss=0.678099\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=0.6780991355578104\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:20 INFO 139828400359040] Epoch[6] Batch [5]#011Speed: 81.85 samples/sec#011loss=0.678099\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] Epoch[6] Batch[10] avg_epoch_loss=0.677596\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=0.6769930243492126\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] Epoch[6] Batch [10]#011Speed: 79.70 samples/sec#011loss=0.676993\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746154.8559923, \"EndTime\": 1646746164.921275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10065.131902694702, \"count\": 1, \"min\": 10065.131902694702, \"max\": 10065.131902694702}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.9627159846904 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] #progress_metric: host=algo-1, completed 1.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=6, train loss <loss>=0.6775963577357206\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:24 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:27 INFO 139828400359040] Epoch[7] Batch[0] avg_epoch_loss=0.544343\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=0.5443433523178101\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:30 INFO 139828400359040] Epoch[7] Batch[5] avg_epoch_loss=0.598499\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=0.5984987219174703\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:30 INFO 139828400359040] Epoch[7] Batch [5]#011Speed: 83.17 samples/sec#011loss=0.598499\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:33 INFO 139828400359040] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746164.921406, \"EndTime\": 1646746173.9983368, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9076.14541053772, \"count\": 1, \"min\": 9076.14541053772, \"max\": 9076.14541053772}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:33 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.77202910980246 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:33 INFO 139828400359040] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=7, train loss <loss>=0.5977857202291489\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:33 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:34 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_d1b5f300-f474-4ef4-8d13-f986f51cfc68-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746173.9989476, \"EndTime\": 1646746174.1214652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 121.39129638671875, \"count\": 1, \"min\": 121.39129638671875, \"max\": 121.39129638671875}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:36 INFO 139828400359040] Epoch[8] Batch[0] avg_epoch_loss=0.626507\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=0.6265067458152771\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:40 INFO 139828400359040] Epoch[8] Batch[5] avg_epoch_loss=0.580332\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=0.5803315291802088\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:40 INFO 139828400359040] Epoch[8] Batch [5]#011Speed: 86.79 samples/sec#011loss=0.580332\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:43 INFO 139828400359040] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746174.1218407, \"EndTime\": 1646746183.2615411, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9139.416217803955, \"count\": 1, \"min\": 9139.416217803955, \"max\": 9139.416217803955}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:43 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.16395893078338 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:43 INFO 139828400359040] #progress_metric: host=algo-1, completed 2.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=8, train loss <loss>=0.5347032994031906\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:43 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:43 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_e8d849af-a669-4693-b30e-7197d15066dc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746183.2618048, \"EndTime\": 1646746183.3820457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 118.69502067565918, \"count\": 1, \"min\": 118.69502067565918, \"max\": 118.69502067565918}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:45 INFO 139828400359040] Epoch[9] Batch[0] avg_epoch_loss=0.625125\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=0.6251248121261597\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:49 INFO 139828400359040] Epoch[9] Batch[5] avg_epoch_loss=0.559938\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=0.5599381178617477\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:49 INFO 139828400359040] Epoch[9] Batch [5]#011Speed: 84.30 samples/sec#011loss=0.559938\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] Epoch[9] Batch[10] avg_epoch_loss=0.480726\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=0.3856704831123352\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] Epoch[9] Batch [10]#011Speed: 83.38 samples/sec#011loss=0.385670\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746183.3824704, \"EndTime\": 1646746193.1447942, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9762.19367980957, \"count\": 1, \"min\": 9762.19367980957, \"max\": 9762.19367980957}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.2438984046878 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] #progress_metric: host=algo-1, completed 2.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=9, train loss <loss>=0.48072555661201477\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:53 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_1a411138-f495-4a11-b1ff-edf8f1bf28ea-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746193.1451454, \"EndTime\": 1646746193.2657847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 119.21191215515137, \"count\": 1, \"min\": 119.21191215515137, \"max\": 119.21191215515137}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:55 INFO 139828400359040] Epoch[10] Batch[0] avg_epoch_loss=0.548590\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=0.5485896468162537\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:59 INFO 139828400359040] Epoch[10] Batch[5] avg_epoch_loss=0.582337\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=0.5823370814323425\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:29:59 INFO 139828400359040] Epoch[10] Batch [5]#011Speed: 83.12 samples/sec#011loss=0.582337\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:02 INFO 139828400359040] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746193.2662065, \"EndTime\": 1646746202.6369157, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9370.604515075684, \"count\": 1, \"min\": 9370.604515075684, \"max\": 9370.604515075684}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:02 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.80377096457421 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:02 INFO 139828400359040] #progress_metric: host=algo-1, completed 2.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=10, train loss <loss>=0.4877848565578461\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:02 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:04 INFO 139828400359040] Epoch[11] Batch[0] avg_epoch_loss=0.338137\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=0.3381367325782776\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:08 INFO 139828400359040] Epoch[11] Batch[5] avg_epoch_loss=0.322393\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=0.3223928436636925\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:08 INFO 139828400359040] Epoch[11] Batch [5]#011Speed: 78.70 samples/sec#011loss=0.322393\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] Epoch[11] Batch[10] avg_epoch_loss=0.370195\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=0.4275572121143341\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] Epoch[11] Batch [10]#011Speed: 81.09 samples/sec#011loss=0.427557\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746202.6369994, \"EndTime\": 1646746212.9005427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10262.984275817871, \"count\": 1, \"min\": 10262.984275817871, \"max\": 10262.984275817871}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.7933292989061 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=11, train loss <loss>=0.370194829323075\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:12 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:13 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_dbbb3630-84d3-4e7d-8dec-a5c90a530a7e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746212.900909, \"EndTime\": 1646746213.0273576, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 124.99475479125977, \"count\": 1, \"min\": 124.99475479125977, \"max\": 124.99475479125977}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:15 INFO 139828400359040] Epoch[12] Batch[0] avg_epoch_loss=0.767623\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=0.7676225304603577\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:19 INFO 139828400359040] Epoch[12] Batch[5] avg_epoch_loss=1.029021\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=1.0290205279986064\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:19 INFO 139828400359040] Epoch[12] Batch [5]#011Speed: 81.96 samples/sec#011loss=1.029021\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] Epoch[12] Batch[10] avg_epoch_loss=0.898934\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=0.742830616235733\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] Epoch[12] Batch [10]#011Speed: 80.91 samples/sec#011loss=0.742831\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746213.0277438, \"EndTime\": 1646746223.1333594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10105.515480041504, \"count\": 1, \"min\": 10105.515480041504, \"max\": 10105.515480041504}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.6154859808476 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] #progress_metric: host=algo-1, completed 3.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=12, train loss <loss>=0.8989342044700276\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:23 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:25 INFO 139828400359040] Epoch[13] Batch[0] avg_epoch_loss=0.944477\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=0.9444774985313416\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:29 INFO 139828400359040] Epoch[13] Batch[5] avg_epoch_loss=0.723923\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=0.7239229083061218\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:29 INFO 139828400359040] Epoch[13] Batch [5]#011Speed: 80.96 samples/sec#011loss=0.723923\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] Epoch[13] Batch[10] avg_epoch_loss=0.597990\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=0.4468712151050568\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] Epoch[13] Batch [10]#011Speed: 84.07 samples/sec#011loss=0.446871\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746223.133719, \"EndTime\": 1646746232.9852567, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9850.151062011719, \"count\": 1, \"min\": 9850.151062011719, \"max\": 9850.151062011719}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.10270963590172 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] #progress_metric: host=algo-1, completed 3.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=13, train loss <loss>=0.5979903204874559\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:32 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:35 INFO 139828400359040] Epoch[14] Batch[0] avg_epoch_loss=1.764974\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.7649744749069214\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:38 INFO 139828400359040] Epoch[14] Batch[5] avg_epoch_loss=1.459410\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=1.4594099919001262\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:38 INFO 139828400359040] Epoch[14] Batch [5]#011Speed: 83.91 samples/sec#011loss=1.459410\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] Epoch[14] Batch[10] avg_epoch_loss=1.491218\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=1.5293877601623536\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] Epoch[14] Batch [10]#011Speed: 81.18 samples/sec#011loss=1.529388\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746232.9856117, \"EndTime\": 1646746242.8344896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9847.454071044922, \"count\": 1, \"min\": 9847.454071044922, \"max\": 9847.454071044922}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.7459660152981 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] #progress_metric: host=algo-1, completed 3.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=14, train loss <loss>=1.4912180683829568\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:42 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:44 INFO 139828400359040] Epoch[15] Batch[0] avg_epoch_loss=1.578511\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=1.5785112380981445\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:48 INFO 139828400359040] Epoch[15] Batch[5] avg_epoch_loss=1.312749\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=1.3127491474151611\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:48 INFO 139828400359040] Epoch[15] Batch [5]#011Speed: 81.58 samples/sec#011loss=1.312749\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] Epoch[15] Batch[10] avg_epoch_loss=1.138792\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=0.9300424814224243\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] Epoch[15] Batch [10]#011Speed: 77.96 samples/sec#011loss=0.930042\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746242.8348393, \"EndTime\": 1646746253.0139737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10177.707195281982, \"count\": 1, \"min\": 10177.707195281982, \"max\": 10177.707195281982}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.67637042026801 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.1387915719639172\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:53 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:55 INFO 139828400359040] Epoch[16] Batch[0] avg_epoch_loss=0.829466\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=0.8294662833213806\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:58 INFO 139828400359040] Epoch[16] Batch[5] avg_epoch_loss=0.776019\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=0.7760193447271982\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:30:58 INFO 139828400359040] Epoch[16] Batch [5]#011Speed: 84.69 samples/sec#011loss=0.776019\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] Epoch[16] Batch[10] avg_epoch_loss=0.691329\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=0.5897011697292328\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] Epoch[16] Batch [10]#011Speed: 77.12 samples/sec#011loss=0.589701\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746253.0143769, \"EndTime\": 1646746263.1164927, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10100.719928741455, \"count\": 1, \"min\": 10100.719928741455, \"max\": 10100.719928741455}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.24206574538577 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] #progress_metric: host=algo-1, completed 4.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=16, train loss <loss>=0.6913292651826685\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:03 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:05 INFO 139828400359040] Epoch[17] Batch[0] avg_epoch_loss=0.850660\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:05 INFO 139828400359040] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=0.8506601452827454\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:09 INFO 139828400359040] Epoch[17] Batch[5] avg_epoch_loss=0.745903\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:09 INFO 139828400359040] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=0.74590336283048\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:09 INFO 139828400359040] Epoch[17] Batch [5]#011Speed: 77.59 samples/sec#011loss=0.745903\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] Epoch[17] Batch[10] avg_epoch_loss=0.653916\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=0.54353047311306\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] Epoch[17] Batch [10]#011Speed: 79.83 samples/sec#011loss=0.543530\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746263.116577, \"EndTime\": 1646746273.5073018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10389.280319213867, \"count\": 1, \"min\": 10389.280319213867, \"max\": 10389.280319213867}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=62.08201562639732 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] #progress_metric: host=algo-1, completed 4.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=17, train loss <loss>=0.6539156856861982\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:13 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:15 INFO 139828400359040] Epoch[18] Batch[0] avg_epoch_loss=0.528046\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=0.5280458331108093\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:19 INFO 139828400359040] Epoch[18] Batch[5] avg_epoch_loss=0.466198\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=0.46619828542073566\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:19 INFO 139828400359040] Epoch[18] Batch [5]#011Speed: 86.58 samples/sec#011loss=0.466198\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] Epoch[18] Batch[10] avg_epoch_loss=0.401464\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=0.3237830579280853\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] Epoch[18] Batch [10]#011Speed: 80.28 samples/sec#011loss=0.323783\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746273.507391, \"EndTime\": 1646746283.3049302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9796.835899353027, \"count\": 1, \"min\": 9796.835899353027, \"max\": 9796.835899353027}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.0595946931556 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] #progress_metric: host=algo-1, completed 4.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=18, train loss <loss>=0.4014640911058946\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:23 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:25 INFO 139828400359040] Epoch[19] Batch[0] avg_epoch_loss=0.384038\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=0.38403838872909546\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:29 INFO 139828400359040] Epoch[19] Batch[5] avg_epoch_loss=0.671762\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=0.6717619995276133\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:29 INFO 139828400359040] Epoch[19] Batch [5]#011Speed: 83.28 samples/sec#011loss=0.671762\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] Epoch[19] Batch[10] avg_epoch_loss=0.699351\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=0.7324586629867553\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] Epoch[19] Batch [10]#011Speed: 82.52 samples/sec#011loss=0.732459\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746283.3052864, \"EndTime\": 1646746293.1340249, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9827.271699905396, \"count\": 1, \"min\": 9827.271699905396, \"max\": 9827.271699905396}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.2097021550123 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=19, train loss <loss>=0.6993513920090415\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:33 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:35 INFO 139828400359040] Epoch[20] Batch[0] avg_epoch_loss=0.584256\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=0.5842562913894653\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:39 INFO 139828400359040] Epoch[20] Batch[5] avg_epoch_loss=0.553203\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=0.553203210234642\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:39 INFO 139828400359040] Epoch[20] Batch [5]#011Speed: 83.22 samples/sec#011loss=0.553203\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] Epoch[20] Batch[10] avg_epoch_loss=0.546707\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=0.5389114081859588\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] Epoch[20] Batch [10]#011Speed: 83.17 samples/sec#011loss=0.538911\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746293.134413, \"EndTime\": 1646746303.03801, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9902.199268341064, \"count\": 1, \"min\": 9902.199268341064, \"max\": 9902.199268341064}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.95404766029391 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] #progress_metric: host=algo-1, completed 5.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=20, train loss <loss>=0.5467069365761497\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:43 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:45 INFO 139828400359040] Epoch[21] Batch[0] avg_epoch_loss=0.433540\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=0.43354037404060364\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:48 INFO 139828400359040] Epoch[21] Batch[5] avg_epoch_loss=0.499298\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=0.49929777284463245\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:48 INFO 139828400359040] Epoch[21] Batch [5]#011Speed: 83.99 samples/sec#011loss=0.499298\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] Epoch[21] Batch[10] avg_epoch_loss=0.474117\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=0.44390068054199217\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] Epoch[21] Batch [10]#011Speed: 81.59 samples/sec#011loss=0.443901\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746303.0380862, \"EndTime\": 1646746312.8772037, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9838.644981384277, \"count\": 1, \"min\": 9838.644981384277, \"max\": 9838.644981384277}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.68947463575797 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] #progress_metric: host=algo-1, completed 5.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=21, train loss <loss>=0.4741172763434323\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:52 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:55 INFO 139828400359040] Epoch[22] Batch[0] avg_epoch_loss=0.411008\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=0.4110078811645508\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:58 INFO 139828400359040] Epoch[22] Batch[5] avg_epoch_loss=0.460957\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=0.46095724403858185\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:31:58 INFO 139828400359040] Epoch[22] Batch [5]#011Speed: 84.26 samples/sec#011loss=0.460957\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:02 INFO 139828400359040] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746312.8775644, \"EndTime\": 1646746322.1983685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9319.501399993896, \"count\": 1, \"min\": 9319.501399993896, \"max\": 9319.501399993896}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:02 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.24185039415401 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:02 INFO 139828400359040] #progress_metric: host=algo-1, completed 5.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=22, train loss <loss>=0.47136920094490053\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:02 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:04 INFO 139828400359040] Epoch[23] Batch[0] avg_epoch_loss=0.236871\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=0.23687104880809784\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:08 INFO 139828400359040] Epoch[23] Batch[5] avg_epoch_loss=0.409041\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=0.4090414419770241\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:08 INFO 139828400359040] Epoch[23] Batch [5]#011Speed: 77.72 samples/sec#011loss=0.409041\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:11 INFO 139828400359040] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746322.1984644, \"EndTime\": 1646746331.5904977, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9391.000986099243, \"count\": 1, \"min\": 9391.000986099243, \"max\": 9391.000986099243}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:11 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.97822132880147 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:11 INFO 139828400359040] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=23, train loss <loss>=0.3484445378184319\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:11 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:11 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_345f402f-a030-4e7d-8ffe-ed05d5addeb2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746331.590572, \"EndTime\": 1646746331.703258, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 112.11943626403809, \"count\": 1, \"min\": 112.11943626403809, \"max\": 112.11943626403809}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:13 INFO 139828400359040] Epoch[24] Batch[0] avg_epoch_loss=0.169862\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=0.16986218094825745\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:17 INFO 139828400359040] Epoch[24] Batch[5] avg_epoch_loss=0.347728\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=0.34772757689158124\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:17 INFO 139828400359040] Epoch[24] Batch [5]#011Speed: 85.41 samples/sec#011loss=0.347728\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] Epoch[24] Batch[10] avg_epoch_loss=0.292218\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=0.22560717910528183\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] Epoch[24] Batch [10]#011Speed: 78.75 samples/sec#011loss=0.225607\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746331.7033288, \"EndTime\": 1646746341.5721016, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9868.685245513916, \"count\": 1, \"min\": 9868.685245513916, \"max\": 9868.685245513916}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.52309792944804 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 6.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=24, train loss <loss>=0.29221830517053604\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:21 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_f48f7fb4-549c-4fbb-b292-d0109b5ff62c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746341.5724664, \"EndTime\": 1646746341.690803, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 116.90807342529297, \"count\": 1, \"min\": 116.90807342529297, \"max\": 116.90807342529297}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:23 INFO 139828400359040] Epoch[25] Batch[0] avg_epoch_loss=0.211109\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=0.21110914647579193\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:27 INFO 139828400359040] Epoch[25] Batch[5] avg_epoch_loss=0.321355\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=0.3213549529512723\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:27 INFO 139828400359040] Epoch[25] Batch [5]#011Speed: 87.00 samples/sec#011loss=0.321355\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] Epoch[25] Batch[10] avg_epoch_loss=0.279355\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=0.22895412892103195\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] Epoch[25] Batch [10]#011Speed: 83.66 samples/sec#011loss=0.228954\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746341.6911974, \"EndTime\": 1646746351.449146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9757.848739624023, \"count\": 1, \"min\": 9757.848739624023, \"max\": 9757.848739624023}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.91755644145984 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 6.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=25, train loss <loss>=0.2793545783920722\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:31 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_210a5b93-b58e-4b6c-af14-3c7fcfe4b1f4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746351.4495096, \"EndTime\": 1646746351.5662436, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.3562068939209, \"count\": 1, \"min\": 115.3562068939209, \"max\": 115.3562068939209}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:33 INFO 139828400359040] Epoch[26] Batch[0] avg_epoch_loss=0.429855\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=0.4298549294471741\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:37 INFO 139828400359040] Epoch[26] Batch[5] avg_epoch_loss=0.321697\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=0.32169738163550693\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:37 INFO 139828400359040] Epoch[26] Batch [5]#011Speed: 84.17 samples/sec#011loss=0.321697\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:40 INFO 139828400359040] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746351.5666592, \"EndTime\": 1646746360.6886826, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9121.925592422485, \"count\": 1, \"min\": 9121.925592422485, \"max\": 9121.925592422485}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:40 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.85519839420748 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:40 INFO 139828400359040] #progress_metric: host=algo-1, completed 6.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=26, train loss <loss>=0.2931820437312126\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:40 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:42 INFO 139828400359040] Epoch[27] Batch[0] avg_epoch_loss=0.412172\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=0.41217178106307983\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:46 INFO 139828400359040] Epoch[27] Batch[5] avg_epoch_loss=0.195906\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=0.19590642924110094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:46 INFO 139828400359040] Epoch[27] Batch [5]#011Speed: 81.17 samples/sec#011loss=0.195906\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] Epoch[27] Batch[10] avg_epoch_loss=0.157000\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=0.11031162068247795\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] Epoch[27] Batch [10]#011Speed: 81.85 samples/sec#011loss=0.110312\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746360.6890638, \"EndTime\": 1646746370.68059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9990.058660507202, \"count\": 1, \"min\": 9990.058660507202, \"max\": 9990.058660507202}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.46246264499463 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=27, train loss <loss>=0.1569996980780905\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:50 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_4e1ae17e-3336-4e71-a05a-0c2323ccde7f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746370.6809232, \"EndTime\": 1646746370.8010378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 118.77131462097168, \"count\": 1, \"min\": 118.77131462097168, \"max\": 118.77131462097168}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:52 INFO 139828400359040] Epoch[28] Batch[0] avg_epoch_loss=0.370637\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=0.3706374764442444\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:56 INFO 139828400359040] Epoch[28] Batch[5] avg_epoch_loss=0.293867\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=0.29386687527100247\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:32:56 INFO 139828400359040] Epoch[28] Batch [5]#011Speed: 83.87 samples/sec#011loss=0.293867\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] Epoch[28] Batch[10] avg_epoch_loss=0.251078\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=0.1997318834066391\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] Epoch[28] Batch [10]#011Speed: 83.29 samples/sec#011loss=0.199732\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746370.801419, \"EndTime\": 1646746380.6172976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9815.781354904175, \"count\": 1, \"min\": 9815.781354904175, \"max\": 9815.781354904175}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.23773551139398 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] #progress_metric: host=algo-1, completed 7.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=28, train loss <loss>=0.25107824260538275\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:00 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:02 INFO 139828400359040] Epoch[29] Batch[0] avg_epoch_loss=0.915572\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=0.9155720472335815\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:06 INFO 139828400359040] Epoch[29] Batch[5] avg_epoch_loss=0.581644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=0.5816444158554077\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:06 INFO 139828400359040] Epoch[29] Batch [5]#011Speed: 82.19 samples/sec#011loss=0.581644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] Epoch[29] Batch[10] avg_epoch_loss=0.578361\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=0.5744208633899689\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] Epoch[29] Batch [10]#011Speed: 80.92 samples/sec#011loss=0.574421\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746380.6173947, \"EndTime\": 1646746390.7729905, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10154.863357543945, \"count\": 1, \"min\": 10154.863357543945, \"max\": 10154.863357543945}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.79576318170265 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 7.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=29, train loss <loss>=0.5783609829165719\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:12 INFO 139828400359040] Epoch[30] Batch[0] avg_epoch_loss=0.655810\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=0.6558099389076233\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:16 INFO 139828400359040] Epoch[30] Batch[5] avg_epoch_loss=0.514986\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=0.514986460407575\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:16 INFO 139828400359040] Epoch[30] Batch [5]#011Speed: 83.82 samples/sec#011loss=0.514986\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] Epoch[30] Batch[10] avg_epoch_loss=0.431418\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=0.33113672733306887\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] Epoch[30] Batch [10]#011Speed: 82.07 samples/sec#011loss=0.331137\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746390.7730732, \"EndTime\": 1646746400.5690897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9795.511245727539, \"count\": 1, \"min\": 9795.511245727539, \"max\": 9795.511245727539}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.74480649896076 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] #progress_metric: host=algo-1, completed 7.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=30, train loss <loss>=0.4314183999191631\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:20 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:22 INFO 139828400359040] Epoch[31] Batch[0] avg_epoch_loss=0.453835\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=0.45383498072624207\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:26 INFO 139828400359040] Epoch[31] Batch[5] avg_epoch_loss=0.385913\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=0.38591261208057404\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:26 INFO 139828400359040] Epoch[31] Batch [5]#011Speed: 86.16 samples/sec#011loss=0.385913\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] Epoch[31] Batch[10] avg_epoch_loss=0.352871\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=0.3132207155227661\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] Epoch[31] Batch [10]#011Speed: 85.74 samples/sec#011loss=0.313221\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746400.5691757, \"EndTime\": 1646746410.1362777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9565.89651107788, \"count\": 1, \"min\": 9565.89651107788, \"max\": 9565.89651107788}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.51698591494605 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=31, train loss <loss>=0.3528708409179341\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:30 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:32 INFO 139828400359040] Epoch[32] Batch[0] avg_epoch_loss=0.148344\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=0.14834363758563995\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:35 INFO 139828400359040] Epoch[32] Batch[5] avg_epoch_loss=0.227162\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=0.2271618371208509\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:35 INFO 139828400359040] Epoch[32] Batch [5]#011Speed: 85.83 samples/sec#011loss=0.227162\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] Epoch[32] Batch[10] avg_epoch_loss=0.203876\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=0.1759328067302704\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] Epoch[32] Batch [10]#011Speed: 82.95 samples/sec#011loss=0.175933\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746410.1363525, \"EndTime\": 1646746419.7583802, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9620.4993724823, \"count\": 1, \"min\": 9620.4993724823, \"max\": 9620.4993724823}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=72.03228681068518 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] #progress_metric: host=algo-1, completed 8.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=32, train loss <loss>=0.20387591421604156\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:39 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:41 INFO 139828400359040] Epoch[33] Batch[0] avg_epoch_loss=0.160111\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=0.16011087596416473\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:45 INFO 139828400359040] Epoch[33] Batch[5] avg_epoch_loss=0.102378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=0.1023780523488919\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:45 INFO 139828400359040] Epoch[33] Batch [5]#011Speed: 84.22 samples/sec#011loss=0.102378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:49 INFO 139828400359040] Epoch[33] Batch[10] avg_epoch_loss=0.172977\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=0.257694935798645\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:49 INFO 139828400359040] Epoch[33] Batch [10]#011Speed: 82.81 samples/sec#011loss=0.257695\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:50 INFO 139828400359040] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746419.7585092, \"EndTime\": 1646746430.2099507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10450.572490692139, \"count\": 1, \"min\": 10450.572490692139, \"max\": 10450.572490692139}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:50 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.84254176152798 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:50 INFO 139828400359040] #progress_metric: host=algo-1, completed 8.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=33, train loss <loss>=0.141501158165435\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:50 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:50 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_3a873967-bee5-43d4-a5bc-cb9447518735-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746430.210015, \"EndTime\": 1646746430.3305585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 120.14651298522949, \"count\": 1, \"min\": 120.14651298522949, \"max\": 120.14651298522949}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:52 INFO 139828400359040] Epoch[34] Batch[0] avg_epoch_loss=0.208634\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=0.2086339294910431\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:56 INFO 139828400359040] Epoch[34] Batch[5] avg_epoch_loss=0.258840\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=0.2588403920332591\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:33:56 INFO 139828400359040] Epoch[34] Batch [5]#011Speed: 81.55 samples/sec#011loss=0.258840\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] Epoch[34] Batch[10] avg_epoch_loss=0.307674\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=0.36627368330955506\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] Epoch[34] Batch [10]#011Speed: 82.73 samples/sec#011loss=0.366274\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746430.3310232, \"EndTime\": 1646746440.2857022, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9954.595804214478, \"count\": 1, \"min\": 9954.595804214478, \"max\": 9954.595804214478}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.49098177760804 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] #progress_metric: host=algo-1, completed 8.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=34, train loss <loss>=0.30767370624975726\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:00 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:02 INFO 139828400359040] Epoch[35] Batch[0] avg_epoch_loss=0.417906\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=0.41790571808815\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:06 INFO 139828400359040] Epoch[35] Batch[5] avg_epoch_loss=0.352444\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=0.3524438515305519\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:06 INFO 139828400359040] Epoch[35] Batch [5]#011Speed: 78.95 samples/sec#011loss=0.352444\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] Epoch[35] Batch[10] avg_epoch_loss=0.391405\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=0.4381576359272003\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] Epoch[35] Batch [10]#011Speed: 79.70 samples/sec#011loss=0.438158\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746440.285801, \"EndTime\": 1646746450.7742472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10487.61248588562, \"count\": 1, \"min\": 10487.61248588562, \"max\": 10487.61248588562}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.55222500394807 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=35, train loss <loss>=0.39140466261993756\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:12 INFO 139828400359040] Epoch[36] Batch[0] avg_epoch_loss=0.340449\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=0.3404487371444702\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:16 INFO 139828400359040] Epoch[36] Batch[5] avg_epoch_loss=0.485846\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=0.4858461618423462\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:16 INFO 139828400359040] Epoch[36] Batch [5]#011Speed: 80.95 samples/sec#011loss=0.485846\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] Epoch[36] Batch[10] avg_epoch_loss=0.421470\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=0.3442196846008301\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] Epoch[36] Batch [10]#011Speed: 81.63 samples/sec#011loss=0.344220\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746450.7745764, \"EndTime\": 1646746460.807427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10031.538963317871, \"count\": 1, \"min\": 10031.538963317871, \"max\": 10031.538963317871}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.88503174706428 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] #progress_metric: host=algo-1, completed 9.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=36, train loss <loss>=0.42147049036892975\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:20 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:22 INFO 139828400359040] Epoch[37] Batch[0] avg_epoch_loss=0.860085\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=0.860084593296051\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:26 INFO 139828400359040] Epoch[37] Batch[5] avg_epoch_loss=0.597484\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=0.5974843030174574\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:26 INFO 139828400359040] Epoch[37] Batch [5]#011Speed: 82.61 samples/sec#011loss=0.597484\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] Epoch[37] Batch[10] avg_epoch_loss=0.534532\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=0.4589894384145737\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] Epoch[37] Batch [10]#011Speed: 81.30 samples/sec#011loss=0.458989\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746460.8075044, \"EndTime\": 1646746470.7844312, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9976.406574249268, \"count\": 1, \"min\": 9976.406574249268, \"max\": 9976.406574249268}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.85672246022622 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] #progress_metric: host=algo-1, completed 9.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=37, train loss <loss>=0.5345320918343284\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:30 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:32 INFO 139828400359040] Epoch[38] Batch[0] avg_epoch_loss=0.544939\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=0.5449385643005371\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:36 INFO 139828400359040] Epoch[38] Batch[5] avg_epoch_loss=0.371423\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=0.3714231600364049\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:36 INFO 139828400359040] Epoch[38] Batch [5]#011Speed: 83.77 samples/sec#011loss=0.371423\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] Epoch[38] Batch[10] avg_epoch_loss=0.376757\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=0.3831568121910095\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] Epoch[38] Batch [10]#011Speed: 79.93 samples/sec#011loss=0.383157\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746470.7848537, \"EndTime\": 1646746480.782983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9996.604681015015, \"count\": 1, \"min\": 9996.604681015015, \"max\": 9996.604681015015}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.32081754216007 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] #progress_metric: host=algo-1, completed 9.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=38, train loss <loss>=0.3767566382884979\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:40 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:43 INFO 139828400359040] Epoch[39] Batch[0] avg_epoch_loss=0.187469\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=0.18746915459632874\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:46 INFO 139828400359040] Epoch[39] Batch[5] avg_epoch_loss=0.170057\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=0.1700568919380506\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:46 INFO 139828400359040] Epoch[39] Batch [5]#011Speed: 82.05 samples/sec#011loss=0.170057\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] Epoch[39] Batch[10] avg_epoch_loss=0.137010\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=0.09735376760363579\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] Epoch[39] Batch [10]#011Speed: 76.43 samples/sec#011loss=0.097354\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746480.7832475, \"EndTime\": 1646746491.1570323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10372.292757034302, \"count\": 1, \"min\": 10372.292757034302, \"max\": 10372.292757034302}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.13515096634846 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=39, train loss <loss>=0.1370100172405893\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:51 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_b6f3b04d-a012-4e7c-a021-08d0408c6020-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746491.1573944, \"EndTime\": 1646746491.2810621, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 122.19882011413574, \"count\": 1, \"min\": 122.19882011413574, \"max\": 122.19882011413574}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:53 INFO 139828400359040] Epoch[40] Batch[0] avg_epoch_loss=0.138274\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=0.13827355206012726\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:57 INFO 139828400359040] Epoch[40] Batch[5] avg_epoch_loss=0.520751\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=0.5207507386803627\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:34:57 INFO 139828400359040] Epoch[40] Batch [5]#011Speed: 80.59 samples/sec#011loss=0.520751\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] Epoch[40] Batch[10] avg_epoch_loss=0.493803\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=0.46146527826786043\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] Epoch[40] Batch [10]#011Speed: 79.39 samples/sec#011loss=0.461465\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746491.2814584, \"EndTime\": 1646746501.4857924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10204.22649383545, \"count\": 1, \"min\": 10204.22649383545, \"max\": 10204.22649383545}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.42223313184334 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] #progress_metric: host=algo-1, completed 10.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=40, train loss <loss>=0.4938028021292253\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:01 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:03 INFO 139828400359040] Epoch[41] Batch[0] avg_epoch_loss=0.232435\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=0.23243506252765656\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:08 INFO 139828400359040] Epoch[41] Batch[5] avg_epoch_loss=0.212752\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=0.21275178343057632\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:08 INFO 139828400359040] Epoch[41] Batch [5]#011Speed: 76.95 samples/sec#011loss=0.212752\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] Epoch[41] Batch[10] avg_epoch_loss=0.163166\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=0.10366329252719879\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] Epoch[41] Batch [10]#011Speed: 81.03 samples/sec#011loss=0.103663\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746501.4858778, \"EndTime\": 1646746511.9875643, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10501.190662384033, \"count\": 1, \"min\": 10501.190662384033, \"max\": 10501.190662384033}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=62.372296209007686 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] #progress_metric: host=algo-1, completed 10.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=41, train loss <loss>=0.1631661057472229\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:11 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:14 INFO 139828400359040] Epoch[42] Batch[0] avg_epoch_loss=0.222344\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=0.22234413027763367\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:18 INFO 139828400359040] Epoch[42] Batch[5] avg_epoch_loss=0.106010\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=0.10600965314855178\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:18 INFO 139828400359040] Epoch[42] Batch [5]#011Speed: 82.10 samples/sec#011loss=0.106010\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] Epoch[42] Batch[10] avg_epoch_loss=0.284014\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=0.4976189658045769\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] Epoch[42] Batch [10]#011Speed: 82.87 samples/sec#011loss=0.497619\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746511.9876537, \"EndTime\": 1646746521.9514966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9962.589979171753, \"count\": 1, \"min\": 9962.589979171753, \"max\": 9962.589979171753}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.8544128977694 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 10.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=42, train loss <loss>=0.28401388617401774\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:24 INFO 139828400359040] Epoch[43] Batch[0] avg_epoch_loss=0.305251\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=0.3052508234977722\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:27 INFO 139828400359040] Epoch[43] Batch[5] avg_epoch_loss=0.677895\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=0.6778948307037354\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:27 INFO 139828400359040] Epoch[43] Batch [5]#011Speed: 83.39 samples/sec#011loss=0.677895\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] Epoch[43] Batch[10] avg_epoch_loss=0.651989\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=0.6209017038345337\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] Epoch[43] Batch [10]#011Speed: 83.61 samples/sec#011loss=0.620902\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746521.9518967, \"EndTime\": 1646746531.754824, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9801.498174667358, \"count\": 1, \"min\": 9801.498174667358, \"max\": 9801.498174667358}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.41761961415786 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=43, train loss <loss>=0.6519888639450073\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:31 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:33 INFO 139828400359040] Epoch[44] Batch[0] avg_epoch_loss=0.585895\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=0.5858952403068542\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:37 INFO 139828400359040] Epoch[44] Batch[5] avg_epoch_loss=0.294704\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=0.2947043279806773\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:37 INFO 139828400359040] Epoch[44] Batch [5]#011Speed: 83.95 samples/sec#011loss=0.294704\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] Epoch[44] Batch[10] avg_epoch_loss=0.224577\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=0.14042515642940998\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] Epoch[44] Batch [10]#011Speed: 83.94 samples/sec#011loss=0.140425\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746531.7549038, \"EndTime\": 1646746541.4842324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9727.391719818115, \"count\": 1, \"min\": 9727.391719818115, \"max\": 9727.391719818115}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.26019806948162 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 11.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=44, train loss <loss>=0.22457743182101034\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:41 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:43 INFO 139828400359040] Epoch[45] Batch[0] avg_epoch_loss=0.191062\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=0.1910618096590042\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:47 INFO 139828400359040] Epoch[45] Batch[5] avg_epoch_loss=0.151711\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=0.15171058875663826\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:47 INFO 139828400359040] Epoch[45] Batch [5]#011Speed: 83.96 samples/sec#011loss=0.151711\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:50 INFO 139828400359040] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746541.484296, \"EndTime\": 1646746550.556054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9071.42972946167, \"count\": 1, \"min\": 9071.42972946167, \"max\": 9071.42972946167}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:50 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.34341593810379 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:50 INFO 139828400359040] #progress_metric: host=algo-1, completed 11.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=45, train loss <loss>=0.16043299676384776\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:50 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:52 INFO 139828400359040] Epoch[46] Batch[0] avg_epoch_loss=0.010764\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=0.010763522237539291\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:56 INFO 139828400359040] Epoch[46] Batch[5] avg_epoch_loss=0.015579\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=0.015578514585892359\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:35:56 INFO 139828400359040] Epoch[46] Batch [5]#011Speed: 82.31 samples/sec#011loss=0.015579\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] Epoch[46] Batch[10] avg_epoch_loss=0.000212\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=-0.018228297308087348\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] Epoch[46] Batch [10]#011Speed: 85.61 samples/sec#011loss=-0.018228\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746550.556414, \"EndTime\": 1646746560.3404076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9782.625436782837, \"count\": 1, \"min\": 9782.625436782837, \"max\": 9782.625436782837}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.69191664931643 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] #progress_metric: host=algo-1, completed 11.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=46, train loss <loss>=0.0002117819068106738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:00 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_0b0631bc-7a6b-46d2-bca4-610d7450014c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746560.340536, \"EndTime\": 1646746560.4557264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 114.39108848571777, \"count\": 1, \"min\": 114.39108848571777, \"max\": 114.39108848571777}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:02 INFO 139828400359040] Epoch[47] Batch[0] avg_epoch_loss=-0.016568\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=-0.016568168997764587\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:07 INFO 139828400359040] Epoch[47] Batch[5] avg_epoch_loss=0.127182\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=0.12718175642658025\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:07 INFO 139828400359040] Epoch[47] Batch [5]#011Speed: 75.50 samples/sec#011loss=0.127182\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] Epoch[47] Batch[10] avg_epoch_loss=0.102706\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=0.07333550862967968\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] Epoch[47] Batch [10]#011Speed: 80.31 samples/sec#011loss=0.073336\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746560.455837, \"EndTime\": 1646746570.9955986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10539.670705795288, \"count\": 1, \"min\": 10539.670705795288, \"max\": 10539.670705795288}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.27514845742712 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=47, train loss <loss>=0.1027061892461709\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:13 INFO 139828400359040] Epoch[48] Batch[0] avg_epoch_loss=0.073134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=0.07313366234302521\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:17 INFO 139828400359040] Epoch[48] Batch[5] avg_epoch_loss=0.124094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=0.12409394979476929\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:17 INFO 139828400359040] Epoch[48] Batch [5]#011Speed: 83.51 samples/sec#011loss=0.124094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:20 INFO 139828400359040] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746570.9958754, \"EndTime\": 1646746580.1091392, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9112.252950668335, \"count\": 1, \"min\": 9112.252950668335, \"max\": 9112.252950668335}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:20 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.01238423902804 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:20 INFO 139828400359040] #progress_metric: host=algo-1, completed 12.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=48, train loss <loss>=0.0855136338621378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:20 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:22 INFO 139828400359040] Epoch[49] Batch[0] avg_epoch_loss=-0.030689\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=-0.03068905882537365\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:26 INFO 139828400359040] Epoch[49] Batch[5] avg_epoch_loss=-0.068746\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=-0.06874632307638724\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:26 INFO 139828400359040] Epoch[49] Batch [5]#011Speed: 85.08 samples/sec#011loss=-0.068746\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] Epoch[49] Batch[10] avg_epoch_loss=-0.074398\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=-0.08118091374635697\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] Epoch[49] Batch [10]#011Speed: 83.23 samples/sec#011loss=-0.081181\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746580.1094444, \"EndTime\": 1646746589.916983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9806.129217147827, \"count\": 1, \"min\": 9806.129217147827, \"max\": 9806.129217147827}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.11780701022887 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=49, train loss <loss>=-0.0743984097445553\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:29 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:30 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_c7f54667-2d16-4a51-a898-72a634865630-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746589.917352, \"EndTime\": 1646746590.034218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.39530754089355, \"count\": 1, \"min\": 115.39530754089355, \"max\": 115.39530754089355}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:32 INFO 139828400359040] Epoch[50] Batch[0] avg_epoch_loss=0.148155\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=0.1481553316116333\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:36 INFO 139828400359040] Epoch[50] Batch[5] avg_epoch_loss=0.159450\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=0.1594495934744676\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:36 INFO 139828400359040] Epoch[50] Batch [5]#011Speed: 82.92 samples/sec#011loss=0.159450\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] Epoch[50] Batch[10] avg_epoch_loss=0.094367\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=0.0162680727429688\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] Epoch[50] Batch [10]#011Speed: 79.64 samples/sec#011loss=0.016268\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746590.0346086, \"EndTime\": 1646746600.1269011, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10092.18955039978, \"count\": 1, \"min\": 10092.18955039978, \"max\": 10092.18955039978}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.38513680550892 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] #progress_metric: host=algo-1, completed 12.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=50, train loss <loss>=0.09436708405105905\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:40 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:42 INFO 139828400359040] Epoch[51] Batch[0] avg_epoch_loss=0.113476\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=0.11347587406635284\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:45 INFO 139828400359040] Epoch[51] Batch[5] avg_epoch_loss=0.071888\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=0.0718881452921778\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:45 INFO 139828400359040] Epoch[51] Batch [5]#011Speed: 84.80 samples/sec#011loss=0.071888\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] Epoch[51] Batch[10] avg_epoch_loss=0.047131\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=0.017423300445079802\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] Epoch[51] Batch [10]#011Speed: 81.62 samples/sec#011loss=0.017423\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746600.127262, \"EndTime\": 1646746609.8503969, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9721.652507781982, \"count\": 1, \"min\": 9721.652507781982, \"max\": 9721.652507781982}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.28350589011414 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=51, train loss <loss>=0.047131397634405985\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:49 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:51 INFO 139828400359040] Epoch[52] Batch[0] avg_epoch_loss=-0.105479\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=-0.10547908395528793\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:55 INFO 139828400359040] Epoch[52] Batch[5] avg_epoch_loss=0.064295\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=0.06429450338085492\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:55 INFO 139828400359040] Epoch[52] Batch [5]#011Speed: 85.02 samples/sec#011loss=0.064295\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] Epoch[52] Batch[10] avg_epoch_loss=0.037310\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=0.004928210005164147\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] Epoch[52] Batch [10]#011Speed: 84.30 samples/sec#011loss=0.004928\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746609.8504584, \"EndTime\": 1646746619.506219, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9655.438423156738, \"count\": 1, \"min\": 9655.438423156738, \"max\": 9655.438423156738}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.83641169028617 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] #progress_metric: host=algo-1, completed 13.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=52, train loss <loss>=0.037309824573722755\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:36:59 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:01 INFO 139828400359040] Epoch[53] Batch[0] avg_epoch_loss=-0.026584\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=-0.026584088802337646\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:05 INFO 139828400359040] Epoch[53] Batch[5] avg_epoch_loss=0.051490\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:05 INFO 139828400359040] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=0.051490399365623794\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:05 INFO 139828400359040] Epoch[53] Batch [5]#011Speed: 81.16 samples/sec#011loss=0.051490\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:09 INFO 139828400359040] Epoch[53] Batch[10] avg_epoch_loss=0.037268\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:09 INFO 139828400359040] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=0.020201117079705\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:09 INFO 139828400359040] Epoch[53] Batch [10]#011Speed: 78.18 samples/sec#011loss=0.020201\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:10 INFO 139828400359040] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746619.5063286, \"EndTime\": 1646746630.468378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10961.591482162476, \"count\": 1, \"min\": 10961.591482162476, \"max\": 10961.591482162476}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.86217685820128 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 13.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=53, train loss <loss>=0.043922090708899\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:12 INFO 139828400359040] Epoch[54] Batch[0] avg_epoch_loss=-0.067204\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=-0.06720353662967682\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:16 INFO 139828400359040] Epoch[54] Batch[5] avg_epoch_loss=0.175966\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=0.17596648447215557\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:16 INFO 139828400359040] Epoch[54] Batch [5]#011Speed: 86.67 samples/sec#011loss=0.175966\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] Epoch[54] Batch[10] avg_epoch_loss=0.214133\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=0.2599338889122009\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] Epoch[54] Batch [10]#011Speed: 83.48 samples/sec#011loss=0.259934\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746630.4684536, \"EndTime\": 1646746640.1296191, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9660.35771369934, \"count\": 1, \"min\": 9660.35771369934, \"max\": 9660.35771369934}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.73294057501585 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] #progress_metric: host=algo-1, completed 13.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=54, train loss <loss>=0.21413348649035802\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:20 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:22 INFO 139828400359040] Epoch[55] Batch[0] avg_epoch_loss=0.099140\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=0.09914019703865051\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:26 INFO 139828400359040] Epoch[55] Batch[5] avg_epoch_loss=0.087903\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=0.08790323262413342\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:26 INFO 139828400359040] Epoch[55] Batch [5]#011Speed: 84.17 samples/sec#011loss=0.087903\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] Epoch[55] Batch[10] avg_epoch_loss=0.064891\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=0.037276748567819595\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] Epoch[55] Batch [10]#011Speed: 82.09 samples/sec#011loss=0.037277\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746640.1297114, \"EndTime\": 1646746649.9273927, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9796.694278717041, \"count\": 1, \"min\": 9796.694278717041, \"max\": 9796.694278717041}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.43072142245018 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=55, train loss <loss>=0.06489119441671805\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:29 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:32 INFO 139828400359040] Epoch[56] Batch[0] avg_epoch_loss=-0.074895\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=-0.0748947411775589\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:35 INFO 139828400359040] Epoch[56] Batch[5] avg_epoch_loss=-0.005331\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=-0.005330914243434866\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:35 INFO 139828400359040] Epoch[56] Batch [5]#011Speed: 83.63 samples/sec#011loss=-0.005331\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] Epoch[56] Batch[10] avg_epoch_loss=-0.013007\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=-0.022217753529548644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] Epoch[56] Batch [10]#011Speed: 83.66 samples/sec#011loss=-0.022218\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746649.9275079, \"EndTime\": 1646746659.822437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9894.258260726929, \"count\": 1, \"min\": 9894.258260726929, \"max\": 9894.258260726929}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.29830256981323 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] #progress_metric: host=algo-1, completed 14.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=56, train loss <loss>=-0.013006750282577494\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:39 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:41 INFO 139828400359040] Epoch[57] Batch[0] avg_epoch_loss=0.120336\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=0.12033569067716599\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:45 INFO 139828400359040] Epoch[57] Batch[5] avg_epoch_loss=0.253406\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=0.25340616299460333\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:45 INFO 139828400359040] Epoch[57] Batch [5]#011Speed: 83.54 samples/sec#011loss=0.253406\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:49 INFO 139828400359040] Epoch[57] Batch[10] avg_epoch_loss=0.248258\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=0.24208106696605683\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:49 INFO 139828400359040] Epoch[57] Batch [10]#011Speed: 81.82 samples/sec#011loss=0.242081\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:50 INFO 139828400359040] processed a total of 720 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746659.8228135, \"EndTime\": 1646746670.3785365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10554.279327392578, \"count\": 1, \"min\": 10554.279327392578, \"max\": 10554.279327392578}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:50 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.21797611089127 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:50 INFO 139828400359040] #progress_metric: host=algo-1, completed 14.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=57, train loss <loss>=0.26226330719267327\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:50 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:52 INFO 139828400359040] Epoch[58] Batch[0] avg_epoch_loss=-0.029975\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=-0.029975038021802902\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:56 INFO 139828400359040] Epoch[58] Batch[5] avg_epoch_loss=0.036165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=0.036164713402589165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:37:56 INFO 139828400359040] Epoch[58] Batch [5]#011Speed: 83.84 samples/sec#011loss=0.036165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] Epoch[58] Batch[10] avg_epoch_loss=-0.015548\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=-0.07760334238409997\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] Epoch[58] Batch [10]#011Speed: 81.24 samples/sec#011loss=-0.077603\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746670.378618, \"EndTime\": 1646746680.285051, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9905.874729156494, \"count\": 1, \"min\": 9905.874729156494, \"max\": 9905.874729156494}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.04722056618066 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] #progress_metric: host=algo-1, completed 14.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=58, train loss <loss>=-0.015548039227724075\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:00 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:02 INFO 139828400359040] Epoch[59] Batch[0] avg_epoch_loss=0.002781\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=0.0027807592414319515\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:06 INFO 139828400359040] Epoch[59] Batch[5] avg_epoch_loss=-0.016351\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=-0.016350828111171722\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:06 INFO 139828400359040] Epoch[59] Batch [5]#011Speed: 83.58 samples/sec#011loss=-0.016351\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] Epoch[59] Batch[10] avg_epoch_loss=-0.052329\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=-0.09550213925540448\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] Epoch[59] Batch [10]#011Speed: 76.26 samples/sec#011loss=-0.095502\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746680.2853837, \"EndTime\": 1646746690.5117872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10225.101470947266, \"count\": 1, \"min\": 10225.101470947266, \"max\": 10225.101470947266}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.16469741318387 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=59, train loss <loss>=-0.0523286968130957\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:12 INFO 139828400359040] Epoch[60] Batch[0] avg_epoch_loss=-0.144959\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=-0.1449589878320694\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:16 INFO 139828400359040] Epoch[60] Batch[5] avg_epoch_loss=-0.050927\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=-0.05092700322469076\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:16 INFO 139828400359040] Epoch[60] Batch [5]#011Speed: 83.01 samples/sec#011loss=-0.050927\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] Epoch[60] Batch[10] avg_epoch_loss=-0.072467\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=-0.0983151912689209\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] Epoch[60] Batch [10]#011Speed: 79.66 samples/sec#011loss=-0.098315\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746690.5118816, \"EndTime\": 1646746700.495614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9982.942342758179, \"count\": 1, \"min\": 9982.942342758179, \"max\": 9982.942342758179}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.61408514222464 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] #progress_metric: host=algo-1, completed 15.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=60, train loss <loss>=-0.07246708869934082\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:20 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:22 INFO 139828400359040] Epoch[61] Batch[0] avg_epoch_loss=0.022055\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=0.022054782137274742\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:26 INFO 139828400359040] Epoch[61] Batch[5] avg_epoch_loss=-0.097142\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=-0.09714248931656282\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:26 INFO 139828400359040] Epoch[61] Batch [5]#011Speed: 84.49 samples/sec#011loss=-0.097142\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] Epoch[61] Batch[10] avg_epoch_loss=-0.119451\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=-0.1462213471531868\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] Epoch[61] Batch [10]#011Speed: 79.05 samples/sec#011loss=-0.146221\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746700.496002, \"EndTime\": 1646746710.4635072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9966.099977493286, \"count\": 1, \"min\": 9966.099977493286, \"max\": 9966.099977493286}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.02783618594131 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] #progress_metric: host=algo-1, completed 15.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=61, train loss <loss>=-0.11945106106048281\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:30 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_2765922c-6714-4fc3-ad02-fe21c0851e49-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746710.4638426, \"EndTime\": 1646746710.5852804, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 120.03493309020996, \"count\": 1, \"min\": 120.03493309020996, \"max\": 120.03493309020996}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:32 INFO 139828400359040] Epoch[62] Batch[0] avg_epoch_loss=0.360108\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=0.3601077198982239\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:36 INFO 139828400359040] Epoch[62] Batch[5] avg_epoch_loss=0.042820\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=0.04282009073843559\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:36 INFO 139828400359040] Epoch[62] Batch [5]#011Speed: 82.96 samples/sec#011loss=0.042820\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:40 INFO 139828400359040] Epoch[62] Batch[10] avg_epoch_loss=-0.006482\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=-0.06564399637281895\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:40 INFO 139828400359040] Epoch[62] Batch [10]#011Speed: 77.69 samples/sec#011loss=-0.065644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:41 INFO 139828400359040] processed a total of 721 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746710.5857203, \"EndTime\": 1646746721.3910482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10805.241107940674, \"count\": 1, \"min\": 10805.241107940674, \"max\": 10805.241107940674}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.72489140163518 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 15.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=62, train loss <loss>=-0.015106432450314363\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:41 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:43 INFO 139828400359040] Epoch[63] Batch[0] avg_epoch_loss=0.393569\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=0.3935685157775879\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:47 INFO 139828400359040] Epoch[63] Batch[5] avg_epoch_loss=0.235752\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=0.23575198153654733\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:47 INFO 139828400359040] Epoch[63] Batch [5]#011Speed: 86.04 samples/sec#011loss=0.235752\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] Epoch[63] Batch[10] avg_epoch_loss=0.194657\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=0.1453419640660286\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] Epoch[63] Batch [10]#011Speed: 79.67 samples/sec#011loss=0.145342\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746721.3912196, \"EndTime\": 1646746731.3439837, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9951.319456100464, \"count\": 1, \"min\": 9951.319456100464, \"max\": 9951.319456100464}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.9245750237029 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=63, train loss <loss>=0.1946565190499479\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:51 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:53 INFO 139828400359040] Epoch[64] Batch[0] avg_epoch_loss=0.384433\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=0.38443320989608765\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:57 INFO 139828400359040] Epoch[64] Batch[5] avg_epoch_loss=0.303802\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=0.3038024182120959\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:38:57 INFO 139828400359040] Epoch[64] Batch [5]#011Speed: 83.84 samples/sec#011loss=0.303802\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] Epoch[64] Batch[10] avg_epoch_loss=0.263442\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=0.2150087296962738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] Epoch[64] Batch [10]#011Speed: 79.78 samples/sec#011loss=0.215009\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746731.3441234, \"EndTime\": 1646746741.269754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9924.540758132935, \"count\": 1, \"min\": 9924.540758132935, \"max\": 9924.540758132935}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.01752812314055 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] #progress_metric: host=algo-1, completed 16.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=64, train loss <loss>=0.26344165070490405\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:01 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:03 INFO 139828400359040] Epoch[65] Batch[0] avg_epoch_loss=0.261109\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=0.2611088156700134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:07 INFO 139828400359040] Epoch[65] Batch[5] avg_epoch_loss=0.071633\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=0.07163263562445839\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:07 INFO 139828400359040] Epoch[65] Batch [5]#011Speed: 76.66 samples/sec#011loss=0.071633\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:10 INFO 139828400359040] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746741.2701075, \"EndTime\": 1646746750.8674355, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9595.916986465454, \"count\": 1, \"min\": 9595.916986465454, \"max\": 9595.916986465454}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=61.37897781517384 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 16.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=65, train loss <loss>=0.02304004514589906\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:12 INFO 139828400359040] Epoch[66] Batch[0] avg_epoch_loss=0.047668\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=0.04766785353422165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:16 INFO 139828400359040] Epoch[66] Batch[5] avg_epoch_loss=0.082151\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=0.08215077896602452\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:16 INFO 139828400359040] Epoch[66] Batch [5]#011Speed: 83.42 samples/sec#011loss=0.082151\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:20 INFO 139828400359040] Epoch[66] Batch[10] avg_epoch_loss=0.102654\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=0.1272571137174964\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:20 INFO 139828400359040] Epoch[66] Batch [10]#011Speed: 79.00 samples/sec#011loss=0.127257\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:21 INFO 139828400359040] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746750.8675961, \"EndTime\": 1646746761.5792117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10710.7253074646, \"count\": 1, \"min\": 10710.7253074646, \"max\": 10710.7253074646}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.81878299067134 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 16.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=66, train loss <loss>=0.1112799314238752\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:23 INFO 139828400359040] Epoch[67] Batch[0] avg_epoch_loss=0.501659\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=0.5016589760780334\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:27 INFO 139828400359040] Epoch[67] Batch[5] avg_epoch_loss=0.319600\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=0.3196004306276639\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:27 INFO 139828400359040] Epoch[67] Batch [5]#011Speed: 83.96 samples/sec#011loss=0.319600\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] Epoch[67] Batch[10] avg_epoch_loss=0.297451\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=0.27087172120809555\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] Epoch[67] Batch [10]#011Speed: 81.34 samples/sec#011loss=0.270872\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746761.5796661, \"EndTime\": 1646746771.403338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9822.160243988037, \"count\": 1, \"min\": 9822.160243988037, \"max\": 9822.160243988037}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.85882543898889 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=67, train loss <loss>=0.29745101725513284\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:31 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:33 INFO 139828400359040] Epoch[68] Batch[0] avg_epoch_loss=0.207763\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=0.20776312053203583\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:37 INFO 139828400359040] Epoch[68] Batch[5] avg_epoch_loss=0.168453\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=0.16845279186964035\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:37 INFO 139828400359040] Epoch[68] Batch [5]#011Speed: 86.77 samples/sec#011loss=0.168453\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] Epoch[68] Batch[10] avg_epoch_loss=0.139348\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=0.10442245760932564\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] Epoch[68] Batch [10]#011Speed: 79.50 samples/sec#011loss=0.104422\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] processed a total of 710 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746771.4034846, \"EndTime\": 1646746781.9953246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10591.058015823364, \"count\": 1, \"min\": 10591.058015823364, \"max\": 10591.058015823364}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.03490580465613 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 17.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=68, train loss <loss>=0.11483970350430657\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:41 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:44 INFO 139828400359040] Epoch[69] Batch[0] avg_epoch_loss=0.425605\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=0.42560499906539917\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:47 INFO 139828400359040] Epoch[69] Batch[5] avg_epoch_loss=0.251989\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=0.2519888908912738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:47 INFO 139828400359040] Epoch[69] Batch [5]#011Speed: 84.33 samples/sec#011loss=0.251989\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] Epoch[69] Batch[10] avg_epoch_loss=0.206669\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=0.15228575915098191\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] Epoch[69] Batch [10]#011Speed: 83.15 samples/sec#011loss=0.152286\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746781.9957163, \"EndTime\": 1646746791.8250413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9827.92043685913, \"count\": 1, \"min\": 9827.92043685913, \"max\": 9827.92043685913}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.57908563674027 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 17.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=69, train loss <loss>=0.20666928555477748\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:51 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:54 INFO 139828400359040] Epoch[70] Batch[0] avg_epoch_loss=0.112273\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=0.11227274686098099\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:57 INFO 139828400359040] Epoch[70] Batch[5] avg_epoch_loss=0.047068\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=0.04706802343328794\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:39:57 INFO 139828400359040] Epoch[70] Batch [5]#011Speed: 83.67 samples/sec#011loss=0.047068\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] Epoch[70] Batch[10] avg_epoch_loss=-0.021831\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=-0.10450910106301307\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] Epoch[70] Batch [10]#011Speed: 78.44 samples/sec#011loss=-0.104509\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746791.825114, \"EndTime\": 1646746801.9464517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10120.65076828003, \"count\": 1, \"min\": 10120.65076828003, \"max\": 10120.65076828003}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=63.532740980244114 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] #progress_metric: host=algo-1, completed 17.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=70, train loss <loss>=-0.02183066951957616\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:01 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:04 INFO 139828400359040] Epoch[71] Batch[0] avg_epoch_loss=-0.040656\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=-0.04065599665045738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:08 INFO 139828400359040] Epoch[71] Batch[5] avg_epoch_loss=0.021965\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=0.021964558710654575\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:08 INFO 139828400359040] Epoch[71] Batch [5]#011Speed: 78.55 samples/sec#011loss=0.021965\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] Epoch[71] Batch[10] avg_epoch_loss=-0.019331\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=-0.0688853308558464\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] Epoch[71] Batch [10]#011Speed: 80.95 samples/sec#011loss=-0.068885\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746801.946528, \"EndTime\": 1646746812.1863978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10239.3479347229, \"count\": 1, \"min\": 10239.3479347229, \"max\": 10239.3479347229}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=62.696875861058295 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=71, train loss <loss>=-0.01933084563775496\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:12 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:14 INFO 139828400359040] Epoch[72] Batch[0] avg_epoch_loss=-0.068581\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=-0.06858085095882416\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:18 INFO 139828400359040] Epoch[72] Batch[5] avg_epoch_loss=0.106524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=0.10652439304006596\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:18 INFO 139828400359040] Epoch[72] Batch [5]#011Speed: 86.21 samples/sec#011loss=0.106524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] Epoch[72] Batch[10] avg_epoch_loss=0.076714\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=0.04094115430489183\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] Epoch[72] Batch [10]#011Speed: 81.33 samples/sec#011loss=0.040941\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746812.1867507, \"EndTime\": 1646746821.9633777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9775.199174880981, \"count\": 1, \"min\": 9775.199174880981, \"max\": 9775.199174880981}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.60655258560111 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 18.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=72, train loss <loss>=0.07671382997862318\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:24 INFO 139828400359040] Epoch[73] Batch[0] avg_epoch_loss=-0.047583\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=-0.047583453357219696\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:27 INFO 139828400359040] Epoch[73] Batch[5] avg_epoch_loss=0.067049\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=0.06704925031711657\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:27 INFO 139828400359040] Epoch[73] Batch [5]#011Speed: 85.31 samples/sec#011loss=0.067049\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] Epoch[73] Batch[10] avg_epoch_loss=0.011733\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=-0.05464693456888199\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] Epoch[73] Batch [10]#011Speed: 82.71 samples/sec#011loss=-0.054647\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746821.96375, \"EndTime\": 1646746831.7668073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9801.54275894165, \"count\": 1, \"min\": 9801.54275894165, \"max\": 9801.54275894165}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.23352372701575 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 18.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=73, train loss <loss>=0.011732802641662684\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:31 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:33 INFO 139828400359040] Epoch[74] Batch[0] avg_epoch_loss=0.625426\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=0.6254255771636963\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:37 INFO 139828400359040] Epoch[74] Batch[5] avg_epoch_loss=0.423713\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=0.42371296137571335\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:37 INFO 139828400359040] Epoch[74] Batch [5]#011Speed: 84.17 samples/sec#011loss=0.423713\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] Epoch[74] Batch[10] avg_epoch_loss=0.408127\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=0.38942367434501646\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] Epoch[74] Batch [10]#011Speed: 83.02 samples/sec#011loss=0.389424\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746831.7668836, \"EndTime\": 1646746841.639315, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9871.979713439941, \"count\": 1, \"min\": 9871.979713439941, \"max\": 9871.979713439941}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.4628849090532 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 18.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=74, train loss <loss>=0.40812692181630567\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:41 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:43 INFO 139828400359040] Epoch[75] Batch[0] avg_epoch_loss=0.171271\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=0.1712709367275238\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:47 INFO 139828400359040] Epoch[75] Batch[5] avg_epoch_loss=0.218447\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=0.2184471074336519\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:47 INFO 139828400359040] Epoch[75] Batch [5]#011Speed: 78.74 samples/sec#011loss=0.218447\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] Epoch[75] Batch[10] avg_epoch_loss=0.187104\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=0.14949324876070022\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] Epoch[75] Batch [10]#011Speed: 79.05 samples/sec#011loss=0.149493\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746841.6393926, \"EndTime\": 1646746851.8554533, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10215.588808059692, \"count\": 1, \"min\": 10215.588808059692, \"max\": 10215.588808059692}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.26854981421872 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=75, train loss <loss>=0.18710444440049204\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:51 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:54 INFO 139828400359040] Epoch[76] Batch[0] avg_epoch_loss=0.095551\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=0.09555087238550186\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:58 INFO 139828400359040] Epoch[76] Batch[5] avg_epoch_loss=0.042949\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=0.04294883364733929\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:40:58 INFO 139828400359040] Epoch[76] Batch [5]#011Speed: 82.50 samples/sec#011loss=0.042949\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:01 INFO 139828400359040] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746851.855828, \"EndTime\": 1646746861.077625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9220.366477966309, \"count\": 1, \"min\": 9220.366477966309, \"max\": 9220.366477966309}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:01 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.19353372511438 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:01 INFO 139828400359040] #progress_metric: host=algo-1, completed 19.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=76, train loss <loss>=0.02903132586507127\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:01 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:03 INFO 139828400359040] Epoch[77] Batch[0] avg_epoch_loss=-0.059194\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=-0.05919415131211281\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:08 INFO 139828400359040] Epoch[77] Batch[5] avg_epoch_loss=-0.056279\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=-0.05627890334775051\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:08 INFO 139828400359040] Epoch[77] Batch [5]#011Speed: 64.77 samples/sec#011loss=-0.056279\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:11 INFO 139828400359040] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746861.0777342, \"EndTime\": 1646746871.8857718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10807.416200637817, \"count\": 1, \"min\": 10807.416200637817, \"max\": 10807.416200637817}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:11 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=58.93967090719281 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:11 INFO 139828400359040] #progress_metric: host=algo-1, completed 19.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=77, train loss <loss>=-0.013998490758240223\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:11 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:13 INFO 139828400359040] Epoch[78] Batch[0] avg_epoch_loss=-0.154759\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=-0.15475918352603912\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:17 INFO 139828400359040] Epoch[78] Batch[5] avg_epoch_loss=0.016411\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=0.01641095181306203\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:17 INFO 139828400359040] Epoch[78] Batch [5]#011Speed: 82.84 samples/sec#011loss=0.016411\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] Epoch[78] Batch[10] avg_epoch_loss=0.015826\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=0.015124285221099853\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] Epoch[78] Batch [10]#011Speed: 80.04 samples/sec#011loss=0.015124\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746871.8859036, \"EndTime\": 1646746881.8437192, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9956.823348999023, \"count\": 1, \"min\": 9956.823348999023, \"max\": 9956.823348999023}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.29843088093519 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 19.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=78, train loss <loss>=0.015826103362170132\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:23 INFO 139828400359040] Epoch[79] Batch[0] avg_epoch_loss=0.059680\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=0.059679705649614334\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:27 INFO 139828400359040] Epoch[79] Batch[5] avg_epoch_loss=0.037681\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=0.037680795416235924\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:27 INFO 139828400359040] Epoch[79] Batch [5]#011Speed: 82.49 samples/sec#011loss=0.037681\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] Epoch[79] Batch[10] avg_epoch_loss=-0.005236\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=-0.05673672668635845\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] Epoch[79] Batch [10]#011Speed: 81.75 samples/sec#011loss=-0.056737\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] processed a total of 703 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746881.843796, \"EndTime\": 1646746891.720881, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9876.639366149902, \"count\": 1, \"min\": 9876.639366149902, \"max\": 9876.639366149902}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.17491283196763 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=79, train loss <loss>=-0.0052362600849433375\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:31 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:33 INFO 139828400359040] Epoch[80] Batch[0] avg_epoch_loss=-0.129099\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=-0.1290990561246872\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:37 INFO 139828400359040] Epoch[80] Batch[5] avg_epoch_loss=-0.053070\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=-0.053070213024814926\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:37 INFO 139828400359040] Epoch[80] Batch [5]#011Speed: 83.31 samples/sec#011loss=-0.053070\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] Epoch[80] Batch[10] avg_epoch_loss=-0.114364\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=-0.18791566789150238\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] Epoch[80] Batch [10]#011Speed: 80.05 samples/sec#011loss=-0.187916\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746891.7212543, \"EndTime\": 1646746901.7847216, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10062.00385093689, \"count\": 1, \"min\": 10062.00385093689, \"max\": 10062.00385093689}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.00066874000393 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 20.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=80, train loss <loss>=-0.11436360160058195\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:41 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:44 INFO 139828400359040] Epoch[81] Batch[0] avg_epoch_loss=-0.131039\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=-0.13103905320167542\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:48 INFO 139828400359040] Epoch[81] Batch[5] avg_epoch_loss=0.010275\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=0.010274785260359446\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:48 INFO 139828400359040] Epoch[81] Batch [5]#011Speed: 79.38 samples/sec#011loss=0.010275\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:51 INFO 139828400359040] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746901.7850673, \"EndTime\": 1646746911.4770029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9690.584659576416, \"count\": 1, \"min\": 9690.584659576416, \"max\": 9690.584659576416}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.73047145495197 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 20.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=81, train loss <loss>=-0.04795769676566124\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:51 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:53 INFO 139828400359040] Epoch[82] Batch[0] avg_epoch_loss=-0.025664\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=-0.02566426433622837\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:57 INFO 139828400359040] Epoch[82] Batch[5] avg_epoch_loss=0.043134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=0.043133785016834736\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:41:57 INFO 139828400359040] Epoch[82] Batch [5]#011Speed: 84.38 samples/sec#011loss=0.043134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] Epoch[82] Batch[10] avg_epoch_loss=0.003000\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=-0.0451600968837738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] Epoch[82] Batch [10]#011Speed: 83.91 samples/sec#011loss=-0.045160\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746911.4774601, \"EndTime\": 1646746921.3154573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9836.554527282715, \"count\": 1, \"min\": 9836.554527282715, \"max\": 9836.554527282715}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.31527433399285 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] #progress_metric: host=algo-1, completed 20.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=82, train loss <loss>=0.003000202334739945\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:01 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:03 INFO 139828400359040] Epoch[83] Batch[0] avg_epoch_loss=0.146238\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=0.14623822271823883\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:08 INFO 139828400359040] Epoch[83] Batch[5] avg_epoch_loss=0.194124\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=0.19412356428802013\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:08 INFO 139828400359040] Epoch[83] Batch [5]#011Speed: 74.42 samples/sec#011loss=0.194124\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] Epoch[83] Batch[10] avg_epoch_loss=0.112051\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=0.013564220815896987\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] Epoch[83] Batch [10]#011Speed: 81.07 samples/sec#011loss=0.013564\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746921.315551, \"EndTime\": 1646746932.0143356, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10696.343898773193, \"count\": 1, \"min\": 10696.343898773193, \"max\": 10696.343898773193}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=62.1689966713921 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=83, train loss <loss>=0.11205113543705507\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:12 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:14 INFO 139828400359040] Epoch[84] Batch[0] avg_epoch_loss=-0.069731\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=-0.06973104923963547\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:18 INFO 139828400359040] Epoch[84] Batch[5] avg_epoch_loss=-0.045581\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=-0.04558094528814157\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:18 INFO 139828400359040] Epoch[84] Batch [5]#011Speed: 84.40 samples/sec#011loss=-0.045581\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] Epoch[84] Batch[10] avg_epoch_loss=-0.063003\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=-0.08390905391424894\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] Epoch[84] Batch [10]#011Speed: 82.83 samples/sec#011loss=-0.083909\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746932.0144203, \"EndTime\": 1646746941.917253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9900.814294815063, \"count\": 1, \"min\": 9900.814294815063, \"max\": 9900.814294815063}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.96309251859692 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 21.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=84, train loss <loss>=-0.06300281284546311\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:23 INFO 139828400359040] Epoch[85] Batch[0] avg_epoch_loss=-0.150595\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=-0.15059474110603333\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:27 INFO 139828400359040] Epoch[85] Batch[5] avg_epoch_loss=-0.062171\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=-0.06217071662346522\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:27 INFO 139828400359040] Epoch[85] Batch [5]#011Speed: 83.90 samples/sec#011loss=-0.062171\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] Epoch[85] Batch[10] avg_epoch_loss=-0.074332\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=-0.08892646208405494\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] Epoch[85] Batch [10]#011Speed: 80.68 samples/sec#011loss=-0.088926\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746941.917375, \"EndTime\": 1646746951.7712293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9853.216886520386, \"count\": 1, \"min\": 9853.216886520386, \"max\": 9853.216886520386}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.31440576773667 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 21.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=85, train loss <loss>=-0.07433241910555145\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:31 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:33 INFO 139828400359040] Epoch[86] Batch[0] avg_epoch_loss=-0.160667\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=-0.16066688299179077\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:37 INFO 139828400359040] Epoch[86] Batch[5] avg_epoch_loss=-0.144824\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=-0.14482416460911432\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:37 INFO 139828400359040] Epoch[86] Batch [5]#011Speed: 87.40 samples/sec#011loss=-0.144824\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] Epoch[86] Batch[10] avg_epoch_loss=-0.146431\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=-0.14835910201072694\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] Epoch[86] Batch [10]#011Speed: 82.34 samples/sec#011loss=-0.148359\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746951.7716007, \"EndTime\": 1646746961.4547105, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9681.650400161743, \"count\": 1, \"min\": 9681.650400161743, \"max\": 9681.650400161743}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.95590083562867 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 21.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=86, train loss <loss>=-0.14643095433712006\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:41 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_cb3d8b70-3922-48e1-865d-907f9bb69793-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746961.4550858, \"EndTime\": 1646746961.57013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 113.63387107849121, \"count\": 1, \"min\": 113.63387107849121, \"max\": 113.63387107849121}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:43 INFO 139828400359040] Epoch[87] Batch[0] avg_epoch_loss=-0.235238\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=-0.23523809015750885\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:47 INFO 139828400359040] Epoch[87] Batch[5] avg_epoch_loss=-0.002391\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=-0.0023910924792289734\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:47 INFO 139828400359040] Epoch[87] Batch [5]#011Speed: 83.95 samples/sec#011loss=-0.002391\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] Epoch[87] Batch[10] avg_epoch_loss=0.050897\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=0.11484230011701584\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] Epoch[87] Batch [10]#011Speed: 83.94 samples/sec#011loss=0.114842\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746961.5705273, \"EndTime\": 1646746971.3576894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9787.056922912598, \"count\": 1, \"min\": 9787.056922912598, \"max\": 9787.056922912598}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.90234872995293 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=87, train loss <loss>=0.05089681324633685\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:51 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:53 INFO 139828400359040] Epoch[88] Batch[0] avg_epoch_loss=0.287235\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=0.28723493218421936\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:57 INFO 139828400359040] Epoch[88] Batch[5] avg_epoch_loss=0.089363\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=0.0893625117217501\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:42:57 INFO 139828400359040] Epoch[88] Batch [5]#011Speed: 83.46 samples/sec#011loss=0.089363\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] Epoch[88] Batch[10] avg_epoch_loss=0.100216\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=0.11323909759521485\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] Epoch[88] Batch [10]#011Speed: 81.81 samples/sec#011loss=0.113239\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746971.357791, \"EndTime\": 1646746981.145882, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9787.058353424072, \"count\": 1, \"min\": 9787.058353424072, \"max\": 9787.058353424072}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.08909993650481 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] #progress_metric: host=algo-1, completed 22.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=88, train loss <loss>=0.10021550530059771\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:01 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:03 INFO 139828400359040] Epoch[89] Batch[0] avg_epoch_loss=-0.020044\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=-0.0200437530875206\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:07 INFO 139828400359040] Epoch[89] Batch[5] avg_epoch_loss=-0.030271\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=-0.030271211949487526\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:07 INFO 139828400359040] Epoch[89] Batch [5]#011Speed: 77.74 samples/sec#011loss=-0.030271\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] Epoch[89] Batch[10] avg_epoch_loss=-0.083828\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=-0.14809570461511612\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] Epoch[89] Batch [10]#011Speed: 84.89 samples/sec#011loss=-0.148096\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746981.1462407, \"EndTime\": 1646746991.3002942, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10152.642250061035, \"count\": 1, \"min\": 10152.642250061035, \"max\": 10152.642250061035}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.71134738644173 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] #progress_metric: host=algo-1, completed 22.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=89, train loss <loss>=-0.08382779952477325\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:11 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:13 INFO 139828400359040] Epoch[90] Batch[0] avg_epoch_loss=0.053783\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=0.053782593458890915\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:17 INFO 139828400359040] Epoch[90] Batch[5] avg_epoch_loss=0.011860\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=0.011860196478664875\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:17 INFO 139828400359040] Epoch[90] Batch [5]#011Speed: 82.55 samples/sec#011loss=0.011860\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] Epoch[90] Batch[10] avg_epoch_loss=-0.058143\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=-0.14214668273925782\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] Epoch[90] Batch [10]#011Speed: 85.73 samples/sec#011loss=-0.142147\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646746991.300392, \"EndTime\": 1646747001.0068855, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9705.818891525269, \"count\": 1, \"min\": 9705.818891525269, \"max\": 9705.818891525269}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.10189136838812 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 22.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=90, train loss <loss>=-0.05814293043857271\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:23 INFO 139828400359040] Epoch[91] Batch[0] avg_epoch_loss=0.210504\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=0.2105037122964859\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:26 INFO 139828400359040] Epoch[91] Batch[5] avg_epoch_loss=0.030302\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=0.03030246131432553\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:26 INFO 139828400359040] Epoch[91] Batch [5]#011Speed: 85.49 samples/sec#011loss=0.030302\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:29 INFO 139828400359040] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747001.0070207, \"EndTime\": 1646747009.8056815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8797.700881958008, \"count\": 1, \"min\": 8797.700881958008, \"max\": 8797.700881958008}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:29 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.60751836641914 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:29 INFO 139828400359040] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=91, train loss <loss>=-0.0009854264091700316\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:29 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:31 INFO 139828400359040] Epoch[92] Batch[0] avg_epoch_loss=-0.044453\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=-0.04445304349064827\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:35 INFO 139828400359040] Epoch[92] Batch[5] avg_epoch_loss=0.071566\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=0.07156641672675808\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:35 INFO 139828400359040] Epoch[92] Batch [5]#011Speed: 81.92 samples/sec#011loss=0.071566\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:38 INFO 139828400359040] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747009.80588, \"EndTime\": 1646747018.8888059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9081.839323043823, \"count\": 1, \"min\": 9081.839323043823, \"max\": 9081.839323043823}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:38 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.02803045620409 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:38 INFO 139828400359040] #progress_metric: host=algo-1, completed 23.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=92, train loss <loss>=0.07233506301417947\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:38 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:41 INFO 139828400359040] Epoch[93] Batch[0] avg_epoch_loss=-0.104047\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=-0.10404691100120544\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:44 INFO 139828400359040] Epoch[93] Batch[5] avg_epoch_loss=-0.035716\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=-0.03571618782977263\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:44 INFO 139828400359040] Epoch[93] Batch [5]#011Speed: 86.58 samples/sec#011loss=-0.035716\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] Epoch[93] Batch[10] avg_epoch_loss=-0.088559\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=-0.15197119414806365\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] Epoch[93] Batch [10]#011Speed: 87.21 samples/sec#011loss=-0.151971\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747018.8889434, \"EndTime\": 1646747028.4462233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9556.413888931274, \"count\": 1, \"min\": 9556.413888931274, \"max\": 9556.413888931274}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.0163417993458 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] #progress_metric: host=algo-1, completed 23.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=93, train loss <loss>=-0.08855937251990492\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:48 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:50 INFO 139828400359040] Epoch[94] Batch[0] avg_epoch_loss=-0.004756\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=-0.004756172187626362\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:54 INFO 139828400359040] Epoch[94] Batch[5] avg_epoch_loss=-0.075616\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=-0.07561555551365018\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:54 INFO 139828400359040] Epoch[94] Batch [5]#011Speed: 84.26 samples/sec#011loss=-0.075616\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] Epoch[94] Batch[10] avg_epoch_loss=-0.115236\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=-0.16278074830770492\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] Epoch[94] Batch [10]#011Speed: 85.97 samples/sec#011loss=-0.162781\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747028.446299, \"EndTime\": 1646747038.138769, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9691.946506500244, \"count\": 1, \"min\": 9691.946506500244, \"max\": 9691.946506500244}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.33509163042483 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] #progress_metric: host=algo-1, completed 23.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=94, train loss <loss>=-0.11523609769276598\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:43:58 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:00 INFO 139828400359040] Epoch[95] Batch[0] avg_epoch_loss=-0.089485\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=-0.08948454260826111\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:04 INFO 139828400359040] Epoch[95] Batch[5] avg_epoch_loss=-0.121612\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=-0.12161163861552875\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:04 INFO 139828400359040] Epoch[95] Batch [5]#011Speed: 79.26 samples/sec#011loss=-0.121612\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] Epoch[95] Batch[10] avg_epoch_loss=-0.134895\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=-0.15083482936024667\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] Epoch[95] Batch [10]#011Speed: 75.88 samples/sec#011loss=-0.150835\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747038.1388464, \"EndTime\": 1646747048.5307848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10391.47424697876, \"count\": 1, \"min\": 10391.47424697876, \"max\": 10391.47424697876}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=63.22251136781456 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=95, train loss <loss>=-0.13489490713585506\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:08 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:10 INFO 139828400359040] Epoch[96] Batch[0] avg_epoch_loss=-0.193396\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=-0.1933964341878891\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:14 INFO 139828400359040] Epoch[96] Batch[5] avg_epoch_loss=-0.173143\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=-0.17314277837673822\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:14 INFO 139828400359040] Epoch[96] Batch [5]#011Speed: 83.15 samples/sec#011loss=-0.173143\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] Epoch[96] Batch[10] avg_epoch_loss=-0.119534\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=-0.055203502625226976\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] Epoch[96] Batch [10]#011Speed: 83.56 samples/sec#011loss=-0.055204\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747048.5311353, \"EndTime\": 1646747058.3006876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9768.369436264038, \"count\": 1, \"min\": 9768.369436264038, \"max\": 9768.369436264038}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.9398172247961 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] #progress_metric: host=algo-1, completed 24.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=96, train loss <loss>=-0.11953401667150584\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:18 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:20 INFO 139828400359040] Epoch[97] Batch[0] avg_epoch_loss=-0.057837\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=-0.0578371100127697\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:24 INFO 139828400359040] Epoch[97] Batch[5] avg_epoch_loss=-0.062236\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=-0.062236201018095016\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:24 INFO 139828400359040] Epoch[97] Batch [5]#011Speed: 85.18 samples/sec#011loss=-0.062236\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] Epoch[97] Batch[10] avg_epoch_loss=-0.112713\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=-0.17328552454710006\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] Epoch[97] Batch [10]#011Speed: 85.28 samples/sec#011loss=-0.173286\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747058.3011167, \"EndTime\": 1646747067.8926616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9590.038776397705, \"count\": 1, \"min\": 9590.038776397705, \"max\": 9590.038776397705}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.9224627840421 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] #progress_metric: host=algo-1, completed 24.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=97, train loss <loss>=-0.11271316625855186\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:27 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:29 INFO 139828400359040] Epoch[98] Batch[0] avg_epoch_loss=-0.161788\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=-0.16178838908672333\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:33 INFO 139828400359040] Epoch[98] Batch[5] avg_epoch_loss=0.084880\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=0.08488006517291069\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:33 INFO 139828400359040] Epoch[98] Batch [5]#011Speed: 84.50 samples/sec#011loss=0.084880\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] Epoch[98] Batch[10] avg_epoch_loss=0.119693\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=0.1614695806056261\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] Epoch[98] Batch [10]#011Speed: 84.10 samples/sec#011loss=0.161470\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747067.8930395, \"EndTime\": 1646747077.5280454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9633.605480194092, \"count\": 1, \"min\": 9633.605480194092, \"max\": 9633.605480194092}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.3752835872843 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] #progress_metric: host=algo-1, completed 24.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=98, train loss <loss>=0.11969348127869042\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:37 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:39 INFO 139828400359040] Epoch[99] Batch[0] avg_epoch_loss=0.086481\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=0.08648107945919037\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:43 INFO 139828400359040] Epoch[99] Batch[5] avg_epoch_loss=-0.023353\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=-0.023353452250982325\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:43 INFO 139828400359040] Epoch[99] Batch [5]#011Speed: 85.79 samples/sec#011loss=-0.023353\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] Epoch[99] Batch[10] avg_epoch_loss=-0.035843\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=-0.05083085093647242\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] Epoch[99] Batch [10]#011Speed: 83.22 samples/sec#011loss=-0.050831\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747077.5284536, \"EndTime\": 1646747087.2894785, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9759.612083435059, \"count\": 1, \"min\": 9759.612083435059, \"max\": 9759.612083435059}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.15980234425442 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=99, train loss <loss>=-0.035843178926205095\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:47 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:49 INFO 139828400359040] Epoch[100] Batch[0] avg_epoch_loss=-0.178771\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=-0.17877061665058136\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:53 INFO 139828400359040] Epoch[100] Batch[5] avg_epoch_loss=0.075094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=0.07509440059463184\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:53 INFO 139828400359040] Epoch[100] Batch [5]#011Speed: 85.20 samples/sec#011loss=0.075094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] Epoch[100] Batch[10] avg_epoch_loss=0.114839\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=0.16253270357847213\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] Epoch[100] Batch [10]#011Speed: 81.99 samples/sec#011loss=0.162533\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747087.2898262, \"EndTime\": 1646747097.0858915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9794.68822479248, \"count\": 1, \"min\": 9794.68822479248, \"max\": 9794.68822479248}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.27878304944832 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] #progress_metric: host=algo-1, completed 25.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=100, train loss <loss>=0.11483908376910469\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:57 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:59 INFO 139828400359040] Epoch[101] Batch[0] avg_epoch_loss=0.400183\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:44:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=0.4001832604408264\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:03 INFO 139828400359040] Epoch[101] Batch[5] avg_epoch_loss=0.219764\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=0.2197637353092432\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:03 INFO 139828400359040] Epoch[101] Batch [5]#011Speed: 81.10 samples/sec#011loss=0.219764\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:06 INFO 139828400359040] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747097.0862255, \"EndTime\": 1646747106.2175603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9129.9889087677, \"count\": 1, \"min\": 9129.9889087677, \"max\": 9129.9889087677}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:06 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.76765432457898 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:06 INFO 139828400359040] #progress_metric: host=algo-1, completed 25.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=101, train loss <loss>=0.11703496612608433\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:06 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:08 INFO 139828400359040] Epoch[102] Batch[0] avg_epoch_loss=-0.078966\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=-0.0789657011628151\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:12 INFO 139828400359040] Epoch[102] Batch[5] avg_epoch_loss=-0.097874\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=-0.09787389418731134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:12 INFO 139828400359040] Epoch[102] Batch [5]#011Speed: 84.86 samples/sec#011loss=-0.097874\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] Epoch[102] Batch[10] avg_epoch_loss=0.055230\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=0.23895494043827056\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] Epoch[102] Batch [10]#011Speed: 83.14 samples/sec#011loss=0.238955\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747106.2178328, \"EndTime\": 1646747116.2164552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9997.540712356567, \"count\": 1, \"min\": 9997.540712356567, \"max\": 9997.540712356567}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.41524685509813 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] #progress_metric: host=algo-1, completed 25.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=102, train loss <loss>=0.05523012155158953\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:16 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:18 INFO 139828400359040] Epoch[103] Batch[0] avg_epoch_loss=0.252537\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=0.2525366544723511\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:22 INFO 139828400359040] Epoch[103] Batch[5] avg_epoch_loss=0.205973\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=0.20597270503640175\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:22 INFO 139828400359040] Epoch[103] Batch [5]#011Speed: 82.23 samples/sec#011loss=0.205973\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] Epoch[103] Batch[10] avg_epoch_loss=0.153412\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=0.0903399109840393\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] Epoch[103] Batch [10]#011Speed: 86.37 samples/sec#011loss=0.090340\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747116.2165403, \"EndTime\": 1646747125.9655292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9747.629165649414, \"count\": 1, \"min\": 9747.629165649414, \"max\": 9747.629165649414}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.91310120322521 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=103, train loss <loss>=0.15341234410350973\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:25 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:28 INFO 139828400359040] Epoch[104] Batch[0] avg_epoch_loss=0.138043\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=0.13804276287555695\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:31 INFO 139828400359040] Epoch[104] Batch[5] avg_epoch_loss=0.113371\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=0.11337081327413519\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:31 INFO 139828400359040] Epoch[104] Batch [5]#011Speed: 85.27 samples/sec#011loss=0.113371\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] Epoch[104] Batch[10] avg_epoch_loss=0.062472\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=0.001392640732228756\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] Epoch[104] Batch [10]#011Speed: 81.44 samples/sec#011loss=0.001393\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747125.9656117, \"EndTime\": 1646747135.7493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9783.211708068848, \"count\": 1, \"min\": 9783.211708068848, \"max\": 9783.211708068848}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.58505478439818 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] #progress_metric: host=algo-1, completed 26.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=104, train loss <loss>=0.06247164393690499\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:35 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:37 INFO 139828400359040] Epoch[105] Batch[0] avg_epoch_loss=0.249499\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=0.2494991421699524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:41 INFO 139828400359040] Epoch[105] Batch[5] avg_epoch_loss=0.227183\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=0.2271831271549066\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:41 INFO 139828400359040] Epoch[105] Batch [5]#011Speed: 84.18 samples/sec#011loss=0.227183\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] Epoch[105] Batch[10] avg_epoch_loss=0.175573\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=0.11364043056964875\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] Epoch[105] Batch [10]#011Speed: 84.44 samples/sec#011loss=0.113640\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747135.749516, \"EndTime\": 1646747145.517773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9767.262935638428, \"count\": 1, \"min\": 9767.262935638428, \"max\": 9767.262935638428}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.0805306274768 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] #progress_metric: host=algo-1, completed 26.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=105, train loss <loss>=0.17557281052524393\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:45 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:47 INFO 139828400359040] Epoch[106] Batch[0] avg_epoch_loss=0.121167\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=0.12116741389036179\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:51 INFO 139828400359040] Epoch[106] Batch[5] avg_epoch_loss=0.074247\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=0.0742467949166894\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:51 INFO 139828400359040] Epoch[106] Batch [5]#011Speed: 83.39 samples/sec#011loss=0.074247\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] Epoch[106] Batch[10] avg_epoch_loss=0.070930\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=0.06695059826597571\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] Epoch[106] Batch [10]#011Speed: 79.98 samples/sec#011loss=0.066951\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747145.5182173, \"EndTime\": 1646747155.440677, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9920.956373214722, \"count\": 1, \"min\": 9920.956373214722, \"max\": 9920.956373214722}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.54628678039381 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] #progress_metric: host=algo-1, completed 26.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=106, train loss <loss>=0.07093034189363773\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:55 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:57 INFO 139828400359040] Epoch[107] Batch[0] avg_epoch_loss=-0.015005\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:45:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=-0.015005472116172314\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:01 INFO 139828400359040] Epoch[107] Batch[5] avg_epoch_loss=0.071280\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=0.07128030962000291\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:01 INFO 139828400359040] Epoch[107] Batch [5]#011Speed: 84.68 samples/sec#011loss=0.071280\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] Epoch[107] Batch[10] avg_epoch_loss=0.057707\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=0.0414186492562294\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] Epoch[107] Batch [10]#011Speed: 79.35 samples/sec#011loss=0.041419\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747155.4410925, \"EndTime\": 1646747165.4288619, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9986.183404922485, \"count\": 1, \"min\": 9986.183404922485, \"max\": 9986.183404922485}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.19056908966601 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] #quality_metric: host=algo-1, epoch=107, train loss <loss>=0.0577068276364695\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:05 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:07 INFO 139828400359040] Epoch[108] Batch[0] avg_epoch_loss=-0.031559\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=-0.03155927732586861\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:11 INFO 139828400359040] Epoch[108] Batch[5] avg_epoch_loss=-0.029716\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=-0.02971558195228378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:11 INFO 139828400359040] Epoch[108] Batch [5]#011Speed: 85.74 samples/sec#011loss=-0.029716\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] Epoch[108] Batch[10] avg_epoch_loss=-0.036979\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=-0.045694369450211526\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] Epoch[108] Batch [10]#011Speed: 81.15 samples/sec#011loss=-0.045694\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747165.4289558, \"EndTime\": 1646747175.4842808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10054.686069488525, \"count\": 1, \"min\": 10054.686069488525, \"max\": 10054.686069488525}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.14268704120192 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] #progress_metric: host=algo-1, completed 27.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=108, train loss <loss>=-0.036978667178614574\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:15 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:17 INFO 139828400359040] Epoch[109] Batch[0] avg_epoch_loss=0.045586\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=0.045586299151182175\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:21 INFO 139828400359040] Epoch[109] Batch[5] avg_epoch_loss=0.046542\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=0.04654189261297385\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:21 INFO 139828400359040] Epoch[109] Batch [5]#011Speed: 84.59 samples/sec#011loss=0.046542\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] Epoch[109] Batch[10] avg_epoch_loss=-0.028394\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=-0.11831775112077594\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] Epoch[109] Batch [10]#011Speed: 81.73 samples/sec#011loss=-0.118318\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] processed a total of 718 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747175.4844055, \"EndTime\": 1646747185.9831862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10498.125076293945, \"count\": 1, \"min\": 10498.125076293945, \"max\": 10498.125076293945}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.3909982356023 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] #progress_metric: host=algo-1, completed 27.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=109, train loss <loss>=-0.06918196888485302\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:25 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:28 INFO 139828400359040] Epoch[110] Batch[0] avg_epoch_loss=-0.099605\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=-0.0996047705411911\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:31 INFO 139828400359040] Epoch[110] Batch[5] avg_epoch_loss=-0.073283\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=-0.07328254760553439\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:31 INFO 139828400359040] Epoch[110] Batch [5]#011Speed: 86.09 samples/sec#011loss=-0.073283\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] Epoch[110] Batch[10] avg_epoch_loss=-0.094364\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=-0.11966144740581512\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] Epoch[110] Batch [10]#011Speed: 81.04 samples/sec#011loss=-0.119661\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747185.9832904, \"EndTime\": 1646747195.8033702, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9818.29833984375, \"count\": 1, \"min\": 9818.29833984375, \"max\": 9818.29833984375}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.39385255298939 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] #progress_metric: host=algo-1, completed 27.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=110, train loss <loss>=-0.09436386569657108\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:35 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:37 INFO 139828400359040] Epoch[111] Batch[0] avg_epoch_loss=-0.101278\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=-0.1012781411409378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:41 INFO 139828400359040] Epoch[111] Batch[5] avg_epoch_loss=-0.021953\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=-0.021953171739975613\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:41 INFO 139828400359040] Epoch[111] Batch [5]#011Speed: 83.50 samples/sec#011loss=-0.021953\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:44 INFO 139828400359040] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747195.8037744, \"EndTime\": 1646747204.8802385, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9071.709156036377, \"count\": 1, \"min\": 9071.709156036377, \"max\": 9071.709156036377}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:44 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.55580503361003 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:44 INFO 139828400359040] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=111, train loss <loss>=0.010249662026762963\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:44 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:46 INFO 139828400359040] Epoch[112] Batch[0] avg_epoch_loss=-0.079909\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=-0.07990934699773788\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:51 INFO 139828400359040] Epoch[112] Batch[5] avg_epoch_loss=0.062156\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=0.062156217793623604\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:51 INFO 139828400359040] Epoch[112] Batch [5]#011Speed: 79.68 samples/sec#011loss=0.062156\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] Epoch[112] Batch[10] avg_epoch_loss=-0.000314\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=-0.07527826204895974\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] Epoch[112] Batch [10]#011Speed: 82.31 samples/sec#011loss=-0.075278\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747204.880337, \"EndTime\": 1646747214.8982768, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10016.772985458374, \"count\": 1, \"min\": 10016.772985458374, \"max\": 10016.772985458374}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.78454029768734 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] #progress_metric: host=algo-1, completed 28.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=112, train loss <loss>=-0.00031400031664154744\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:54 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:57 INFO 139828400359040] Epoch[113] Batch[0] avg_epoch_loss=-0.072560\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:46:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=-0.07256012409925461\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:00 INFO 139828400359040] Epoch[113] Batch[5] avg_epoch_loss=-0.110361\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=-0.11036099679768085\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:00 INFO 139828400359040] Epoch[113] Batch [5]#011Speed: 84.75 samples/sec#011loss=-0.110361\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] Epoch[113] Batch[10] avg_epoch_loss=-0.115733\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=-0.12217882350087166\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] Epoch[113] Batch [10]#011Speed: 79.22 samples/sec#011loss=-0.122179\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747214.898364, \"EndTime\": 1646747224.8395078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9939.928531646729, \"count\": 1, \"min\": 9939.928531646729, \"max\": 9939.928531646729}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.89501781245846 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] #progress_metric: host=algo-1, completed 28.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=113, train loss <loss>=-0.11573273620822212\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:04 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:07 INFO 139828400359040] Epoch[114] Batch[0] avg_epoch_loss=-0.133227\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=-0.1332271248102188\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:11 INFO 139828400359040] Epoch[114] Batch[5] avg_epoch_loss=-0.181392\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=-0.18139169116814932\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:11 INFO 139828400359040] Epoch[114] Batch [5]#011Speed: 79.55 samples/sec#011loss=-0.181392\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] Epoch[114] Batch[10] avg_epoch_loss=-0.078524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=0.04491822421550751\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] Epoch[114] Batch [10]#011Speed: 80.38 samples/sec#011loss=0.044918\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747224.8395922, \"EndTime\": 1646747235.11954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10279.048681259155, \"count\": 1, \"min\": 10279.048681259155, \"max\": 10279.048681259155}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.59640323966165 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] #progress_metric: host=algo-1, completed 28.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=114, train loss <loss>=-0.07852354781194167\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:15 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:17 INFO 139828400359040] Epoch[115] Batch[0] avg_epoch_loss=0.295120\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=0.2951202094554901\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:21 INFO 139828400359040] Epoch[115] Batch[5] avg_epoch_loss=0.145978\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=0.14597762748599052\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:21 INFO 139828400359040] Epoch[115] Batch [5]#011Speed: 82.51 samples/sec#011loss=0.145978\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] Epoch[115] Batch[10] avg_epoch_loss=0.092732\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=0.02883748859167099\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] Epoch[115] Batch [10]#011Speed: 81.17 samples/sec#011loss=0.028837\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747235.1196508, \"EndTime\": 1646747245.0058784, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9885.329008102417, \"count\": 1, \"min\": 9885.329008102417, \"max\": 9885.329008102417}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.06674891406352 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=115, train loss <loss>=0.09273210980675438\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:25 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:27 INFO 139828400359040] Epoch[116] Batch[0] avg_epoch_loss=0.366395\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=0.3663948178291321\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:30 INFO 139828400359040] Epoch[116] Batch[5] avg_epoch_loss=0.240424\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=0.24042373647292456\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:30 INFO 139828400359040] Epoch[116] Batch [5]#011Speed: 84.76 samples/sec#011loss=0.240424\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:33 INFO 139828400359040] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747245.0061712, \"EndTime\": 1646747253.9748394, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 8967.517375946045, \"count\": 1, \"min\": 8967.517375946045, \"max\": 8967.517375946045}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:33 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.92172098776217 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:33 INFO 139828400359040] #progress_metric: host=algo-1, completed 29.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=116, train loss <loss>=0.21061912328004836\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:33 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:36 INFO 139828400359040] Epoch[117] Batch[0] avg_epoch_loss=0.051125\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=0.05112471804022789\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:39 INFO 139828400359040] Epoch[117] Batch[5] avg_epoch_loss=-0.008257\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=-0.008256720378994942\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:39 INFO 139828400359040] Epoch[117] Batch [5]#011Speed: 82.46 samples/sec#011loss=-0.008257\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] Epoch[117] Batch[10] avg_epoch_loss=0.002539\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=0.015493551269173622\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] Epoch[117] Batch [10]#011Speed: 83.86 samples/sec#011loss=0.015494\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747253.9749155, \"EndTime\": 1646747263.7431326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9767.65251159668, \"count\": 1, \"min\": 9767.65251159668, \"max\": 9767.65251159668}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.1043789686311 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] #progress_metric: host=algo-1, completed 29.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=117, train loss <loss>=0.00253885764289986\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:43 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:45 INFO 139828400359040] Epoch[118] Batch[0] avg_epoch_loss=-0.052776\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=-0.052776213735342026\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:49 INFO 139828400359040] Epoch[118] Batch[5] avg_epoch_loss=-0.083376\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=-0.08337560668587685\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:49 INFO 139828400359040] Epoch[118] Batch [5]#011Speed: 83.35 samples/sec#011loss=-0.083376\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] Epoch[118] Batch[10] avg_epoch_loss=-0.115940\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=-0.1550171285867691\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] Epoch[118] Batch [10]#011Speed: 79.10 samples/sec#011loss=-0.155017\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747263.7432709, \"EndTime\": 1646747273.7083483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9964.234352111816, \"count\": 1, \"min\": 9964.234352111816, \"max\": 9964.234352111816}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.64472837850147 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] #progress_metric: host=algo-1, completed 29.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=118, train loss <loss>=-0.11593993482264606\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:53 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:55 INFO 139828400359040] Epoch[119] Batch[0] avg_epoch_loss=-0.118589\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=-0.11858930438756943\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:59 INFO 139828400359040] Epoch[119] Batch[5] avg_epoch_loss=-0.143642\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=-0.14364159231384596\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:47:59 INFO 139828400359040] Epoch[119] Batch [5]#011Speed: 85.52 samples/sec#011loss=-0.143642\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] Epoch[119] Batch[10] avg_epoch_loss=-0.194100\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=-0.254650291800499\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] Epoch[119] Batch [10]#011Speed: 80.19 samples/sec#011loss=-0.254650\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747273.7084231, \"EndTime\": 1646747283.727863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10018.980026245117, \"count\": 1, \"min\": 10018.980026245117, \"max\": 10018.980026245117}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.26946915897271 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=119, train loss <loss>=-0.1941000920805064\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:03 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_ad8932ec-0852-4048-95b6-07945e39a481-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747283.728214, \"EndTime\": 1646747283.842982, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 113.33608627319336, \"count\": 1, \"min\": 113.33608627319336, \"max\": 113.33608627319336}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:05 INFO 139828400359040] Epoch[120] Batch[0] avg_epoch_loss=-0.257179\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:05 INFO 139828400359040] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=-0.25717851519584656\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:10 INFO 139828400359040] Epoch[120] Batch[5] avg_epoch_loss=-0.095863\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=-0.09586317340532939\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:10 INFO 139828400359040] Epoch[120] Batch [5]#011Speed: 78.91 samples/sec#011loss=-0.095863\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] Epoch[120] Batch[10] avg_epoch_loss=-0.098406\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=-0.10145640764385462\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] Epoch[120] Batch [10]#011Speed: 82.85 samples/sec#011loss=-0.101456\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747283.843384, \"EndTime\": 1646747293.90645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10062.960624694824, \"count\": 1, \"min\": 10062.960624694824, \"max\": 10062.960624694824}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.07639703638559 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] #progress_metric: host=algo-1, completed 30.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=120, train loss <loss>=-0.09840555260465904\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:13 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:16 INFO 139828400359040] Epoch[121] Batch[0] avg_epoch_loss=-0.161823\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=-0.1618226021528244\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:19 INFO 139828400359040] Epoch[121] Batch[5] avg_epoch_loss=0.027657\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=0.027656540274620056\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:19 INFO 139828400359040] Epoch[121] Batch [5]#011Speed: 83.23 samples/sec#011loss=0.027657\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] Epoch[121] Batch[10] avg_epoch_loss=0.190820\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=0.386615127325058\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] Epoch[121] Batch [10]#011Speed: 83.35 samples/sec#011loss=0.386615\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747293.9065995, \"EndTime\": 1646747303.7096903, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9802.049398422241, \"count\": 1, \"min\": 9802.049398422241, \"max\": 9802.049398422241}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.63647666948044 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] #progress_metric: host=algo-1, completed 30.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=121, train loss <loss>=0.19081953438845548\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:23 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:25 INFO 139828400359040] Epoch[122] Batch[0] avg_epoch_loss=0.355263\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=0.3552633225917816\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:29 INFO 139828400359040] Epoch[122] Batch[5] avg_epoch_loss=0.146250\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=0.14625006479521593\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:29 INFO 139828400359040] Epoch[122] Batch [5]#011Speed: 85.19 samples/sec#011loss=0.146250\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] Epoch[122] Batch[10] avg_epoch_loss=0.044056\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=-0.07857772037386894\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] Epoch[122] Batch [10]#011Speed: 83.36 samples/sec#011loss=-0.078578\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747303.7099273, \"EndTime\": 1646747313.4645226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9753.468036651611, \"count\": 1, \"min\": 9753.468036651611, \"max\": 9753.468036651611}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.76971074817634 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] #progress_metric: host=algo-1, completed 30.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=122, train loss <loss>=0.04405561699108644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:33 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:35 INFO 139828400359040] Epoch[123] Batch[0] avg_epoch_loss=-0.027613\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=-0.027612783014774323\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:39 INFO 139828400359040] Epoch[123] Batch[5] avg_epoch_loss=-0.066823\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=-0.06682250586648782\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:39 INFO 139828400359040] Epoch[123] Batch [5]#011Speed: 82.53 samples/sec#011loss=-0.066823\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:42 INFO 139828400359040] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747313.4646354, \"EndTime\": 1646747322.6738436, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9208.576679229736, \"count\": 1, \"min\": 9208.576679229736, \"max\": 9208.576679229736}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:42 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.10763564793778 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:42 INFO 139828400359040] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=123, train loss <loss>=-0.1002270881086588\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:42 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:44 INFO 139828400359040] Epoch[124] Batch[0] avg_epoch_loss=1.625048\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=1.6250478029251099\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:48 INFO 139828400359040] Epoch[124] Batch[5] avg_epoch_loss=0.872324\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=0.8723235428333282\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:48 INFO 139828400359040] Epoch[124] Batch [5]#011Speed: 82.77 samples/sec#011loss=0.872324\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] Epoch[124] Batch[10] avg_epoch_loss=0.851488\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=0.8264861345291138\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] Epoch[124] Batch [10]#011Speed: 82.23 samples/sec#011loss=0.826486\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747322.6742826, \"EndTime\": 1646747332.6069784, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9931.174278259277, \"count\": 1, \"min\": 9931.174278259277, \"max\": 9931.174278259277}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.37486747989038 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] #progress_metric: host=algo-1, completed 31.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=124, train loss <loss>=0.8514883572405035\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:52 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:54 INFO 139828400359040] Epoch[125] Batch[0] avg_epoch_loss=0.574861\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=0.5748606324195862\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:58 INFO 139828400359040] Epoch[125] Batch[5] avg_epoch_loss=0.525543\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=0.5255427062511444\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:48:58 INFO 139828400359040] Epoch[125] Batch [5]#011Speed: 84.09 samples/sec#011loss=0.525543\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] Epoch[125] Batch[10] avg_epoch_loss=0.379867\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=0.20505571812391282\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] Epoch[125] Batch [10]#011Speed: 78.16 samples/sec#011loss=0.205056\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747332.6072705, \"EndTime\": 1646747342.565731, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9957.25965499878, \"count\": 1, \"min\": 9957.25965499878, \"max\": 9957.25965499878}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.59431416185109 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] #progress_metric: host=algo-1, completed 31.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=125, train loss <loss>=0.3798668025569482\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:02 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:04 INFO 139828400359040] Epoch[126] Batch[0] avg_epoch_loss=0.011941\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=0.011940792202949524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:08 INFO 139828400359040] Epoch[126] Batch[5] avg_epoch_loss=0.062534\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=0.06253366669019063\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:08 INFO 139828400359040] Epoch[126] Batch [5]#011Speed: 77.84 samples/sec#011loss=0.062534\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] Epoch[126] Batch[10] avg_epoch_loss=-0.015403\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=-0.10892607048153877\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] Epoch[126] Batch [10]#011Speed: 82.56 samples/sec#011loss=-0.108926\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747342.566103, \"EndTime\": 1646747352.7067196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10139.198780059814, \"count\": 1, \"min\": 10139.198780059814, \"max\": 10139.198780059814}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.4018103365065 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] #progress_metric: host=algo-1, completed 31.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=126, train loss <loss>=-0.015402577478777279\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:12 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:14 INFO 139828400359040] Epoch[127] Batch[0] avg_epoch_loss=-0.078371\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=-0.07837114483118057\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:18 INFO 139828400359040] Epoch[127] Batch[5] avg_epoch_loss=-0.083032\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=-0.08303187973797321\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:18 INFO 139828400359040] Epoch[127] Batch [5]#011Speed: 85.04 samples/sec#011loss=-0.083032\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] Epoch[127] Batch[10] avg_epoch_loss=-0.114107\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=-0.15139787495136262\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] Epoch[127] Batch [10]#011Speed: 80.32 samples/sec#011loss=-0.151398\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747352.7069256, \"EndTime\": 1646747362.5593617, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9851.487159729004, \"count\": 1, \"min\": 9851.487159729004, \"max\": 9851.487159729004}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.12367812798495 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=127, train loss <loss>=-0.11410733210769566\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:22 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:24 INFO 139828400359040] Epoch[128] Batch[0] avg_epoch_loss=-0.230623\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=-0.23062339425086975\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:28 INFO 139828400359040] Epoch[128] Batch[5] avg_epoch_loss=-0.160970\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=-0.16096977765361467\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:28 INFO 139828400359040] Epoch[128] Batch [5]#011Speed: 87.05 samples/sec#011loss=-0.160970\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] Epoch[128] Batch[10] avg_epoch_loss=-0.169128\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=-0.17891851663589478\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] Epoch[128] Batch [10]#011Speed: 82.97 samples/sec#011loss=-0.178919\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747362.5597348, \"EndTime\": 1646747372.150627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9589.470148086548, \"count\": 1, \"min\": 9589.470148086548, \"max\": 9589.470148086548}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.32689107370132 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] #progress_metric: host=algo-1, completed 32.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=128, train loss <loss>=-0.16912829537283292\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:32 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:34 INFO 139828400359040] Epoch[129] Batch[0] avg_epoch_loss=0.462974\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:34 INFO 139828400359040] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=0.4629735052585602\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:38 INFO 139828400359040] Epoch[129] Batch[5] avg_epoch_loss=0.173618\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=0.17361762622992197\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:38 INFO 139828400359040] Epoch[129] Batch [5]#011Speed: 84.35 samples/sec#011loss=0.173618\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] Epoch[129] Batch[10] avg_epoch_loss=0.103859\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=0.020148932933807373\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] Epoch[129] Batch [10]#011Speed: 83.32 samples/sec#011loss=0.020149\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747372.1507664, \"EndTime\": 1646747381.9411814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9789.162635803223, \"count\": 1, \"min\": 9789.162635803223, \"max\": 9789.162635803223}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.29667033590118 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 32.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=129, train loss <loss>=0.10385912927714261\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:41 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:44 INFO 139828400359040] Epoch[130] Batch[0] avg_epoch_loss=-0.141039\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=-0.14103859663009644\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:47 INFO 139828400359040] Epoch[130] Batch[5] avg_epoch_loss=-0.038382\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=-0.03838156769052148\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:47 INFO 139828400359040] Epoch[130] Batch [5]#011Speed: 84.87 samples/sec#011loss=-0.038382\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] Epoch[130] Batch[10] avg_epoch_loss=-0.065617\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=-0.0982998114079237\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] Epoch[130] Batch [10]#011Speed: 83.65 samples/sec#011loss=-0.098300\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747381.9412782, \"EndTime\": 1646747391.626091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9684.087038040161, \"count\": 1, \"min\": 9684.087038040161, \"max\": 9684.087038040161}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.5646973936793 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 32.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=130, train loss <loss>=-0.0656171330166134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:51 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:53 INFO 139828400359040] Epoch[131] Batch[0] avg_epoch_loss=0.037105\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=0.03710522502660751\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:57 INFO 139828400359040] Epoch[131] Batch[5] avg_epoch_loss=-0.128333\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=-0.12833292906483015\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:49:57 INFO 139828400359040] Epoch[131] Batch [5]#011Speed: 81.34 samples/sec#011loss=-0.128333\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] Epoch[131] Batch[10] avg_epoch_loss=-0.143932\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=-0.16265047639608382\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] Epoch[131] Batch [10]#011Speed: 86.54 samples/sec#011loss=-0.162650\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747391.6262321, \"EndTime\": 1646747401.43264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9805.58705329895, \"count\": 1, \"min\": 9805.58705329895, \"max\": 9805.58705329895}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.81441290205156 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=131, train loss <loss>=-0.1439318142154\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:01 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:03 INFO 139828400359040] Epoch[132] Batch[0] avg_epoch_loss=-0.064712\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=-0.06471216678619385\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:07 INFO 139828400359040] Epoch[132] Batch[5] avg_epoch_loss=-0.141190\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=-0.14119029541810355\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:07 INFO 139828400359040] Epoch[132] Batch [5]#011Speed: 77.43 samples/sec#011loss=-0.141190\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] Epoch[132] Batch[10] avg_epoch_loss=-0.161510\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=-0.18589263409376144\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] Epoch[132] Batch [10]#011Speed: 83.99 samples/sec#011loss=-0.185893\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747401.4331868, \"EndTime\": 1646747411.6248703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10190.363645553589, \"count\": 1, \"min\": 10190.363645553589, \"max\": 10190.363645553589}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.53220445891047 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] #progress_metric: host=algo-1, completed 33.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=132, train loss <loss>=-0.16150954027067532\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:11 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:13 INFO 139828400359040] Epoch[133] Batch[0] avg_epoch_loss=-0.197094\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=-0.19709351658821106\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:17 INFO 139828400359040] Epoch[133] Batch[5] avg_epoch_loss=-0.208116\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=-0.20811605950196585\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:17 INFO 139828400359040] Epoch[133] Batch [5]#011Speed: 82.65 samples/sec#011loss=-0.208116\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] Epoch[133] Batch[10] avg_epoch_loss=-0.221432\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=-0.2374101459980011\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] Epoch[133] Batch [10]#011Speed: 81.16 samples/sec#011loss=-0.237410\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747411.6250007, \"EndTime\": 1646747421.6569328, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10031.195163726807, \"count\": 1, \"min\": 10031.195163726807, \"max\": 10031.195163726807}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.29282317262708 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 33.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=133, train loss <loss>=-0.22143155336380005\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:21 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_dff1296b-c887-4c37-83c8-53575283ac5b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747421.6574264, \"EndTime\": 1646747421.7930188, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 134.0470314025879, \"count\": 1, \"min\": 134.0470314025879, \"max\": 134.0470314025879}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:23 INFO 139828400359040] Epoch[134] Batch[0] avg_epoch_loss=-0.087791\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=-0.08779121190309525\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:27 INFO 139828400359040] Epoch[134] Batch[5] avg_epoch_loss=-0.186762\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=-0.18676225965221724\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:27 INFO 139828400359040] Epoch[134] Batch [5]#011Speed: 83.12 samples/sec#011loss=-0.186762\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] Epoch[134] Batch[10] avg_epoch_loss=-0.223781\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=-0.26820367872714995\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] Epoch[134] Batch [10]#011Speed: 84.46 samples/sec#011loss=-0.268204\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747421.7933493, \"EndTime\": 1646747431.6224785, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9829.03790473938, \"count\": 1, \"min\": 9829.03790473938, \"max\": 9829.03790473938}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.82456907359352 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 33.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=134, train loss <loss>=-0.22378108650445938\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:31 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_6db1fc41-8ecf-4ee1-bd7f-637d6c000ca4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747431.6225567, \"EndTime\": 1646747431.7305267, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 107.49030113220215, \"count\": 1, \"min\": 107.49030113220215, \"max\": 107.49030113220215}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:33 INFO 139828400359040] Epoch[135] Batch[0] avg_epoch_loss=-0.196379\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=-0.19637909531593323\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:37 INFO 139828400359040] Epoch[135] Batch[5] avg_epoch_loss=-0.168850\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:37 INFO 139828400359040] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=-0.16884962065766254\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:37 INFO 139828400359040] Epoch[135] Batch [5]#011Speed: 85.01 samples/sec#011loss=-0.168850\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] Epoch[135] Batch[10] avg_epoch_loss=-0.173701\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=-0.17952293455600737\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] Epoch[135] Batch [10]#011Speed: 80.74 samples/sec#011loss=-0.179523\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747431.7305984, \"EndTime\": 1646747441.4831698, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9752.503395080566, \"count\": 1, \"min\": 9752.503395080566, \"max\": 9752.503395080566}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.05552013355634 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=135, train loss <loss>=-0.17370112697509202\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:41 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:43 INFO 139828400359040] Epoch[136] Batch[0] avg_epoch_loss=-0.127752\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=-0.12775175273418427\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:47 INFO 139828400359040] Epoch[136] Batch[5] avg_epoch_loss=-0.120861\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=-0.12086062133312225\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:47 INFO 139828400359040] Epoch[136] Batch [5]#011Speed: 83.98 samples/sec#011loss=-0.120861\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] Epoch[136] Batch[10] avg_epoch_loss=-0.096089\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=-0.06636365205049514\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] Epoch[136] Batch [10]#011Speed: 82.47 samples/sec#011loss=-0.066364\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747441.4835637, \"EndTime\": 1646747451.329423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9844.428300857544, \"count\": 1, \"min\": 9844.428300857544, \"max\": 9844.428300857544}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.00373691196239 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] #progress_metric: host=algo-1, completed 34.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=136, train loss <loss>=-0.09608927165920084\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:51 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:53 INFO 139828400359040] Epoch[137] Batch[0] avg_epoch_loss=0.369830\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=0.3698295056819916\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:57 INFO 139828400359040] Epoch[137] Batch[5] avg_epoch_loss=-0.111795\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=-0.11179517457882564\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:50:57 INFO 139828400359040] Epoch[137] Batch [5]#011Speed: 83.14 samples/sec#011loss=-0.111795\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:00 INFO 139828400359040] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747451.3295033, \"EndTime\": 1646747460.3567224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9026.644229888916, \"count\": 1, \"min\": 9026.644229888916, \"max\": 9026.644229888916}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:00 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.67876278473854 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:00 INFO 139828400359040] #progress_metric: host=algo-1, completed 34.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=137, train loss <loss>=-0.1286582201719284\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:00 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:02 INFO 139828400359040] Epoch[138] Batch[0] avg_epoch_loss=-0.219085\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=-0.21908466517925262\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:06 INFO 139828400359040] Epoch[138] Batch[5] avg_epoch_loss=-0.237828\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=-0.23782813300689062\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:06 INFO 139828400359040] Epoch[138] Batch [5]#011Speed: 82.53 samples/sec#011loss=-0.237828\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] Epoch[138] Batch[10] avg_epoch_loss=0.084869\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=0.47210640385746955\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] Epoch[138] Batch [10]#011Speed: 80.42 samples/sec#011loss=0.472106\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747460.3567982, \"EndTime\": 1646747470.573853, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10216.549158096313, \"count\": 1, \"min\": 10216.549158096313, \"max\": 10216.549158096313}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=63.42550233956463 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 34.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=138, train loss <loss>=0.08486938374963673\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:12 INFO 139828400359040] Epoch[139] Batch[0] avg_epoch_loss=0.351371\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=0.35137122869491577\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:16 INFO 139828400359040] Epoch[139] Batch[5] avg_epoch_loss=0.515552\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=0.5155519197384516\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:16 INFO 139828400359040] Epoch[139] Batch [5]#011Speed: 84.84 samples/sec#011loss=0.515552\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:20 INFO 139828400359040] Epoch[139] Batch[10] avg_epoch_loss=0.347895\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=0.1467058638110757\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:20 INFO 139828400359040] Epoch[139] Batch [10]#011Speed: 80.58 samples/sec#011loss=0.146706\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:21 INFO 139828400359040] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747470.573956, \"EndTime\": 1646747481.065755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10491.127252578735, \"count\": 1, \"min\": 10491.127252578735, \"max\": 10491.127252578735}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.77056550735065 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=139, train loss <loss>=0.2910129767066489\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:23 INFO 139828400359040] Epoch[140] Batch[0] avg_epoch_loss=-0.051115\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=-0.05111498013138771\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:27 INFO 139828400359040] Epoch[140] Batch[5] avg_epoch_loss=0.036405\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=0.036404854928453766\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:27 INFO 139828400359040] Epoch[140] Batch [5]#011Speed: 83.81 samples/sec#011loss=0.036405\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] Epoch[140] Batch[10] avg_epoch_loss=-0.032646\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=-0.11550735123455524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] Epoch[140] Batch [10]#011Speed: 85.57 samples/sec#011loss=-0.115507\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747481.0658464, \"EndTime\": 1646747490.7494535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9682.264804840088, \"count\": 1, \"min\": 9682.264804840088, \"max\": 9682.264804840088}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.95840604369762 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] #progress_metric: host=algo-1, completed 35.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] #quality_metric: host=algo-1, epoch=140, train loss <loss>=-0.03264614787291397\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:30 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:32 INFO 139828400359040] Epoch[141] Batch[0] avg_epoch_loss=0.074254\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=0.07425399869680405\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:36 INFO 139828400359040] Epoch[141] Batch[5] avg_epoch_loss=0.067708\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=0.06770804151892662\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:36 INFO 139828400359040] Epoch[141] Batch [5]#011Speed: 84.24 samples/sec#011loss=0.067708\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] Epoch[141] Batch[10] avg_epoch_loss=0.013841\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=-0.0507986880838871\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] Epoch[141] Batch [10]#011Speed: 86.37 samples/sec#011loss=-0.050799\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747490.7495377, \"EndTime\": 1646747500.4039102, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9653.86414527893, \"count\": 1, \"min\": 9653.86414527893, \"max\": 9653.86414527893}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.98493265279421 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] #progress_metric: host=algo-1, completed 35.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=141, train loss <loss>=0.013841346244920383\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:40 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:42 INFO 139828400359040] Epoch[142] Batch[0] avg_epoch_loss=0.760567\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=0.7605671286582947\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:46 INFO 139828400359040] Epoch[142] Batch[5] avg_epoch_loss=0.280684\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=0.28068377760549384\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:46 INFO 139828400359040] Epoch[142] Batch [5]#011Speed: 85.82 samples/sec#011loss=0.280684\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] Epoch[142] Batch[10] avg_epoch_loss=0.200142\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=0.1034909427165985\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] Epoch[142] Batch [10]#011Speed: 86.61 samples/sec#011loss=0.103491\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747500.4042852, \"EndTime\": 1646747509.9916952, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9585.976600646973, \"count\": 1, \"min\": 9585.976600646973, \"max\": 9585.976600646973}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.0149482921377 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] #progress_metric: host=algo-1, completed 35.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=142, train loss <loss>=0.20014157992872325\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:49 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:52 INFO 139828400359040] Epoch[143] Batch[0] avg_epoch_loss=0.230659\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=0.2306591421365738\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:55 INFO 139828400359040] Epoch[143] Batch[5] avg_epoch_loss=0.050259\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:55 INFO 139828400359040] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=0.0502593411753575\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:55 INFO 139828400359040] Epoch[143] Batch [5]#011Speed: 85.75 samples/sec#011loss=0.050259\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] Epoch[143] Batch[10] avg_epoch_loss=-0.014447\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=-0.09209518060088158\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] Epoch[143] Batch [10]#011Speed: 85.20 samples/sec#011loss=-0.092095\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747509.9917862, \"EndTime\": 1646747519.5989373, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9606.396198272705, \"count\": 1, \"min\": 9606.396198272705, \"max\": 9606.396198272705}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.45396849600608 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=143, train loss <loss>=-0.014447259632023897\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:51:59 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:01 INFO 139828400359040] Epoch[144] Batch[0] avg_epoch_loss=0.119859\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:01 INFO 139828400359040] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=0.1198587492108345\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:05 INFO 139828400359040] Epoch[144] Batch[5] avg_epoch_loss=0.086962\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:05 INFO 139828400359040] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=0.08696150189886491\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:05 INFO 139828400359040] Epoch[144] Batch [5]#011Speed: 84.00 samples/sec#011loss=0.086962\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] Epoch[144] Batch[10] avg_epoch_loss=0.031863\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=-0.034254867490381\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] Epoch[144] Batch [10]#011Speed: 81.79 samples/sec#011loss=-0.034255\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747519.599035, \"EndTime\": 1646747529.6075253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10007.847785949707, \"count\": 1, \"min\": 10007.847785949707, \"max\": 10007.847785949707}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.54545360553284 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] #progress_metric: host=algo-1, completed 36.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] #quality_metric: host=algo-1, epoch=144, train loss <loss>=0.0318631521764804\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:09 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:11 INFO 139828400359040] Epoch[145] Batch[0] avg_epoch_loss=0.423158\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:11 INFO 139828400359040] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=0.42315787076950073\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:15 INFO 139828400359040] Epoch[145] Batch[5] avg_epoch_loss=0.232838\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=0.23283805201450983\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:15 INFO 139828400359040] Epoch[145] Batch [5]#011Speed: 83.31 samples/sec#011loss=0.232838\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] Epoch[145] Batch[10] avg_epoch_loss=0.225122\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=0.21586200147867202\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] Epoch[145] Batch [10]#011Speed: 84.03 samples/sec#011loss=0.215862\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747529.6075974, \"EndTime\": 1646747539.5563395, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9945.97339630127, \"count\": 1, \"min\": 9945.97339630127, \"max\": 9945.97339630127}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.56339027345608 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] #progress_metric: host=algo-1, completed 36.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=145, train loss <loss>=0.22512166540731082\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:19 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:21 INFO 139828400359040] Epoch[146] Batch[0] avg_epoch_loss=0.307944\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=0.3079441487789154\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:25 INFO 139828400359040] Epoch[146] Batch[5] avg_epoch_loss=0.099901\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=0.09990095812827349\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:25 INFO 139828400359040] Epoch[146] Batch [5]#011Speed: 84.60 samples/sec#011loss=0.099901\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] Epoch[146] Batch[10] avg_epoch_loss=0.065148\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=0.023445064947009087\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] Epoch[146] Batch [10]#011Speed: 83.50 samples/sec#011loss=0.023445\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747539.556468, \"EndTime\": 1646747549.241427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9683.897018432617, \"count\": 1, \"min\": 9683.897018432617, \"max\": 9683.897018432617}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.21605149355364 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] #progress_metric: host=algo-1, completed 36.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=146, train loss <loss>=0.06514827940951694\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:29 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:31 INFO 139828400359040] Epoch[147] Batch[0] avg_epoch_loss=-0.159250\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=-0.1592504233121872\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:35 INFO 139828400359040] Epoch[147] Batch[5] avg_epoch_loss=-0.086533\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=-0.08653307395676772\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:35 INFO 139828400359040] Epoch[147] Batch [5]#011Speed: 85.92 samples/sec#011loss=-0.086533\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] Epoch[147] Batch[10] avg_epoch_loss=-0.108819\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=-0.13556256592273713\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] Epoch[147] Batch [10]#011Speed: 83.84 samples/sec#011loss=-0.135563\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747549.241855, \"EndTime\": 1646747558.8849685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9641.575336456299, \"count\": 1, \"min\": 9641.575336456299, \"max\": 9641.575336456299}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.65991937452921 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=147, train loss <loss>=-0.10881920666857199\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:38 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:40 INFO 139828400359040] Epoch[148] Batch[0] avg_epoch_loss=-0.008304\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:40 INFO 139828400359040] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=-0.008304406888782978\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:44 INFO 139828400359040] Epoch[148] Batch[5] avg_epoch_loss=0.014028\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=0.014028080816691121\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:44 INFO 139828400359040] Epoch[148] Batch [5]#011Speed: 83.89 samples/sec#011loss=0.014028\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] Epoch[148] Batch[10] avg_epoch_loss=-0.052109\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=-0.1314738690853119\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] Epoch[148] Batch [10]#011Speed: 83.19 samples/sec#011loss=-0.131474\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747558.8850756, \"EndTime\": 1646747568.5905879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9704.811334609985, \"count\": 1, \"min\": 9704.811334609985, \"max\": 9704.811334609985}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.55001470026397 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] #progress_metric: host=algo-1, completed 37.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=148, train loss <loss>=-0.052109169138764795\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:48 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:50 INFO 139828400359040] Epoch[149] Batch[0] avg_epoch_loss=-0.216783\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=-0.21678338944911957\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:54 INFO 139828400359040] Epoch[149] Batch[5] avg_epoch_loss=-0.180018\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=-0.18001811827222505\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:54 INFO 139828400359040] Epoch[149] Batch [5]#011Speed: 84.72 samples/sec#011loss=-0.180018\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] Epoch[149] Batch[10] avg_epoch_loss=-0.174302\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=-0.16744337677955629\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] Epoch[149] Batch [10]#011Speed: 80.48 samples/sec#011loss=-0.167443\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747568.5909762, \"EndTime\": 1646747578.390908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9798.45905303955, \"count\": 1, \"min\": 9798.45905303955, \"max\": 9798.45905303955}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=71.13278070097897 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] #progress_metric: host=algo-1, completed 37.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=149, train loss <loss>=-0.17430232668464835\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:52:58 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:00 INFO 139828400359040] Epoch[150] Batch[0] avg_epoch_loss=-0.230561\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=-0.23056110739707947\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:04 INFO 139828400359040] Epoch[150] Batch[5] avg_epoch_loss=-0.047427\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=-0.047426531401773296\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:04 INFO 139828400359040] Epoch[150] Batch [5]#011Speed: 82.38 samples/sec#011loss=-0.047427\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] Epoch[150] Batch[10] avg_epoch_loss=-0.066955\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=-0.09038882351014763\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] Epoch[150] Batch [10]#011Speed: 75.52 samples/sec#011loss=-0.090389\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747578.3909864, \"EndTime\": 1646747588.6347868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10243.338584899902, \"count\": 1, \"min\": 10243.338584899902, \"max\": 10243.338584899902}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.33245711699159 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] #progress_metric: host=algo-1, completed 37.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=150, train loss <loss>=-0.0669548459964889\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:08 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:10 INFO 139828400359040] Epoch[151] Batch[0] avg_epoch_loss=-0.268101\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=-0.26810139417648315\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:14 INFO 139828400359040] Epoch[151] Batch[5] avg_epoch_loss=-0.178666\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=-0.17866618372499943\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:14 INFO 139828400359040] Epoch[151] Batch [5]#011Speed: 82.44 samples/sec#011loss=-0.178666\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:17 INFO 139828400359040] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747588.6350608, \"EndTime\": 1646747597.8395958, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9203.252077102661, \"count\": 1, \"min\": 9203.252077102661, \"max\": 9203.252077102661}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:17 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.45039260496516 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:17 INFO 139828400359040] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=151, train loss <loss>=-0.08929947204887867\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:17 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:20 INFO 139828400359040] Epoch[152] Batch[0] avg_epoch_loss=-0.003026\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=-0.003025718964636326\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:23 INFO 139828400359040] Epoch[152] Batch[5] avg_epoch_loss=-0.079618\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=-0.07961844094097614\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:23 INFO 139828400359040] Epoch[152] Batch [5]#011Speed: 81.81 samples/sec#011loss=-0.079618\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:26 INFO 139828400359040] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747597.8400378, \"EndTime\": 1646747606.9993067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9157.796859741211, \"count\": 1, \"min\": 9157.796859741211, \"max\": 9157.796859741211}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:26 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.5731622025206 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:26 INFO 139828400359040] #progress_metric: host=algo-1, completed 38.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=152, train loss <loss>=-0.09211807064712048\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:27 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:29 INFO 139828400359040] Epoch[153] Batch[0] avg_epoch_loss=-0.179779\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=-0.179778590798378\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:33 INFO 139828400359040] Epoch[153] Batch[5] avg_epoch_loss=-0.226974\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=-0.2269737496972084\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:33 INFO 139828400359040] Epoch[153] Batch [5]#011Speed: 81.23 samples/sec#011loss=-0.226974\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] Epoch[153] Batch[10] avg_epoch_loss=-0.222758\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=-0.2176982879638672\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] Epoch[153] Batch [10]#011Speed: 82.40 samples/sec#011loss=-0.217698\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747606.9995499, \"EndTime\": 1646747616.94251, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9941.962480545044, \"count\": 1, \"min\": 9941.962480545044, \"max\": 9941.962480545044}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.39424943104244 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] #progress_metric: host=algo-1, completed 38.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=153, train loss <loss>=-0.22275763072750784\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:36 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:39 INFO 139828400359040] Epoch[154] Batch[0] avg_epoch_loss=-0.258164\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=-0.25816407799720764\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:43 INFO 139828400359040] Epoch[154] Batch[5] avg_epoch_loss=-0.220820\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:43 INFO 139828400359040] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=-0.22081962476174036\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:43 INFO 139828400359040] Epoch[154] Batch [5]#011Speed: 81.78 samples/sec#011loss=-0.220820\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] Epoch[154] Batch[10] avg_epoch_loss=-0.145930\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=-0.05606236308813095\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] Epoch[154] Batch [10]#011Speed: 79.72 samples/sec#011loss=-0.056062\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747616.942843, \"EndTime\": 1646747627.0439873, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10099.817037582397, \"count\": 1, \"min\": 10099.817037582397, \"max\": 10099.817037582397}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.72258747376753 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] #progress_metric: host=algo-1, completed 38.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=154, train loss <loss>=-0.14592996036464517\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:47 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:49 INFO 139828400359040] Epoch[155] Batch[0] avg_epoch_loss=-0.129717\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=-0.12971679866313934\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:52 INFO 139828400359040] Epoch[155] Batch[5] avg_epoch_loss=-0.098790\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=-0.0987897062053283\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:52 INFO 139828400359040] Epoch[155] Batch [5]#011Speed: 83.90 samples/sec#011loss=-0.098790\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] Epoch[155] Batch[10] avg_epoch_loss=-0.047621\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=0.013781245052814483\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] Epoch[155] Batch [10]#011Speed: 83.13 samples/sec#011loss=0.013781\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747627.044125, \"EndTime\": 1646747636.8227751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9777.843475341797, \"count\": 1, \"min\": 9777.843475341797, \"max\": 9777.843475341797}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.62142669119346 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=155, train loss <loss>=-0.04762109199708158\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:56 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:58 INFO 139828400359040] Epoch[156] Batch[0] avg_epoch_loss=0.286028\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:53:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=0.28602835536003113\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:03 INFO 139828400359040] Epoch[156] Batch[5] avg_epoch_loss=0.075681\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=0.07568085938692093\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:03 INFO 139828400359040] Epoch[156] Batch [5]#011Speed: 77.43 samples/sec#011loss=0.075681\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] Epoch[156] Batch[10] avg_epoch_loss=0.017469\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=-0.05238441908732057\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] Epoch[156] Batch [10]#011Speed: 76.66 samples/sec#011loss=-0.052384\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747636.8231316, \"EndTime\": 1646747647.2364218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10411.824941635132, \"count\": 1, \"min\": 10411.824941635132, \"max\": 10411.824941635132}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.11722952422377 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] #progress_metric: host=algo-1, completed 39.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=156, train loss <loss>=0.01746936917135661\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:07 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:09 INFO 139828400359040] Epoch[157] Batch[0] avg_epoch_loss=-0.192861\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:09 INFO 139828400359040] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=-0.192860946059227\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:13 INFO 139828400359040] Epoch[157] Batch[5] avg_epoch_loss=-0.098565\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=-0.09856473933905363\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:13 INFO 139828400359040] Epoch[157] Batch [5]#011Speed: 85.68 samples/sec#011loss=-0.098565\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] Epoch[157] Batch[10] avg_epoch_loss=-0.133989\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=-0.17649833485484123\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] Epoch[157] Batch [10]#011Speed: 83.27 samples/sec#011loss=-0.176498\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747647.2365482, \"EndTime\": 1646747656.8942018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9657.031297683716, \"count\": 1, \"min\": 9657.031297683716, \"max\": 9657.031297683716}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=72.06901476991916 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] #progress_metric: host=algo-1, completed 39.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=157, train loss <loss>=-0.1339891009371389\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:16 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:18 INFO 139828400359040] Epoch[158] Batch[0] avg_epoch_loss=-0.173538\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=-0.1735379993915558\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:22 INFO 139828400359040] Epoch[158] Batch[5] avg_epoch_loss=-0.228303\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=-0.22830320398012796\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:22 INFO 139828400359040] Epoch[158] Batch [5]#011Speed: 83.91 samples/sec#011loss=-0.228303\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] Epoch[158] Batch[10] avg_epoch_loss=-0.228236\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=-0.22815464437007904\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] Epoch[158] Batch [10]#011Speed: 80.57 samples/sec#011loss=-0.228155\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747656.8945367, \"EndTime\": 1646747666.7655876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9869.712114334106, \"count\": 1, \"min\": 9869.712114334106, \"max\": 9869.712114334106}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.29964544399238 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] #progress_metric: host=algo-1, completed 39.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=158, train loss <loss>=-0.22823567688465118\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:26 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_f8fc0236-140d-4f01-969c-4ae88a23ca75-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747666.7659805, \"EndTime\": 1646747666.9125893, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 145.02406120300293, \"count\": 1, \"min\": 145.02406120300293, \"max\": 145.02406120300293}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:28 INFO 139828400359040] Epoch[159] Batch[0] avg_epoch_loss=-0.154746\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=-0.15474575757980347\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:32 INFO 139828400359040] Epoch[159] Batch[5] avg_epoch_loss=-0.215892\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=-0.2158921348551909\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:32 INFO 139828400359040] Epoch[159] Batch [5]#011Speed: 84.23 samples/sec#011loss=-0.215892\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] Epoch[159] Batch[10] avg_epoch_loss=-0.228749\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=-0.24417712688446044\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] Epoch[159] Batch [10]#011Speed: 84.23 samples/sec#011loss=-0.244177\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747666.913056, \"EndTime\": 1646747676.566686, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9653.545618057251, \"count\": 1, \"min\": 9653.545618057251, \"max\": 9653.545618057251}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=72.40770591147965 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=159, train loss <loss>=-0.2287489494139498\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:36 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_06e42754-18ef-47d5-9888-234dbc37f228-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747676.5667713, \"EndTime\": 1646747676.6929464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 124.7715950012207, \"count\": 1, \"min\": 124.7715950012207, \"max\": 124.7715950012207}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:38 INFO 139828400359040] Epoch[160] Batch[0] avg_epoch_loss=-0.251157\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=-0.2511571943759918\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:42 INFO 139828400359040] Epoch[160] Batch[5] avg_epoch_loss=-0.299906\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=-0.29990556836128235\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:42 INFO 139828400359040] Epoch[160] Batch [5]#011Speed: 82.33 samples/sec#011loss=-0.299906\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] Epoch[160] Batch[10] avg_epoch_loss=-0.242680\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=-0.17400910165160893\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] Epoch[160] Batch [10]#011Speed: 86.20 samples/sec#011loss=-0.174009\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747676.6930428, \"EndTime\": 1646747686.4274056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9734.098672866821, \"count\": 1, \"min\": 9734.098672866821, \"max\": 9734.098672866821}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.6993602150315 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] #progress_metric: host=algo-1, completed 40.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=160, train loss <loss>=-0.24267990167506717\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:46 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/state_6060663a-43d6-4ab3-9dec-cc8b8e10fc02-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747686.4274821, \"EndTime\": 1646747686.5433786, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 115.38171768188477, \"count\": 1, \"min\": 115.38171768188477, \"max\": 115.38171768188477}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:48 INFO 139828400359040] Epoch[161] Batch[0] avg_epoch_loss=0.064753\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=0.06475284695625305\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:52 INFO 139828400359040] Epoch[161] Batch[5] avg_epoch_loss=-0.054139\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=-0.05413851638635\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:52 INFO 139828400359040] Epoch[161] Batch [5]#011Speed: 82.51 samples/sec#011loss=-0.054139\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] Epoch[161] Batch[10] avg_epoch_loss=-0.058367\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=-0.06344194710254669\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] Epoch[161] Batch [10]#011Speed: 80.57 samples/sec#011loss=-0.063442\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747686.5434477, \"EndTime\": 1646747696.5174382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9973.91963005066, \"count\": 1, \"min\": 9973.91963005066, \"max\": 9973.91963005066}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.56780640149981 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] #progress_metric: host=algo-1, completed 40.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=161, train loss <loss>=-0.05836734853007577\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:56 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:58 INFO 139828400359040] Epoch[162] Batch[0] avg_epoch_loss=0.048848\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:54:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=0.048847999423742294\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:02 INFO 139828400359040] Epoch[162] Batch[5] avg_epoch_loss=0.099531\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=0.0995311892280976\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:02 INFO 139828400359040] Epoch[162] Batch [5]#011Speed: 80.40 samples/sec#011loss=0.099531\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] Epoch[162] Batch[10] avg_epoch_loss=0.032419\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=-0.04811460971832275\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] Epoch[162] Batch [10]#011Speed: 81.84 samples/sec#011loss=-0.048115\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747696.5178819, \"EndTime\": 1646747706.6106048, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10091.217279434204, \"count\": 1, \"min\": 10091.217279434204, \"max\": 10091.217279434204}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.80783774015397 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] #progress_metric: host=algo-1, completed 40.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=162, train loss <loss>=0.032419462434270165\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:06 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:08 INFO 139828400359040] Epoch[163] Batch[0] avg_epoch_loss=0.039253\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=0.03925338014960289\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:12 INFO 139828400359040] Epoch[163] Batch[5] avg_epoch_loss=-0.103286\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=-0.10328557466467221\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:12 INFO 139828400359040] Epoch[163] Batch [5]#011Speed: 80.00 samples/sec#011loss=-0.103286\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:16 INFO 139828400359040] Epoch[163] Batch[10] avg_epoch_loss=-0.102543\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=-0.10165179073810578\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:16 INFO 139828400359040] Epoch[163] Batch [10]#011Speed: 81.57 samples/sec#011loss=-0.101652\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:17 INFO 139828400359040] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747706.6107166, \"EndTime\": 1646747717.4523358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10840.779066085815, \"count\": 1, \"min\": 10840.779066085815, \"max\": 10840.779066085815}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:17 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.95389053808154 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:17 INFO 139828400359040] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=163, train loss <loss>=-0.08492843620479107\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:17 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:19 INFO 139828400359040] Epoch[164] Batch[0] avg_epoch_loss=1.301389\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=1.3013893365859985\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:23 INFO 139828400359040] Epoch[164] Batch[5] avg_epoch_loss=0.789412\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=0.7894119222958883\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:23 INFO 139828400359040] Epoch[164] Batch [5]#011Speed: 82.82 samples/sec#011loss=0.789412\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] Epoch[164] Batch[10] avg_epoch_loss=0.794835\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=0.801342511177063\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] Epoch[164] Batch [10]#011Speed: 81.19 samples/sec#011loss=0.801343\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747717.4524224, \"EndTime\": 1646747727.3227742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9869.115114212036, \"count\": 1, \"min\": 9869.115114212036, \"max\": 9869.115114212036}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.48018088917578 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] #progress_metric: host=algo-1, completed 41.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] #quality_metric: host=algo-1, epoch=164, train loss <loss>=0.7948349172418768\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:27 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:29 INFO 139828400359040] Epoch[165] Batch[0] avg_epoch_loss=0.637684\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=0.6376842856407166\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:33 INFO 139828400359040] Epoch[165] Batch[5] avg_epoch_loss=0.508235\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:33 INFO 139828400359040] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=0.5082353055477142\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:33 INFO 139828400359040] Epoch[165] Batch [5]#011Speed: 82.83 samples/sec#011loss=0.508235\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:36 INFO 139828400359040] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747727.323159, \"EndTime\": 1646747736.5606935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9236.11855506897, \"count\": 1, \"min\": 9236.11855506897, \"max\": 9236.11855506897}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:36 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.93311609200396 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:36 INFO 139828400359040] #progress_metric: host=algo-1, completed 41.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=165, train loss <loss>=0.4368373841047287\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:36 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:38 INFO 139828400359040] Epoch[166] Batch[0] avg_epoch_loss=0.181781\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=0.18178071081638336\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:42 INFO 139828400359040] Epoch[166] Batch[5] avg_epoch_loss=0.086827\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=0.08682688991151129\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:42 INFO 139828400359040] Epoch[166] Batch [5]#011Speed: 83.28 samples/sec#011loss=0.086827\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] Epoch[166] Batch[10] avg_epoch_loss=0.035830\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=-0.025366348400712013\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] Epoch[166] Batch [10]#011Speed: 80.49 samples/sec#011loss=-0.025366\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747736.5611572, \"EndTime\": 1646747746.570518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10007.839918136597, \"count\": 1, \"min\": 10007.839918136597, \"max\": 10007.839918136597}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.34440074184207 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] #progress_metric: host=algo-1, completed 41.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=166, train loss <loss>=0.03582996340595524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:46 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:48 INFO 139828400359040] Epoch[167] Batch[0] avg_epoch_loss=0.278137\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=0.2781372368335724\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:52 INFO 139828400359040] Epoch[167] Batch[5] avg_epoch_loss=0.207132\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=0.20713187381625175\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:52 INFO 139828400359040] Epoch[167] Batch [5]#011Speed: 82.71 samples/sec#011loss=0.207132\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] Epoch[167] Batch[10] avg_epoch_loss=0.147559\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=0.07607210725545883\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] Epoch[167] Batch [10]#011Speed: 82.35 samples/sec#011loss=0.076072\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747746.5708702, \"EndTime\": 1646747756.4550645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9882.719993591309, \"count\": 1, \"min\": 9882.719993591309, \"max\": 9882.719993591309}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.38767656566523 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=167, train loss <loss>=0.14755925265225497\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:56 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:58 INFO 139828400359040] Epoch[168] Batch[0] avg_epoch_loss=0.029622\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:55:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=0.0296219103038311\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:03 INFO 139828400359040] Epoch[168] Batch[5] avg_epoch_loss=0.124516\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=0.12451617730160554\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:03 INFO 139828400359040] Epoch[168] Batch [5]#011Speed: 73.50 samples/sec#011loss=0.124516\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] Epoch[168] Batch[10] avg_epoch_loss=0.051216\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=-0.036744624376297\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] Epoch[168] Batch [10]#011Speed: 76.75 samples/sec#011loss=-0.036745\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747756.455408, \"EndTime\": 1646747767.171526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10714.816093444824, \"count\": 1, \"min\": 10714.816093444824, \"max\": 10714.816093444824}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=60.663006323105435 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] #progress_metric: host=algo-1, completed 42.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=168, train loss <loss>=0.05121581290255894\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:07 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:09 INFO 139828400359040] Epoch[169] Batch[0] avg_epoch_loss=0.120373\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:09 INFO 139828400359040] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=0.12037260085344315\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:13 INFO 139828400359040] Epoch[169] Batch[5] avg_epoch_loss=0.012061\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=0.012061413998405138\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:13 INFO 139828400359040] Epoch[169] Batch [5]#011Speed: 82.25 samples/sec#011loss=0.012061\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] Epoch[169] Batch[10] avg_epoch_loss=-0.045381\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=-0.11431237757205963\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] Epoch[169] Batch [10]#011Speed: 82.69 samples/sec#011loss=-0.114312\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747767.1716044, \"EndTime\": 1646747777.181779, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10009.0651512146, \"count\": 1, \"min\": 10009.0651512146, \"max\": 10009.0651512146}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.63820286896727 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] #progress_metric: host=algo-1, completed 42.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=169, train loss <loss>=-0.045381218533624305\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:17 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:19 INFO 139828400359040] Epoch[170] Batch[0] avg_epoch_loss=-0.010448\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=-0.01044843066483736\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:23 INFO 139828400359040] Epoch[170] Batch[5] avg_epoch_loss=-0.076286\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=-0.07628605716551344\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:23 INFO 139828400359040] Epoch[170] Batch [5]#011Speed: 82.08 samples/sec#011loss=-0.076286\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:26 INFO 139828400359040] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747777.1819508, \"EndTime\": 1646747786.5401144, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9356.069326400757, \"count\": 1, \"min\": 9356.069326400757, \"max\": 9356.069326400757}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:26 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.6906350574408 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:26 INFO 139828400359040] #progress_metric: host=algo-1, completed 42.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=170, train loss <loss>=-0.10030704932287335\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:26 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:28 INFO 139828400359040] Epoch[171] Batch[0] avg_epoch_loss=-0.088036\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=-0.08803604543209076\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:32 INFO 139828400359040] Epoch[171] Batch[5] avg_epoch_loss=-0.137302\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=-0.13730227574706078\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:32 INFO 139828400359040] Epoch[171] Batch [5]#011Speed: 82.17 samples/sec#011loss=-0.137302\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] Epoch[171] Batch[10] avg_epoch_loss=-0.140965\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=-0.14536056369543077\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] Epoch[171] Batch [10]#011Speed: 77.89 samples/sec#011loss=-0.145361\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747786.5406356, \"EndTime\": 1646747796.6037695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10062.461137771606, \"count\": 1, \"min\": 10062.461137771606, \"max\": 10062.461137771606}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.26412671419497 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=171, train loss <loss>=-0.14096513390541077\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:36 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:38 INFO 139828400359040] Epoch[172] Batch[0] avg_epoch_loss=-0.096833\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=-0.09683334827423096\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:42 INFO 139828400359040] Epoch[172] Batch[5] avg_epoch_loss=-0.160822\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=-0.16082230086127916\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:42 INFO 139828400359040] Epoch[172] Batch [5]#011Speed: 82.10 samples/sec#011loss=-0.160822\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] Epoch[172] Batch[10] avg_epoch_loss=-0.170439\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=-0.18197965025901794\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] Epoch[172] Batch [10]#011Speed: 82.17 samples/sec#011loss=-0.181980\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747796.6041782, \"EndTime\": 1646747806.5701532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9964.67113494873, \"count\": 1, \"min\": 9964.67113494873, \"max\": 9964.67113494873}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.13602669449544 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] #progress_metric: host=algo-1, completed 43.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=172, train loss <loss>=-0.17043927786025134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:46 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:48 INFO 139828400359040] Epoch[173] Batch[0] avg_epoch_loss=-0.159412\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=-0.15941154956817627\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:52 INFO 139828400359040] Epoch[173] Batch[5] avg_epoch_loss=-0.121543\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=-0.12154323576639096\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:52 INFO 139828400359040] Epoch[173] Batch [5]#011Speed: 84.92 samples/sec#011loss=-0.121543\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] Epoch[173] Batch[10] avg_epoch_loss=-0.107147\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=-0.08987201824784279\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] Epoch[173] Batch [10]#011Speed: 82.85 samples/sec#011loss=-0.089872\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747806.5702853, \"EndTime\": 1646747816.3220131, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9751.17826461792, \"count\": 1, \"min\": 9751.17826461792, \"max\": 9751.17826461792}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.14516847979975 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] #progress_metric: host=algo-1, completed 43.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=173, train loss <loss>=-0.10714722780341451\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:56 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:58 INFO 139828400359040] Epoch[174] Batch[0] avg_epoch_loss=0.048852\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:56:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=0.0488518625497818\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:02 INFO 139828400359040] Epoch[174] Batch[5] avg_epoch_loss=-0.063784\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=-0.0637840951482455\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:02 INFO 139828400359040] Epoch[174] Batch [5]#011Speed: 79.39 samples/sec#011loss=-0.063784\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] Epoch[174] Batch[10] avg_epoch_loss=-0.080941\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=-0.10152866328135132\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] Epoch[174] Batch [10]#011Speed: 77.32 samples/sec#011loss=-0.101529\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747816.3220794, \"EndTime\": 1646747826.6423552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10319.636106491089, \"count\": 1, \"min\": 10319.636106491089, \"max\": 10319.636106491089}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=62.984911238857904 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] #progress_metric: host=algo-1, completed 43.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=174, train loss <loss>=-0.08094071702692997\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:06 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:08 INFO 139828400359040] Epoch[175] Batch[0] avg_epoch_loss=-0.214131\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=-0.21413128077983856\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:12 INFO 139828400359040] Epoch[175] Batch[5] avg_epoch_loss=-0.143205\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=-0.14320514785746732\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:12 INFO 139828400359040] Epoch[175] Batch [5]#011Speed: 83.45 samples/sec#011loss=-0.143205\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] Epoch[175] Batch[10] avg_epoch_loss=-0.182000\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=-0.22855471670627595\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] Epoch[175] Batch [10]#011Speed: 83.29 samples/sec#011loss=-0.228555\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747826.6424441, \"EndTime\": 1646747836.5783033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9934.4961643219, \"count\": 1, \"min\": 9934.4961643219, \"max\": 9934.4961643219}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.52846479275101 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=175, train loss <loss>=-0.18200040642510762\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:16 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:18 INFO 139828400359040] Epoch[176] Batch[0] avg_epoch_loss=0.694036\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=0.6940364837646484\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:22 INFO 139828400359040] Epoch[176] Batch[5] avg_epoch_loss=0.363002\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:22 INFO 139828400359040] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=0.3630020407338937\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:22 INFO 139828400359040] Epoch[176] Batch [5]#011Speed: 82.50 samples/sec#011loss=0.363002\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] Epoch[176] Batch[10] avg_epoch_loss=0.369603\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=0.37752357721328733\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] Epoch[176] Batch [10]#011Speed: 82.39 samples/sec#011loss=0.377524\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747836.5783827, \"EndTime\": 1646747846.4109242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9832.081079483032, \"count\": 1, \"min\": 9832.081079483032, \"max\": 9832.081079483032}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=70.07393909667259 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] #progress_metric: host=algo-1, completed 44.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=176, train loss <loss>=0.3696027391336181\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:26 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:28 INFO 139828400359040] Epoch[177] Batch[0] avg_epoch_loss=0.267977\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=0.2679767906665802\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:32 INFO 139828400359040] Epoch[177] Batch[5] avg_epoch_loss=0.144788\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=0.14478808517257372\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:32 INFO 139828400359040] Epoch[177] Batch [5]#011Speed: 83.32 samples/sec#011loss=0.144788\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] Epoch[177] Batch[10] avg_epoch_loss=0.106353\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=0.06023124344646931\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] Epoch[177] Batch [10]#011Speed: 80.99 samples/sec#011loss=0.060231\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747846.4112554, \"EndTime\": 1646747856.3733847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9960.776805877686, \"count\": 1, \"min\": 9960.776805877686, \"max\": 9960.776805877686}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.16659430176938 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] #progress_metric: host=algo-1, completed 44.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=177, train loss <loss>=0.10635315711525353\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:36 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:38 INFO 139828400359040] Epoch[178] Batch[0] avg_epoch_loss=0.389144\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=0.3891444206237793\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:42 INFO 139828400359040] Epoch[178] Batch[5] avg_epoch_loss=0.322243\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=0.3222431888182958\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:42 INFO 139828400359040] Epoch[178] Batch [5]#011Speed: 84.45 samples/sec#011loss=0.322243\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] Epoch[178] Batch[10] avg_epoch_loss=0.237932\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=0.13675771802663803\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] Epoch[178] Batch [10]#011Speed: 81.58 samples/sec#011loss=0.136758\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747856.373459, \"EndTime\": 1646747866.2125835, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9838.672637939453, \"count\": 1, \"min\": 9838.672637939453, \"max\": 9838.672637939453}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.65849985596192 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] #progress_metric: host=algo-1, completed 44.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=178, train loss <loss>=0.2379316111857241\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:46 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:48 INFO 139828400359040] Epoch[179] Batch[0] avg_epoch_loss=0.713413\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:48 INFO 139828400359040] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=0.7134125232696533\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:52 INFO 139828400359040] Epoch[179] Batch[5] avg_epoch_loss=0.616335\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=0.6163347959518433\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:52 INFO 139828400359040] Epoch[179] Batch [5]#011Speed: 81.44 samples/sec#011loss=0.616335\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:56 INFO 139828400359040] Epoch[179] Batch[10] avg_epoch_loss=0.537508\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=0.44291664063930514\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:56 INFO 139828400359040] Epoch[179] Batch [10]#011Speed: 76.67 samples/sec#011loss=0.442917\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:57 INFO 139828400359040] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747866.2126582, \"EndTime\": 1646747877.5378206, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 11324.718236923218, \"count\": 1, \"min\": 11324.718236923218, \"max\": 11324.718236923218}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:57 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=62.51539786018396 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:57 INFO 139828400359040] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=179, train loss <loss>=0.528617033114036\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:57 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:59 INFO 139828400359040] Epoch[180] Batch[0] avg_epoch_loss=1.082526\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:57:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=1.0825258493423462\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:03 INFO 139828400359040] Epoch[180] Batch[5] avg_epoch_loss=0.654919\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:03 INFO 139828400359040] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=0.6549193859100342\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:03 INFO 139828400359040] Epoch[180] Batch [5]#011Speed: 79.80 samples/sec#011loss=0.654919\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] Epoch[180] Batch[10] avg_epoch_loss=0.593191\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=0.5191160142421722\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] Epoch[180] Batch [10]#011Speed: 78.34 samples/sec#011loss=0.519116\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747877.538228, \"EndTime\": 1646747887.8291948, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10289.474964141846, \"count\": 1, \"min\": 10289.474964141846, \"max\": 10289.474964141846}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.7256312698176 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] #progress_metric: host=algo-1, completed 45.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] #quality_metric: host=algo-1, epoch=180, train loss <loss>=0.5931905806064606\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:07 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:10 INFO 139828400359040] Epoch[181] Batch[0] avg_epoch_loss=0.111274\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=0.11127427220344543\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:13 INFO 139828400359040] Epoch[181] Batch[5] avg_epoch_loss=0.227476\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=0.22747582445542017\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:13 INFO 139828400359040] Epoch[181] Batch [5]#011Speed: 83.09 samples/sec#011loss=0.227476\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] Epoch[181] Batch[10] avg_epoch_loss=0.168736\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=0.09824847871204838\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] Epoch[181] Batch [10]#011Speed: 82.51 samples/sec#011loss=0.098248\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747887.8292701, \"EndTime\": 1646747897.846099, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10016.37315750122, \"count\": 1, \"min\": 10016.37315750122, \"max\": 10016.37315750122}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.79147859442052 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] #progress_metric: host=algo-1, completed 45.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] #quality_metric: host=algo-1, epoch=181, train loss <loss>=0.16873612184479664\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:17 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:19 INFO 139828400359040] Epoch[182] Batch[0] avg_epoch_loss=0.032213\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=0.032213497906923294\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:23 INFO 139828400359040] Epoch[182] Batch[5] avg_epoch_loss=0.047929\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=0.047929431311786175\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:23 INFO 139828400359040] Epoch[182] Batch [5]#011Speed: 84.46 samples/sec#011loss=0.047929\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:26 INFO 139828400359040] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747897.8461807, \"EndTime\": 1646747906.8699515, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9023.30994606018, \"count\": 1, \"min\": 9023.30994606018, \"max\": 9023.30994606018}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:26 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.15302238203905 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:26 INFO 139828400359040] #progress_metric: host=algo-1, completed 45.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:26 INFO 139828400359040] #quality_metric: host=algo-1, epoch=182, train loss <loss>=0.014372600987553597\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:26 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:29 INFO 139828400359040] Epoch[183] Batch[0] avg_epoch_loss=-0.035190\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=-0.03518960624933243\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:32 INFO 139828400359040] Epoch[183] Batch[5] avg_epoch_loss=-0.049834\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=-0.04983387173463901\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:32 INFO 139828400359040] Epoch[183] Batch [5]#011Speed: 82.87 samples/sec#011loss=-0.049834\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] Epoch[183] Batch[10] avg_epoch_loss=-0.055620\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=-0.06256442070007324\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] Epoch[183] Batch [10]#011Speed: 81.75 samples/sec#011loss=-0.062564\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747906.8703814, \"EndTime\": 1646747916.8062084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9934.87024307251, \"count\": 1, \"min\": 9934.87024307251, \"max\": 9934.87024307251}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.9286561034044 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] #quality_metric: host=algo-1, epoch=183, train loss <loss>=-0.055620484900745476\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:36 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:38 INFO 139828400359040] Epoch[184] Batch[0] avg_epoch_loss=1.184848\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=1.1848479509353638\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:42 INFO 139828400359040] Epoch[184] Batch[5] avg_epoch_loss=0.754608\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=0.7546079854170481\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:42 INFO 139828400359040] Epoch[184] Batch [5]#011Speed: 81.68 samples/sec#011loss=0.754608\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] Epoch[184] Batch[10] avg_epoch_loss=0.628567\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=0.47731754183769226\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] Epoch[184] Batch [10]#011Speed: 78.32 samples/sec#011loss=0.477318\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747916.8062856, \"EndTime\": 1646747926.9102037, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10103.452444076538, \"count\": 1, \"min\": 10103.452444076538, \"max\": 10103.452444076538}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=69.48012772312168 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] #progress_metric: host=algo-1, completed 46.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] #quality_metric: host=algo-1, epoch=184, train loss <loss>=0.6285668746991591\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:46 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:49 INFO 139828400359040] Epoch[185] Batch[0] avg_epoch_loss=0.497138\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=0.49713757634162903\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:53 INFO 139828400359040] Epoch[185] Batch[5] avg_epoch_loss=0.407893\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:53 INFO 139828400359040] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=0.4078928927580516\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:53 INFO 139828400359040] Epoch[185] Batch [5]#011Speed: 80.37 samples/sec#011loss=0.407893\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] Epoch[185] Batch[10] avg_epoch_loss=0.327656\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=0.23137154132127763\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] Epoch[185] Batch [10]#011Speed: 80.13 samples/sec#011loss=0.231372\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747926.9103231, \"EndTime\": 1646747937.7920947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10881.196975708008, \"count\": 1, \"min\": 10881.196975708008, \"max\": 10881.196975708008}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.8815754583735 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] #progress_metric: host=algo-1, completed 46.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] #quality_metric: host=algo-1, epoch=185, train loss <loss>=0.31622976747651893\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:57 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:59 INFO 139828400359040] Epoch[186] Batch[0] avg_epoch_loss=0.117049\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:58:59 INFO 139828400359040] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=0.11704860627651215\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:04 INFO 139828400359040] Epoch[186] Batch[5] avg_epoch_loss=0.070746\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=0.07074641746779282\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:04 INFO 139828400359040] Epoch[186] Batch [5]#011Speed: 76.07 samples/sec#011loss=0.070746\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] Epoch[186] Batch[10] avg_epoch_loss=0.065186\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=0.05851292638108134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] Epoch[186] Batch [10]#011Speed: 74.52 samples/sec#011loss=0.058513\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747937.7922182, \"EndTime\": 1646747948.4555469, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10662.459373474121, \"count\": 1, \"min\": 10662.459373474121, \"max\": 10662.459373474121}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=63.86765247621784 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] #progress_metric: host=algo-1, completed 46.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] #quality_metric: host=algo-1, epoch=186, train loss <loss>=0.06518573970110579\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:08 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:10 INFO 139828400359040] Epoch[187] Batch[0] avg_epoch_loss=-0.098662\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=-0.09866198152303696\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:14 INFO 139828400359040] Epoch[187] Batch[5] avg_epoch_loss=-0.064496\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:14 INFO 139828400359040] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=-0.06449615210294724\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:14 INFO 139828400359040] Epoch[187] Batch [5]#011Speed: 79.84 samples/sec#011loss=-0.064496\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] Epoch[187] Batch[10] avg_epoch_loss=-0.091372\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=-0.1236232690513134\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] Epoch[187] Batch [10]#011Speed: 81.57 samples/sec#011loss=-0.123623\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747948.4556258, \"EndTime\": 1646747958.564375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10107.647180557251, \"count\": 1, \"min\": 10107.647180557251, \"max\": 10107.647180557251}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.58068388663044 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] #quality_metric: host=algo-1, epoch=187, train loss <loss>=-0.09137211435220459\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:18 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:20 INFO 139828400359040] Epoch[188] Batch[0] avg_epoch_loss=-0.115096\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=-0.11509586125612259\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:24 INFO 139828400359040] Epoch[188] Batch[5] avg_epoch_loss=-0.112638\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=-0.11263808235526085\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:24 INFO 139828400359040] Epoch[188] Batch [5]#011Speed: 80.83 samples/sec#011loss=-0.112638\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:28 INFO 139828400359040] Epoch[188] Batch[10] avg_epoch_loss=-0.132741\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=-0.15686476305127145\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:28 INFO 139828400359040] Epoch[188] Batch [10]#011Speed: 79.05 samples/sec#011loss=-0.156865\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:29 INFO 139828400359040] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747958.5647213, \"EndTime\": 1646747969.4148421, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10848.752737045288, \"count\": 1, \"min\": 10848.752737045288, \"max\": 10848.752737045288}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:29 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.26025841334466 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:29 INFO 139828400359040] #progress_metric: host=algo-1, completed 47.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=188, train loss <loss>=-0.13320022790382305\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:29 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:31 INFO 139828400359040] Epoch[189] Batch[0] avg_epoch_loss=-0.038344\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=-0.03834369033575058\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:35 INFO 139828400359040] Epoch[189] Batch[5] avg_epoch_loss=0.033072\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:35 INFO 139828400359040] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=0.03307185166825851\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:35 INFO 139828400359040] Epoch[189] Batch [5]#011Speed: 80.56 samples/sec#011loss=0.033072\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] Epoch[189] Batch[10] avg_epoch_loss=-0.010421\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=-0.06261236257851124\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] Epoch[189] Batch [10]#011Speed: 82.10 samples/sec#011loss=-0.062612\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747969.4149175, \"EndTime\": 1646747979.4448116, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10029.388904571533, \"count\": 1, \"min\": 10029.388904571533, \"max\": 10029.388904571533}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.00797997362821 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] #progress_metric: host=algo-1, completed 47.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] #quality_metric: host=algo-1, epoch=189, train loss <loss>=-0.010420972989364103\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:39 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:41 INFO 139828400359040] Epoch[190] Batch[0] avg_epoch_loss=-0.115147\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:41 INFO 139828400359040] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=-0.11514676362276077\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:45 INFO 139828400359040] Epoch[190] Batch[5] avg_epoch_loss=-0.073448\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:45 INFO 139828400359040] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=-0.07344807032495737\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:45 INFO 139828400359040] Epoch[190] Batch [5]#011Speed: 79.99 samples/sec#011loss=-0.073448\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:49 INFO 139828400359040] Epoch[190] Batch[10] avg_epoch_loss=-0.093284\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:49 INFO 139828400359040] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=-0.11708710640668869\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:49 INFO 139828400359040] Epoch[190] Batch [10]#011Speed: 80.09 samples/sec#011loss=-0.117087\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:50 INFO 139828400359040] processed a total of 729 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747979.4449027, \"EndTime\": 1646747990.2442636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10798.696279525757, \"count\": 1, \"min\": 10798.696279525757, \"max\": 10798.696279525757}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:50 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.50535321963795 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:50 INFO 139828400359040] #progress_metric: host=algo-1, completed 47.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:50 INFO 139828400359040] #quality_metric: host=algo-1, epoch=190, train loss <loss>=-0.10503961875413854\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:50 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:52 INFO 139828400359040] Epoch[191] Batch[0] avg_epoch_loss=-0.191868\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=-0.19186754524707794\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:56 INFO 139828400359040] Epoch[191] Batch[5] avg_epoch_loss=-0.042618\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:56 INFO 139828400359040] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=-0.04261769230167071\u001b[0m\n",
      "\u001b[34m[03/08/2022 13:59:56 INFO 139828400359040] Epoch[191] Batch [5]#011Speed: 80.53 samples/sec#011loss=-0.042618\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] Epoch[191] Batch[10] avg_epoch_loss=-0.074956\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=-0.11376259699463845\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] Epoch[191] Batch [10]#011Speed: 82.36 samples/sec#011loss=-0.113763\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646747990.2446442, \"EndTime\": 1646748000.243679, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9997.608661651611, \"count\": 1, \"min\": 9997.608661651611, \"max\": 9997.608661651611}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=68.31504972122727 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] #quality_metric: host=algo-1, epoch=191, train loss <loss>=-0.07495628534392877\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:00 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:02 INFO 139828400359040] Epoch[192] Batch[0] avg_epoch_loss=-0.160846\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=-0.16084600985050201\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:06 INFO 139828400359040] Epoch[192] Batch[5] avg_epoch_loss=-0.077758\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:06 INFO 139828400359040] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=-0.07775844012697537\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:06 INFO 139828400359040] Epoch[192] Batch [5]#011Speed: 79.39 samples/sec#011loss=-0.077758\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] Epoch[192] Batch[10] avg_epoch_loss=-0.084527\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=-0.0926501415669918\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] Epoch[192] Batch [10]#011Speed: 75.84 samples/sec#011loss=-0.092650\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748000.243812, \"EndTime\": 1646748010.7059014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10461.357116699219, \"count\": 1, \"min\": 10461.357116699219, \"max\": 10461.357116699219}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.5224376384715 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] #progress_metric: host=algo-1, completed 48.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] #quality_metric: host=algo-1, epoch=192, train loss <loss>=-0.08452739532698285\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:10 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:12 INFO 139828400359040] Epoch[193] Batch[0] avg_epoch_loss=-0.158946\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:12 INFO 139828400359040] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=-0.15894575417041779\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:16 INFO 139828400359040] Epoch[193] Batch[5] avg_epoch_loss=0.043649\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:16 INFO 139828400359040] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=0.04364881540338198\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:16 INFO 139828400359040] Epoch[193] Batch [5]#011Speed: 84.00 samples/sec#011loss=0.043649\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:20 INFO 139828400359040] Epoch[193] Batch[10] avg_epoch_loss=0.034193\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:20 INFO 139828400359040] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=0.022846345975995063\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:20 INFO 139828400359040] Epoch[193] Batch [10]#011Speed: 77.93 samples/sec#011loss=0.022846\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:21 INFO 139828400359040] processed a total of 717 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748010.705981, \"EndTime\": 1646748021.413544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10705.95407485962, \"count\": 1, \"min\": 10705.95407485962, \"max\": 10705.95407485962}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:21 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.96999233388838 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:21 INFO 139828400359040] #progress_metric: host=algo-1, completed 48.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:21 INFO 139828400359040] #quality_metric: host=algo-1, epoch=193, train loss <loss>=0.016904499537001055\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:21 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:24 INFO 139828400359040] Epoch[194] Batch[0] avg_epoch_loss=-0.157085\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:24 INFO 139828400359040] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=-0.1570845991373062\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:28 INFO 139828400359040] Epoch[194] Batch[5] avg_epoch_loss=-0.094111\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:28 INFO 139828400359040] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=-0.09411111070464055\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:28 INFO 139828400359040] Epoch[194] Batch [5]#011Speed: 82.33 samples/sec#011loss=-0.094111\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] Epoch[194] Batch[10] avg_epoch_loss=-0.081314\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=-0.06595642734318971\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] Epoch[194] Batch [10]#011Speed: 81.16 samples/sec#011loss=-0.065956\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748021.4136412, \"EndTime\": 1646748031.9978402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10582.534790039062, \"count\": 1, \"min\": 10582.534790039062, \"max\": 10582.534790039062}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=63.025804797583504 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] #progress_metric: host=algo-1, completed 48.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] #quality_metric: host=algo-1, epoch=194, train loss <loss>=-0.08131352735852654\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:31 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:34 INFO 139828400359040] Epoch[195] Batch[0] avg_epoch_loss=0.156595\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:34 INFO 139828400359040] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=0.1565951406955719\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:38 INFO 139828400359040] Epoch[195] Batch[5] avg_epoch_loss=-0.017420\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:38 INFO 139828400359040] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=-0.017420278241237003\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:38 INFO 139828400359040] Epoch[195] Batch [5]#011Speed: 81.04 samples/sec#011loss=-0.017420\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] Epoch[195] Batch[10] avg_epoch_loss=-0.053400\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=-0.09657614286988973\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] Epoch[195] Batch [10]#011Speed: 80.83 samples/sec#011loss=-0.096576\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748031.9982095, \"EndTime\": 1646748042.0751388, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10075.462102890015, \"count\": 1, \"min\": 10075.462102890015, \"max\": 10075.462102890015}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.20502803620228 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] #quality_metric: host=algo-1, epoch=195, train loss <loss>=-0.05340021670880643\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:42 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:44 INFO 139828400359040] Epoch[196] Batch[0] avg_epoch_loss=-0.111783\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:44 INFO 139828400359040] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=-0.1117829829454422\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:47 INFO 139828400359040] Epoch[196] Batch[5] avg_epoch_loss=-0.018772\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:47 INFO 139828400359040] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=-0.018772482794399064\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:47 INFO 139828400359040] Epoch[196] Batch [5]#011Speed: 83.08 samples/sec#011loss=-0.018772\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:51 INFO 139828400359040] Epoch[196] Batch[10] avg_epoch_loss=-0.040415\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:51 INFO 139828400359040] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=-0.0663869172334671\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:51 INFO 139828400359040] Epoch[196] Batch [10]#011Speed: 80.32 samples/sec#011loss=-0.066387\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:52 INFO 139828400359040] processed a total of 721 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748042.0755115, \"EndTime\": 1646748052.7315059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10654.425382614136, \"count\": 1, \"min\": 10654.425382614136, \"max\": 10654.425382614136}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:52 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.67010123618546 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:52 INFO 139828400359040] #progress_metric: host=algo-1, completed 49.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:52 INFO 139828400359040] #quality_metric: host=algo-1, epoch=196, train loss <loss>=-0.0729029985377565\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:52 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:54 INFO 139828400359040] Epoch[197] Batch[0] avg_epoch_loss=-0.106388\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:54 INFO 139828400359040] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=-0.10638832300901413\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:58 INFO 139828400359040] Epoch[197] Batch[5] avg_epoch_loss=-0.069967\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:58 INFO 139828400359040] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=-0.06996737855176131\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:00:58 INFO 139828400359040] Epoch[197] Batch [5]#011Speed: 84.99 samples/sec#011loss=-0.069967\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] Epoch[197] Batch[10] avg_epoch_loss=-0.091826\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=-0.1180554524064064\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] Epoch[197] Batch [10]#011Speed: 76.16 samples/sec#011loss=-0.118055\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748052.731671, \"EndTime\": 1646748062.888514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10155.18045425415, \"count\": 1, \"min\": 10155.18045425415, \"max\": 10155.18045425415}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=66.17248240998109 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] #progress_metric: host=algo-1, completed 49.5 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] #quality_metric: host=algo-1, epoch=197, train loss <loss>=-0.09182559394023636\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:02 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:04 INFO 139828400359040] Epoch[198] Batch[0] avg_epoch_loss=0.015593\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:04 INFO 139828400359040] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=0.015592552721500397\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:09 INFO 139828400359040] Epoch[198] Batch[5] avg_epoch_loss=0.104919\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:09 INFO 139828400359040] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=0.10491862706840038\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:09 INFO 139828400359040] Epoch[198] Batch [5]#011Speed: 76.58 samples/sec#011loss=0.104919\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] Epoch[198] Batch[10] avg_epoch_loss=0.082751\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=0.056149125844240186\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] Epoch[198] Batch [10]#011Speed: 79.90 samples/sec#011loss=0.056149\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748062.8885794, \"EndTime\": 1646748073.1737936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10284.831523895264, \"count\": 1, \"min\": 10284.831523895264, \"max\": 10284.831523895264}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=64.9476654833752 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] #progress_metric: host=algo-1, completed 49.75 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] #quality_metric: host=algo-1, epoch=198, train loss <loss>=0.08275067196650938\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:13 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:15 INFO 139828400359040] Epoch[199] Batch[0] avg_epoch_loss=0.038348\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:15 INFO 139828400359040] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=0.038348376750946045\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:19 INFO 139828400359040] Epoch[199] Batch[5] avg_epoch_loss=0.004960\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:19 INFO 139828400359040] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=0.004960343241691589\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:19 INFO 139828400359040] Epoch[199] Batch [5]#011Speed: 79.94 samples/sec#011loss=0.004960\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] Epoch[199] Batch[10] avg_epoch_loss=-0.064850\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=-0.14862145334482194\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] Epoch[199] Batch [10]#011Speed: 80.75 samples/sec#011loss=-0.148621\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748073.1741214, \"EndTime\": 1646748083.3811018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 10205.649375915527, \"count\": 1, \"min\": 10205.649375915527, \"max\": 10205.649375915527}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=65.35503049978456 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] #quality_metric: host=algo-1, epoch=199, train loss <loss>=-0.06484956429763274\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:23 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:25 INFO 139828400359040] Epoch[200] Batch[0] avg_epoch_loss=-0.147789\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:25 INFO 139828400359040] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=-0.1477886438369751\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:29 INFO 139828400359040] Epoch[200] Batch[5] avg_epoch_loss=-0.151174\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:29 INFO 139828400359040] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=-0.15117399021983147\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:29 INFO 139828400359040] Epoch[200] Batch [5]#011Speed: 81.55 samples/sec#011loss=-0.151174\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748083.3811905, \"EndTime\": 1646748092.5867238, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 9204.903602600098, \"count\": 1, \"min\": 9204.903602600098, \"max\": 9204.903602600098}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] #throughput_metric: host=algo-1, train throughput=67.78620461379477 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] #progress_metric: host=algo-1, completed 50.25 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] #quality_metric: host=algo-1, epoch=200, train loss <loss>=-0.1258403889834881\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] Loading parameters from best epoch (160)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748092.587183, \"EndTime\": 1646748092.662254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 73.18568229675293, \"count\": 1, \"min\": 73.18568229675293, \"max\": 73.18568229675293}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] stopping training now\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] Final loss: -0.24267990167506717 (occurred at epoch 160)\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] #quality_metric: host=algo-1, train final_loss <loss>=-0.24267990167506717\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.6/site-packages/algorithm/run_worker.py:356: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  \"You are using large values for `context_length` and/or `prediction_length`. \"\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 WARNING 139828400359040] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 WARNING 139828400359040] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:32 INFO 139828400359040] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748092.6628537, \"EndTime\": 1646748094.3796396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 1712.674856185913, \"count\": 1, \"min\": 1712.674856185913, \"max\": 1712.674856185913}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:35 INFO 139828400359040] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748094.3797514, \"EndTime\": 1646748095.0571795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2390.2440071105957, \"count\": 1, \"min\": 2390.2440071105957, \"max\": 2390.2440071105957}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:35 INFO 139828400359040] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:35 INFO 139828400359040] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748095.0575898, \"EndTime\": 1646748095.1564763, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 98.8149642944336, \"count\": 1, \"min\": 98.8149642944336, \"max\": 98.8149642944336}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:35 INFO 139828400359040] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:35 INFO 139828400359040] #memory_usage::<batchbuffer> = 51.66389465332031 mb\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:35 INFO 139828400359040] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748095.1569004, \"EndTime\": 1646748095.1589055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.051975250244140625, \"count\": 1, \"min\": 0.051975250244140625, \"max\": 0.051975250244140625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748095.159304, \"EndTime\": 1646748117.2247455, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 22065.894842147827, \"count\": 1, \"min\": 22065.894842147827, \"max\": 22065.894842147827}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, RMSE): 0.9198733628423605\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, mean_absolute_QuantileLoss): 1263.4490833679008\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, mean_wQuantileLoss): 0.8437561867030383\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.1]): 0.21325362199158937\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.2]): 0.401793238545446\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.3]): 0.5818544153320233\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.4]): 0.7537409060177456\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.5]): 0.9159262971797919\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.6]): 1.0639566943001113\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.7]): 1.1893686217751616\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.8]): 1.2687103213727096\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #test_score (algo-1, wQuantileLoss[0.9]): 1.205201563812766\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #quality_metric: host=algo-1, test RMSE <loss>=0.9198733628423605\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.8437561867030383\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646748117.224864, \"EndTime\": 1646748117.337162, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 15.091896057128906, \"count\": 1, \"min\": 15.091896057128906, \"max\": 15.091896057128906}, \"totaltime\": {\"sum\": 2030240.7913208008, \"count\": 1, \"min\": 2030240.7913208008, \"max\": 2030240.7913208008}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 14:01:57 INFO 139828400359040 integration.py:592] worker closed\u001b[0m\n",
      "\n",
      "2022-03-08 14:02:30 Uploading - Uploading generated training model\n",
      "2022-03-08 14:02:30 Completed - Training job completed\n",
      "ProfilerReport-1646745895: NoIssuesFound\n",
      "Training seconds: 2141\n",
      "Billable seconds: 2141\n",
      "CPU times: user 4.72 s, sys: 472 ms, total: 5.2 s\n",
      "Wall time: 37min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "# Ta bort kommentering f철r att tr채na ny modell\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you pass a test set in this example, accuracy metrics for the forecast are computed and logged (see bottom of the log).\n",
    "You can find the definition of these metrics from [our documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html). You can use these to optimize the parameters and tune your model or use SageMaker's [Automated Model Tuning service](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/) to tune the model for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_pickle('./df_days_all.pkl').round(decimals=2).replace(0,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_feat(start_date):\n",
    "    start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    start_date_w_offset = pd.Timestamp(start_date) + pd.offsets.DateOffset(days=8)\n",
    "    df_dynamic_feat = df_weather.filter(regex=start_date.strftime(\"%Y%m%d\")).loc[start_date.strftime(\"%Y-%m-%d\"):start_date_w_offset.strftime(\"%Y-%m-%d\")].dropna()\n",
    "    return df_dynamic_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepair the data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-7621044a03bd>:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_price['DateTime'] = df_price['Date'] + ' ' + df_price['Hours'].str.replace(r'\\s-.*', '')\n"
     ]
    }
   ],
   "source": [
    "d_parser = lambda d, h: pd.datetime.strptime(d, '%d-%m-%Y')\n",
    "table_2021 = pd.read_html('https://www.nordpoolgroup.com/492498/globalassets/marketdata-excel-files/elspot-prices_2021_hourly_sek.xls', decimal=',', thousands='', header=2)\n",
    "df_price_2021 = table_2021[0]\n",
    "table_2022 = pd.read_html('https://www.nordpoolgroup.com/492498/globalassets/marketdata-excel-files/elspot-prices_2022_hourly_sek.xls', decimal=',', thousands='', header=2)\n",
    "df_price_2022 = table_2022[0]\n",
    "\n",
    "df_price = pd.concat([df_price_2021, df_price_2022])\n",
    "\n",
    "# D철p om f철rsta kolumnen till Date\n",
    "df_price.rename(columns={'Unnamed: 0':'Date'}, inplace=True )\n",
    "\n",
    "# Omvandla kolumerna Date och Hours till en DateTime och g철r den till index f철r dataframe\n",
    "df_price['DateTime'] = df_price['Date'] + ' ' + df_price['Hours'].str.replace(r'\\s-.*', '')\n",
    "df_price['DateTime'] = pd.to_datetime(df_price['DateTime'], format='%d-%m-%Y %H')\n",
    "df_price.set_index('DateTime', inplace=True)\n",
    "df_price\n",
    "# Ta bort oanv채nda kolumner\n",
    "df_price.drop(columns=['Date', 'Hours'], axis=1, inplace=True)\n",
    "\n",
    "# Omvandla fr책n MWh till kWh\n",
    "df_price.loc[:,(df_price.dtypes=='float64').values] = df_price.loc[:,(df_price.dtypes=='float64').values].div(1000).round(decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeseries(start_date):\n",
    "    start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    start_date_w_offset = pd.Timestamp(start_date) + pd.offsets.DateOffset(days=0)\n",
    "    df_timeseries = df_price['SE3'].loc[start_date.strftime(\"%Y-%m-%d\"):start_date_w_offset.strftime(\"%Y-%m-%d\")].dropna()\n",
    "    data_resample = df_timeseries.resample(\"1H\").sum()\n",
    "    return data_resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint and predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, we can use it to perform predictions by deploying it to an endpoint.\n",
    "\n",
    "**Note: Remember to delete the endpoint after running this experiment. A cell at the very bottom of this notebook will do that: make sure you run it at the end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the endpoint and perform predictions, we can define the following utility class: this allows making requests using `pandas.Series` objects rather than raw JSON strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            # serializer=JSONSerializer(),\n",
    "            serializer=IdentitySerializer(content_type=\"application/json\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        ts,\n",
    "        cat=None,\n",
    "        dynamic_feat=None,\n",
    "        num_samples=100,\n",
    "        return_samples=False,\n",
    "        quantiles=[\"0.1\", \"0.5\", \"0.9\"],\n",
    "    ):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + ts.index.freq\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "\n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(\n",
    "            ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None\n",
    "        )\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles,\n",
    "        }\n",
    "\n",
    "        http_request_data = {\"instances\": [instance], \"configuration\": configuration}\n",
    "\n",
    "        return json.dumps(http_request_data).encode(\"utf-8\")\n",
    "\n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode(\"utf-8\"))[\"predictions\"][0]\n",
    "        prediction_length = len(next(iter(predictions[\"quantiles\"].values())))\n",
    "        prediction_index = pd.date_range(\n",
    "            start=prediction_time, freq=freq, periods=prediction_length\n",
    "        )\n",
    "        if return_samples:\n",
    "            dict_of_samples = {\"sample_\" + str(i): s for i, s in enumerate(predictions[\"samples\"])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(\n",
    "            data={**predictions[\"quantiles\"], **dict_of_samples}, index=prediction_index\n",
    "        )\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "\n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]\n",
    "\n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `predictor` object to generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can deploy the model and create and endpoint that can be queried using our custom DeepARPredictor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last valid weather fetch: 2022-02-26 12:00:00\n"
     ]
    }
   ],
   "source": [
    "print('Last valid weather fetch:', df_weather.last_valid_index() - pd.offsets.DateOffset(days=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          0.1       0.5       0.9     SE3\n",
      "2022-02-17 00:00:00  0.182020  0.258244  0.320478  0.1848\n",
      "2022-02-17 01:00:00  0.141666  0.183941  0.248074  0.1589\n",
      "2022-02-17 02:00:00  0.142787  0.186455  0.263720  0.1587\n",
      "2022-02-17 03:00:00  0.169106  0.268620  0.442004  0.1476\n",
      "2022-02-17 04:00:00  0.290705  0.543442  0.902718  0.1589\n",
      "...                       ...       ...       ...     ...\n",
      "2022-02-24 19:00:00  0.152993  0.245194  1.032602  1.2911\n",
      "2022-02-24 20:00:00  0.129463  0.201632  0.923244  1.1340\n",
      "2022-02-24 21:00:00  0.119759  0.182503  0.759344  0.6854\n",
      "2022-02-24 22:00:00  0.080131  0.156260  0.532417  0.4646\n",
      "2022-02-24 23:00:00  0.081682  0.130122  0.273036  0.1684\n",
      "\n",
      "[192 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "predict_start_date = '2022-02-16'\n",
    "\n",
    "prediction = predictor.predict(ts=get_timeseries(predict_start_date), dynamic_feat=get_dynamic_feat(predict_start_date).T.values.tolist(), quantiles=[0.1, 0.5, 0.90])\n",
    "#prediction.index.name = 'DateTime'\n",
    "prediction = prediction.merge(df_price['SE3'], how='inner', left_index=True, right_index=True)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the queries of the model and displays the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(20, 10))\n",
    "\n",
    "ax = plt\n",
    "ax.plot(prediction['SE3'], color='Red', label='Pris')\n",
    "ax.plot(prediction['0.5'], color='Blue', label='Eestimerat pris median')\n",
    "ax.fill_between(x = prediction.index,\n",
    "                y1 = prediction['0.1'],\n",
    "                y2 = prediction['0.9'],\n",
    "                facecolor = 'lightskyblue',\n",
    "                alpha = 0.5,\n",
    "                label='Eestimerat min/max')\n",
    "ax.legend()\n",
    "ax.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-north-1:243637512696:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
